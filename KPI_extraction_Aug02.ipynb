{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esemsc-rw1024/irp-rw1024-public/blob/main/KPI_extraction_Aug02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "extract_sustainability_kpi.py\n",
        "==================================\n",
        "Automatically extract KPI sentences/table rows from Sustainability Report PDF\n",
        "and compare with manual KPI annotations\n",
        "--------------------------------------------------\n",
        "1. pdfplumber extracts text + tables\n",
        "2. Camelot supplements complex table parsing (optional)\n",
        "3. Chunking to control tokens\n",
        "4. OpenAI ChatCompletion API call (GPT-4o / GPT-4 / GPT-3.5)\n",
        "5. Aggregate, deduplicate, and export to auto_kpi.xlsx\n",
        "6. Compare with manual_kpi.xlsx for differences\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eDB9oRTEZoZw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "c2c0e31a-91b3-4872-9d61-d2ab3db1b3db"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nextract_sustainability_kpi.py\\n==================================\\nAutomatically extract KPI sentences/table rows from Sustainability Report PDF\\nand compare with manual KPI annotations\\n--------------------------------------------------\\n1. pdfplumber extracts text + tables\\n2. Camelot supplements complex table parsing (optional)\\n3. Chunking to control tokens\\n4. OpenAI ChatCompletion API call (GPT-4o / GPT-4 / GPT-3.5)\\n5. Aggregate, deduplicate, and export to auto_kpi.xlsx\\n6. Compare with manual_kpi.xlsx for differences\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "LaGnafXLZxfg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "3w2Bya8SZob3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai python-dotenv pdfplumber tiktoken pandas\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y ghostscript\n",
        "!pip install \"camelot-py[cv]\"\n",
        "!pip install PyMuPDF Pillow\n",
        "!pip install -q transformers pillow torchvision"
      ],
      "metadata": {
        "id": "JSakj9TyZodt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d02613-38cd-40a6-fb9c-1e7018706d0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0 python-dotenv-1.1.1\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,518 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,575 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,290 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,171 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,853 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,775 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,207 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,103 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,270 kB]\n",
            "Fetched 34.2 MB in 6s (5,501 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 libgs9 libgs9-common\n",
            "  libidn12 libijs-0.35 libjbig2dec0 poppler-data\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf fonts-texgyre\n",
            "  ghostscript-x poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho\n",
            "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n",
            "  fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript libgs9\n",
            "  libgs9-common libidn12 libijs-0.35 libjbig2dec0 poppler-data\n",
            "0 upgraded, 10 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 16.7 MB of archives.\n",
            "After this operation, 63.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.12 [753 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.12 [5,031 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.12 [49.4 kB]\n",
            "Fetched 16.7 MB in 0s (35.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 10.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../0-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../1-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../2-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../3-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../4-libgs9-common_9.55.0~dfsg1-0ubuntu5.12_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.12) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../5-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../6-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../7-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../8-libgs9_9.55.0~dfsg1-0ubuntu5.12_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.12) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../9-ghostscript_9.55.0~dfsg1-0ubuntu5.12_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.12) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.12) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.12) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.12) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting camelot-py[cv]\n",
            "  Downloading camelot_py-1.0.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "\u001b[33mWARNING: camelot-py 1.0.0 does not provide the extra 'cv'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (8.2.1)\n",
            "Requirement already satisfied: chardet>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (5.2.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (2.0.2)\n",
            "Requirement already satisfied: openpyxl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (3.1.5)\n",
            "Requirement already satisfied: pdfminer-six>=20240706 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (20250506)\n",
            "Collecting pypdf<4.0,>=3.17 (from camelot-py[cv])\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pandas>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (2.2.2)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (0.9.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.7.0.68 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (4.12.0.88)\n",
            "Requirement already satisfied: pypdfium2>=4 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (4.30.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.0->camelot-py[cv]) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->camelot-py[cv]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->camelot-py[cv]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->camelot-py[cv]) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six>=20240706->camelot-py[cv]) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six>=20240706->camelot-py[cv]) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py[cv]) (1.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.2->camelot-py[cv]) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py[cv]) (2.22)\n",
            "Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading camelot_py-1.0.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf, camelot-py\n",
            "Successfully installed camelot-py-1.0.0 pypdf-3.17.4\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.3\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m846.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, json, time, textwrap, argparse, logging\n",
        "import pdfplumber, pandas as pd, tiktoken\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from typing import List, Dict, Optional, Set, Tuple\n",
        "from pathlib import Path\n",
        "from difflib import SequenceMatcher\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import fitz  # PyMuPDF\n",
        "import numpy as np\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import concurrent.futures\n",
        "import hashlib\n",
        "import pickle\n",
        "# 在现有的导入语句后添加这些新的导入\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from datetime import datetime\n",
        "import shutil"
      ],
      "metadata": {
        "id": "rNQHu6_fZofh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------- Configuration -----------------------------\n",
        "PDF_PATH          = \"/content/Test_Unknown_northwest-sustainability-report-2022_fbqow68f-60-74.pdf\"\n",
        "MANUAL_XLSX       = \"manual_kpi.xlsx\"   # Leave empty if not available\n",
        "EXPORT_AUTO_XLSX  = \"auto_kpi.xlsx\"\n",
        "MODEL_NAME        = \"gpt-4o\"       # Adjust based on account availability\n",
        "MAX_TOKENS_CHUNK  = 1500               # Token limit per chunk\n",
        "SLEEP_SEC         = 0.6                # Rate limiting\n",
        "ENABLE_QUALITY_VALIDATION = True       # Enable additional quality checks\n",
        "# -----------------------------------------------------------------"
      ],
      "metadata": {
        "id": "L9B6ORg1Zohn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Fixed initialization part ============\n",
        "def initialize_environment():\n",
        "    \"\"\"Initialize the environment and API client\"\"\"\n",
        "    # Load environment variables\n",
        "    load_dotenv(\"ruojia_api_key.env\")\n",
        "\n",
        "    # Initialize OpenAI client\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OPENAI_API_KEY not found in environment variables!\")\n",
        "\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "    # Initialize tokenizer\n",
        "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "    return client, enc\n",
        "\n",
        "# Initialize global variables\n",
        "client, enc = initialize_environment()"
      ],
      "metadata": {
        "id": "mi52QoSbZoja"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Fixed PDF text extraction ============\n",
        "def pdf_to_text_and_tables(path: str) -> str:\n",
        "    \"\"\"Extract text paragraphs and tables using pdfplumber.\"\"\"\n",
        "    all_chunks = []\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"PDF file not found: {path}\")\n",
        "\n",
        "    try:\n",
        "        with pdfplumber.open(path) as pdf:\n",
        "            logging.info(f\"Processing PDF with {len(pdf.pages)} pages...\")\n",
        "\n",
        "            for page_num, page in enumerate(pdf.pages, 1):\n",
        "                try:\n",
        "                    # Extract text\n",
        "                    text = page.extract_text() or \"\"\n",
        "                    if text.strip():\n",
        "                        all_chunks.append(f\"PAGE_{page_num}_TEXT:\\n{text}\")\n",
        "\n",
        "                    # Extract tables\n",
        "                    tables = page.extract_tables()\n",
        "                    for table_num, tb in enumerate(tables):\n",
        "                        if tb and len(tb) > 0:\n",
        "                            try:\n",
        "                                # Handle table headers safely\n",
        "                                if tb[0]:\n",
        "                                    headers = tb[0]\n",
        "                                else:\n",
        "                                    headers = [f\"Col_{i}\" for i in range(len(tb[1]) if len(tb) > 1 else 1)]\n",
        "\n",
        "                                rows = tb[1:] if len(tb) > 1 else []\n",
        "\n",
        "                                if rows:\n",
        "                                    df = pd.DataFrame(rows, columns=headers)\n",
        "                                    # Clean DataFrame\n",
        "                                    df = df.dropna(how='all')  # Remove empty rows\n",
        "                                    if not df.empty:\n",
        "                                        table_txt = f\"TABLE_START_PAGE_{page_num}_{table_num}\\n\" + df.to_csv(index=False) + \"\\nTABLE_END\"\n",
        "                                        all_chunks.append(table_txt)\n",
        "                            except Exception as e:\n",
        "                                logging.warning(f\"Error processing table on page {page_num}: {e}\")\n",
        "                                continue\n",
        "\n",
        "                except Exception as e:\n",
        "                    logging.warning(f\"Error processing page {page_num}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        return \"\\n\\n\".join(all_chunks)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error opening PDF file: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "IkSbr5pqaGsO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Fixed Camelot table extraction ============\n",
        "def generate_table_fingerprint(df: pd.DataFrame) -> str:\n",
        "    \"\"\"Generate table fingerprint for deduplication\"\"\"\n",
        "    try:\n",
        "        fingerprint_parts = []\n",
        "        fingerprint_parts.append(f\"shape_{df.shape[0]}x{df.shape[1]}\")\n",
        "\n",
        "        if not df.columns.empty:\n",
        "            col_names = [str(col).strip().lower().replace(' ', '') for col in df.columns]\n",
        "            col_fingerprint = '_'.join(sorted(col_names))\n",
        "            fingerprint_parts.append(f\"cols_{hash(col_fingerprint)}\")\n",
        "\n",
        "        if df.shape[0] > 0:\n",
        "            numeric_values = []\n",
        "            for col in df.columns:\n",
        "                for val in df[col].head(3):\n",
        "                    if pd.notna(val):\n",
        "                        numbers = re.findall(r'\\d+\\.?\\d*', str(val))\n",
        "                        numeric_values.extend(numbers)\n",
        "\n",
        "            if numeric_values:\n",
        "                numeric_fingerprint = hash('_'.join(sorted(numeric_values[:10])))\n",
        "                fingerprint_parts.append(f\"nums_{numeric_fingerprint}\")\n",
        "\n",
        "        return '_'.join(fingerprint_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Error generating table fingerprint: {e}\")\n",
        "        return str(hash(df.to_csv()))\n",
        "\n",
        "def clean_table_data_improved(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Improved table data cleaning\"\"\"\n",
        "    try:\n",
        "        cleaned_df = df.copy()\n",
        "        cleaned_df = cleaned_df.dropna(how='all')\n",
        "        cleaned_df = cleaned_df.dropna(axis=1, how='all')\n",
        "\n",
        "        for col in cleaned_df.columns:\n",
        "            if cleaned_df[col].dtype == 'object':\n",
        "                cleaned_df[col] = cleaned_df[col].astype(str).str.strip()\n",
        "                cleaned_df[col] = cleaned_df[col].replace(['nan', 'NaN', 'None'], '')\n",
        "\n",
        "        if not cleaned_df.empty:\n",
        "            new_columns = []\n",
        "            for i, col in enumerate(cleaned_df.columns):\n",
        "                col_str = str(col).strip()\n",
        "                if col_str in ['nan', 'NaN', 'None', ''] or pd.isna(col):\n",
        "                    new_columns.append(f'Column_{i}')\n",
        "                else:\n",
        "                    new_columns.append(col_str)\n",
        "            cleaned_df.columns = new_columns\n",
        "\n",
        "        cleaned_df = cleaned_df.reset_index(drop=True)\n",
        "        return cleaned_df\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Error in table cleaning: {e}\")\n",
        "        return df\n",
        "\n",
        "def is_valid_table_improved(df: pd.DataFrame) -> bool:\n",
        "    \"\"\"Improved table validation\"\"\"\n",
        "    try:\n",
        "        if df.empty or df.shape[0] < 1 or df.shape[1] < 1:\n",
        "            return False\n",
        "\n",
        "        non_null_cells = 0\n",
        "        total_cells = df.shape[0] * df.shape[1]\n",
        "\n",
        "        for col in df.columns:\n",
        "            for val in df[col]:\n",
        "                if pd.notna(val) and str(val).strip() not in ['', 'nan', 'NaN', 'None']:\n",
        "                    non_null_cells += 1\n",
        "\n",
        "        if non_null_cells / total_cells < 0.2:\n",
        "            return False\n",
        "\n",
        "        has_meaningful_content = False\n",
        "        for col in df.columns:\n",
        "            text_content = ' '.join(df[col].dropna().astype(str))\n",
        "            if (any(char.isdigit() for char in text_content) or\n",
        "                '%' in text_content or\n",
        "                any(keyword in text_content.lower() for keyword in [\n",
        "                    'rate', 'percentage', 'total', 'number', 'emission', 'energy',\n",
        "                    'water', 'waste', 'employee', 'year', '2020', '2021', '2022', '2023'\n",
        "                ])):\n",
        "                has_meaningful_content = True\n",
        "                break\n",
        "\n",
        "        return has_meaningful_content\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Error validating table: {e}\")\n",
        "        return True\n",
        "\n",
        "def format_table_output_improved(df: pd.DataFrame, table_id: str, parsing_report=None) -> str:\n",
        "    \"\"\"Improved table output formatting\"\"\"\n",
        "    try:\n",
        "        table_info = f\"TABLE_START_{table_id}\\n\"\n",
        "        table_info += f\"DIMENSIONS: {df.shape[0]} rows × {df.shape[1]} columns\\n\"\n",
        "\n",
        "        col_info = \"COLUMNS: \" + \" | \".join([f\"{i}:{col}\" for i, col in enumerate(df.columns)])\n",
        "        table_info += col_info + \"\\n\"\n",
        "\n",
        "        if df.shape[0] > 0:\n",
        "            preview_rows = min(2, df.shape[0])\n",
        "            table_info += f\"PREVIEW_FIRST_{preview_rows}_ROWS:\\n\"\n",
        "            for i in range(preview_rows):\n",
        "                row_preview = \" | \".join([str(df.iloc[i, j])[:20] for j in range(min(5, df.shape[1]))])\n",
        "                table_info += f\"  Row_{i}: {row_preview}\\n\"\n",
        "\n",
        "        if parsing_report:\n",
        "            try:\n",
        "                accuracy = getattr(parsing_report, 'accuracy', 'N/A')\n",
        "                if accuracy != 'N/A':\n",
        "                    table_info += f\"EXTRACTION_ACCURACY: {accuracy:.2f}\\n\"\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        table_info += \"TABLE_DATA_START\\n\"\n",
        "        table_csv = df.to_csv(index=False, na_rep='', quoting=1, escapechar='\\\\')\n",
        "        table_end = f\"TABLE_DATA_END\\nTABLE_END_{table_id}\\n\"\n",
        "\n",
        "        return table_info + table_csv + table_end\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Error formatting table output: {e}\")\n",
        "        return f\"TABLE_START_{table_id}\\n{df.to_csv(index=False)}\\nTABLE_END_{table_id}\\n\"\n",
        "\n",
        "def camelot_extra_tables_enhanced(path: str) -> List[str]:\n",
        "    \"\"\"Enhanced table extraction using Camelot with better error handling\"\"\"\n",
        "    try:\n",
        "        import camelot\n",
        "    except ImportError:\n",
        "        logging.warning(\"Camelot not installed, skipping Camelot table parsing.\")\n",
        "        return []\n",
        "\n",
        "    extra_chunks = []\n",
        "    extracted_tables_fingerprints = set()\n",
        "\n",
        "    try:\n",
        "        logging.info(\"Starting Camelot table extraction...\")\n",
        "\n",
        "        # Stream mode extraction\n",
        "        try:\n",
        "            stream_tables = camelot.read_pdf(\n",
        "                path,\n",
        "                pages=\"all\",\n",
        "                flavor=\"stream\",\n",
        "                edge_tol=50,\n",
        "                row_tol=2,\n",
        "                column_tol=0\n",
        "            )\n",
        "\n",
        "            stream_count = 0\n",
        "            for i, table in enumerate(stream_tables):\n",
        "                if not table.df.empty and table.df.shape[0] > 0:\n",
        "                    table_fingerprint = generate_table_fingerprint(table.df)\n",
        "\n",
        "                    if table_fingerprint not in extracted_tables_fingerprints:\n",
        "                        cleaned_df = clean_table_data_improved(table.df)\n",
        "\n",
        "                        if is_valid_table_improved(cleaned_df):\n",
        "                            table_txt = format_table_output_improved(cleaned_df, f\"STREAM_{i}\", table.parsing_report)\n",
        "                            extra_chunks.append(table_txt)\n",
        "                            extracted_tables_fingerprints.add(table_fingerprint)\n",
        "                            stream_count += 1\n",
        "\n",
        "            logging.info(f\"Stream mode extracted {stream_count} valid tables\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Stream mode extraction failed: {e}\")\n",
        "\n",
        "        # Lattice mode extraction\n",
        "        try:\n",
        "            lattice_tables = camelot.read_pdf(\n",
        "                path,\n",
        "                pages=\"all\",\n",
        "                flavor=\"lattice\",\n",
        "                line_scale=15,\n",
        "                line_tol=2,\n",
        "                joint_tol=2\n",
        "            )\n",
        "\n",
        "            lattice_count = 0\n",
        "            for i, table in enumerate(lattice_tables):\n",
        "                if not table.df.empty and table.df.shape[0] > 0:\n",
        "                    table_fingerprint = generate_table_fingerprint(table.df)\n",
        "\n",
        "                    if table_fingerprint not in extracted_tables_fingerprints:\n",
        "                        cleaned_df = clean_table_data_improved(table.df)\n",
        "\n",
        "                        if is_valid_table_improved(cleaned_df):\n",
        "                            table_txt = format_table_output_improved(cleaned_df, f\"LATTICE_{i}\", table.parsing_report)\n",
        "                            extra_chunks.append(table_txt)\n",
        "                            extracted_tables_fingerprints.add(table_fingerprint)\n",
        "                            lattice_count += 1\n",
        "\n",
        "            logging.info(f\"Lattice mode extracted {lattice_count} additional unique tables\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Lattice mode extraction failed: {e}\")\n",
        "\n",
        "        total_extracted = len(extra_chunks)\n",
        "        logging.info(f\"Camelot extraction completed: {total_extracted} total unique tables extracted\")\n",
        "        return extra_chunks\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Camelot table extraction failed: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "amKWHBAHaGuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Text Chunking ============\n",
        "def split_into_chunks(full_text: str, max_tokens: int) -> List[str]:\n",
        "    \"\"\"Split text into chunks based on token limit\"\"\"\n",
        "    paragraphs = [p for p in full_text.split(\"\\n\") if p.strip()]\n",
        "    chunks, current = [], []\n",
        "    current_tokens = 0\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        para_tokens = len(enc.encode(paragraph))\n",
        "\n",
        "        if current_tokens + para_tokens > max_tokens and current:\n",
        "            chunks.append(\"\\n\".join(current))\n",
        "            current = [paragraph]\n",
        "            current_tokens = para_tokens\n",
        "        else:\n",
        "            current.append(paragraph)\n",
        "            current_tokens += para_tokens\n",
        "\n",
        "    if current:\n",
        "        chunks.append(\"\\n\".join(current))\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "ZSLAWykuaGxs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ System prompt words ============\n",
        "UNIVERSAL_SYSTEM_PROMPT = textwrap.dedent(\"\"\"\n",
        "    You are a professional ESG data analyst specializing in extracting Key Performance Indicators (KPIs) from sustainability reports.\n",
        "\n",
        "    ## CRITICAL: What is a KPI?\n",
        "    A KPI MUST contain SPECIFIC NUMBERS, PERCENTAGES, or MEASURABLE QUANTITIES that demonstrate actual performance or concrete targets.\n",
        "\n",
        "    ## IMPORTANT: Table Data Processing Rules\n",
        "    When processing table data:\n",
        "    1. Pay close attention to column headers to identify the correct time periods\n",
        "    2. Match data values with their corresponding year columns\n",
        "    3. If you see table format like \"Metric, 2021, 2022\" - the first number after metric belongs to 2021, second to 2022\n",
        "    4. Look for table headers that indicate year columns (e.g., \"2020\", \"2021\", \"2022\")\n",
        "    5. Extract each year's data as separate KPIs\n",
        "    6. Avoid extracting the same KPI multiple times - consolidate similar metrics\n",
        "\n",
        "    ## ENHANCED: Advanced Table Processing\n",
        "    7. **EXTRACT ALL DATA POINTS**: For each table cell containing a number, create a separate KPI\n",
        "    8. **REGIONAL/LOCATION DATA**: Pay special attention to location-specific data (countries, regions, cities)\n",
        "    9. **WORKFORCE DATA**: Extract all employee numbers, headcount data, and demographic information\n",
        "    10. **INCOMPLETE DATA**: Extract available data even if some cells are empty or missing\n",
        "    11. **TOTALS AND SUBTOTALS**: Always extract total values and aggregated numbers\n",
        "\n",
        "    ## ✅ VALID KPI EXAMPLES:\n",
        "    - \"Achieved 89.4% reuse and recycle rate for cloud hardware in 2023\"\n",
        "    - \"Diverted over 18,537 metric tons of waste from landfills in 2023\"\n",
        "    - \"Reduced single-use plastics in product packaging to 2.7%\"\n",
        "    - \"Contracted 19 GW of new renewable energy across 16 countries in 2024\"\n",
        "    - \"Provided clean water access to over 1.5 million people in 2023\"\n",
        "    - \"Protected 15,849 acres of land—exceeding target by more than 30%\"\n",
        "    - \"Allocated 761 million toward innovative climate technologies\"\n",
        "    - \"Achieved 80% renewable energy operations by 2024\"\n",
        "    - \"Water replenishment projects estimated to provide over 25 million cubic meters\"\n",
        "    - \"Exceeded annual target to divert 75% of construction waste by reaching 85%\"\n",
        "    - \"Board independence: 78% of directors\"\n",
        "    - \"Women in senior leadership increased to 35% in 2023\"\n",
        "    - \"Employee engagement score: 87% in annual survey\"\n",
        "    - \"Reduced greenhouse gas emissions by 50% compared to 2019 baseline\"\n",
        "    - \"Zero workplace fatalities achieved for third consecutive year\"\n",
        "    - \"Training completion rate: 98% for mandatory compliance courses\"\n",
        "    - \"Supplier ESG assessments completed for 95% of tier-1 suppliers\"\n",
        "    - \"Customer satisfaction rating: 4.6 out of 5.0\"\n",
        "    - \"Data breach incidents: 0 material breaches in 2023\"\n",
        "\n",
        "    ## ❌ NOT KPIs (DO NOT EXTRACT):\n",
        "    - \"Microsoft will require select suppliers to use carbon-free electricity by 2030\"\n",
        "    - \"The company plans to expand Sustainability Manager capabilities\"\n",
        "    - \"We are launching two new Circular Centers in 2023\"\n",
        "    - \"The organization established a new climate innovation fund\"\n",
        "    - \"Microsoft introduced enhanced data governance solutions\"\n",
        "    - \"Updated guidebook to include guidance on corporate responsibility\"\n",
        "    - \"Plans to publish new ESG strategy\"\n",
        "    - \"Implemented a new recycling program\"\n",
        "    - \"Conducted sustainability training sessions\"\n",
        "    - \"Launched employee wellness programs\"\n",
        "    - \"Committed to reducing emissions\"\n",
        "    - \"Focusing on environmental performance\"\n",
        "    - \"Established sustainability committee\"\n",
        "    - \"The company operates facilities in multiple regions\"\n",
        "    - \"Our supply chain includes thousands of vendors globally\"\n",
        "    - Any text without specific numbers, percentages, or quantifiable metrics\n",
        "    - Duplicate or repeated metrics (extract only once per time period)\n",
        "    - Any statement that describes business operations rather than performance outcomes\n",
        "\n",
        "    ## KPI Categories:\n",
        "    ### Environmental:\n",
        "    - **Carbon_Climate**: GHG emissions, carbon footprint, emission reductions, climate targets, scope 1/2/3 emissions, carbon intensity, carbon offsets, TCFD alignment\n",
        "    - **Energy**: Energy consumption, renewable energy percentage, energy efficiency, energy intensity, MWh, GWh, energy savings, fossil fuel usage\n",
        "    - **Water**: Water withdrawal, water consumption, water intensity, water recycling, water reuse, water stress, water discharge quality\n",
        "    - **Waste**: Waste generation, recycling rates, diversion percentages, hazardous waste, non-hazardous waste, zero waste to landfill, e-waste, incineration\n",
        "    - **Biodiversity**: Protected areas, species conservation, habitat restoration, biodiversity impact assessments, land use, ecosystem restoration\n",
        "    - **Circular_Economy**: Recycling rates, material recovery, circular design, raw materials usage, renewable materials, packaging waste\n",
        "    - **Materials**: Raw materials consumption, recycled content, sustainable materials, material intensity, sustainable sourcing\n",
        "\n",
        "    ### Social:\n",
        "    - **Workforce_Diversity**: Employee demographics, gender diversity, age diversity, ethnic diversity, disability inclusion, LGBTQ+ inclusion, workforce composition\n",
        "    - **Gender_Equality**: Women in leadership, gender pay ratio, parental leave return rates, gender representation, female employees percentage\n",
        "    - **Disability_Inclusion**: Employees with disabilities, accessibility compliance, inclusive workplace design, disability support programs\n",
        "    - **Health_Safety**: Lost Time Injury Frequency Rate (LTIFR), Total Recordable Incident Rate (TRIR), fatalities, workplace illness, safety training hours, PPE compliance, emergency drills\n",
        "    - **Employee_Wellbeing**: Employee satisfaction, retention rates, turnover rates, training hours, wellness programs, mental health services, work-life balance\n",
        "    - **Community_Engagement**: Corporate volunteering, social investment, community impact assessments, local hiring, stakeholder engagement activities\n",
        "    - **Human_Rights**: Child labor incidents, forced labor, human rights due diligence, freedom of association, grievance mechanisms, labor audits\n",
        "    - **Labor_Rights**: Collective bargaining coverage, labor complaints resolution, supplier labor audits, working conditions, fair wages\n",
        "    - **Customer_Safety**: Product safety incidents, customer satisfaction, accessibility features, safety recalls, quality metrics\n",
        "    - **Supply_Chain_Social**: Supplier assessments, sustainable sourcing, supplier code compliance, supply chain audits\n",
        "\n",
        "    ### Governance:\n",
        "    - **Board_Governance**: Board independence, board diversity, CEO-chair separation, board ESG expertise, board composition, director tenure\n",
        "    - **Executive_Compensation**: ESG-linked compensation, executive pay ratios, compensation disclosure, incentive structures\n",
        "    - **Ethics_Compliance**: Code of conduct training, corruption incidents, bribery cases, fines and penalties, whistleblower reports, anti-corruption assessments\n",
        "    - **Transparency_Disclosure**: ESG reporting coverage, third-party assurance, political contributions disclosure, GRI/SASB/TCFD compliance\n",
        "    - **Risk_Management**: Risk assessments, mitigation measures, climate risk disclosure, operational risk management\n",
        "    - **Cybersecurity_Data**: Cybersecurity breaches, data privacy policies, cybersecurity training, GDPR compliance, data protection measures\n",
        "    - **Supply_Chain_Governance**: Supplier ESG screening, supplier audits, procurement ESG clauses, vendor compliance rates\n",
        "\n",
        "    ## MANDATORY Requirements:\n",
        "    1. MUST contain specific numbers (e.g., 25%, 15,000, 2.5M, 8.5%, 0.3 per million hours)\n",
        "    2. MUST relate to measurable sustainability outcomes\n",
        "    3. MUST have time reference (year, period, or deadline)\n",
        "    4. MUST be performance-focused (results, not activities or descriptions)\n",
        "    5. MUST NOT be future plans or operational descriptions\n",
        "\n",
        "    ## Output Format:\n",
        "    Return a JSON array. Each KPI must contain:\n",
        "    ```json\n",
        "    {\n",
        "        \"kpi_text\": \"Complete original sentence with the quantifiable metric\",\n",
        "        \"kpi_theme\": \"Environmental/Social/Governance\",\n",
        "        \"kpi_category\": \"Specific category from above list\",\n",
        "        \"quantitative_value\": \"The specific number/percentage extracted\",\n",
        "        \"unit\": \"Unit of measurement (%, tonnes, employees, etc.)\",\n",
        "        \"time_period\": \"Time reference (2023, annual, by 2030, etc.)\",\n",
        "        \"target_or_actual\": \"Target/Actual/Both\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "    ## Additional Instructions:\n",
        "    - If a sentence includes a comparison value, such as a baseline, previous year, or other historical/target data (e.g., \"Compared to 32,395 MWh in 2020\"), extract it as a **separate KPI**.\n",
        "    - Do NOT store the comparison in any other field — just create another valid KPI from it.\n",
        "    - Avoid merging multiple numerical values into one KPI unless they are clearly part of the same metric (e.g., male: X, female: Y).\n",
        "\n",
        "    ## STRICT FILTERING:\n",
        "    - Return empty array [] if no quantifiable KPIs found\n",
        "    - Only extract text that contains specific measurable values\n",
        "    - Ignore all qualitative statements, plans, and descriptions\n",
        "    - Focus only on numerical performance data\n",
        "\n",
        "    Now analyze the following text for sustainability KPIs:\n",
        "\"\"\").strip()\n",
        "\n",
        "# 🔥 新增：增强的图像分析Prompt\n",
        "ENHANCED_IMAGE_KPI_SYSTEM_PROMPT = textwrap.dedent(\"\"\"\n",
        "    You are an expert data analyst specializing in extracting quantifiable KPI data from charts, graphs, and data visualizations in sustainability reports.\n",
        "\n",
        "    ## CRITICAL INSTRUCTION: ALWAYS EXTRACT NUMERICAL VALUES\n",
        "\n",
        "    **Your primary task is to extract the ACTUAL NUMBERS and PERCENTAGES visible in charts, not just descriptions.**\n",
        "\n",
        "    ## MISSION:\n",
        "    Extract ALL quantifiable data points from charts and graphs, including:\n",
        "    - Bar charts (vertical/horizontal)\n",
        "    - Pie charts and donut charts\n",
        "    - Line charts and trend graphs\n",
        "    - Stacked charts and combo charts\n",
        "    - Tables with numerical data\n",
        "    - Infographics with statistics\n",
        "    - Gauge charts and dashboards\n",
        "\n",
        "    ## DETAILED ANALYSIS INSTRUCTIONS:\n",
        "\n",
        "    ### For PIE CHARTS:\n",
        "    1. Read percentage labels on each slice\n",
        "    2. If no labels visible, estimate based on slice size\n",
        "    3. Identify what each slice represents (categories)\n",
        "    4. Extract each slice as separate KPI\n",
        "    5. **MUST read the percentage labels on each slice** - Look for numbers like 64%, 33%, 68%, 30%, etc.\n",
        "    6. **If percentages are visible on the chart, extract them exactly**\n",
        "    7. **If no labels visible, estimate based on slice size using these guidelines:**\n",
        "       - 90° slice = 25%\n",
        "       - 180° slice = 50%\n",
        "       - 270° slice = 75%\n",
        "       - Full circle = 100%\n",
        "    8. **Each slice MUST have a specific percentage value in the final output**\n",
        "\n",
        "    ### For BAR CHARTS:\n",
        "    1. Read Y-axis scale carefully (units, increments)\n",
        "    2. Estimate bar heights using grid lines and scale\n",
        "    3. Read X-axis labels (years, categories, regions)\n",
        "    4. Extract each bar as separate KPI\n",
        "    5. Pay attention to grouped/stacked bars\n",
        "\n",
        "    ### For LINE CHARTS:\n",
        "    1. Read data points at intersection of grid lines\n",
        "    2. Follow trend lines to extract values for each time period\n",
        "    3. Use Y-axis scale for value estimation\n",
        "    4. Extract each data point as separate KPI\n",
        "\n",
        "    ### For TABLES:\n",
        "    1. Read all numerical values in cells\n",
        "    2. Match values with row and column headers\n",
        "    3. Extract each cell with numerical data as KPI\n",
        "\n",
        "    ## MANDATORY VALUE EXTRACTION RULES:\n",
        "\n",
        "    **RULE 1**: Every KPI MUST contain a specific numerical value (percentage, amount, count, etc.)\n",
        "    **RULE 2**: For charts with categories, you MUST find and extract the quantitative values for each category\n",
        "    **RULE 3**: Never create KPIs without specific numbers - descriptions alone are incomplete\n",
        "    **RULE 4**: Include complete context: what + how much + when/where if available\n",
        "\n",
        "\n",
        "    ## VALUE ESTIMATION GUIDELINES:\n",
        "    - Use proportional analysis: if a bar reaches 80% of scale maximum, calculate 80% of max value\n",
        "    - For pie charts: estimate slice angles (90° = 25%, 180° = 50%, etc.)\n",
        "    - Cross-reference with any visible data labels or legends\n",
        "    - Be conservative but reasonably accurate in estimates\n",
        "\n",
        "    ## CHART IDENTIFICATION:\n",
        "    First identify the chart type, then apply appropriate extraction method.\n",
        "    Look for:\n",
        "    - Axes and scales\n",
        "    - Data labels and legends\n",
        "    - Grid lines for reference\n",
        "    - Color coding and patterns\n",
        "    - Title and subtitle information\n",
        "\n",
        "    ## OUTPUT FORMAT:\n",
        "    Return a JSON array. For each data point found:\n",
        "    ```json\n",
        "    {\n",
        "        \"kpi_text\": \"Complete description with the ACTUAL NUMERICAL VALUE included\",\n",
        "        \"kpi_theme\": \"Environmental/Social/Governance\",\n",
        "        \"kpi_category\": \"Specific category based on content\",\n",
        "        \"quantitative_value\": \"The exact number/percentage (e.g., '64', '33.5', '68')\",\n",
        "        \"unit\": \"% / tonnes / employees / MWh / USD / etc.\",\n",
        "        \"time_period\": \"2021/2020/2022/Year/period/etc if identifiable\",\n",
        "        \"target_or_actual\": \"Actual\",\n",
        "        \"chart_type\": \"pie_chart/bar_chart/line_chart/table/etc\",\n",
        "        \"estimation_confidence\": \"High/Medium/Low\",\n",
        "        \"chart_title\": \"Chart title if visible\",\n",
        "        \"data_source\": \"Legend or source if visible\"\n",
        "    }\n",
        "\n",
        "    ```\n",
        "    ## EXAMPLES of CORRECT vs INCORRECT extraction:\n",
        "\n",
        "    ### ❌ INCORRECT (incomplete - missing numerical values):\n",
        "    ```json\n",
        "    {\n",
        "        \"kpi_text\": \"Energy consumption by facility type\",\n",
        "        \"quantitative_value\": \"\",\n",
        "        \"unit\": \"%\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "    ### ✅ CORRECT (complete with specific values):\n",
        "    ```json\n",
        "    {\n",
        "        \"kpi_text\": \"Office buildings account for 45% of total energy consumption\",\n",
        "        \"quantitative_value\": \"45\",\n",
        "        \"unit\": \"%\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "    ### ❌ INCORRECT (category without value):\n",
        "    ```json\n",
        "    {\n",
        "        \"kpi_text\": \"Renewable energy percentage by region\",\n",
        "        \"quantitative_value\": \"\",\n",
        "        \"unit\": \"%\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "    ### ✅ CORRECT (specific regional data):\n",
        "    ```json\n",
        "    {\n",
        "        \"kpi_text\": \"North America achieved 78% renewable energy usage\",\n",
        "        \"quantitative_value\": \"78\",\n",
        "        \"unit\": \"%\"\n",
        "    }\n",
        "    ```\n",
        "    ## QUALITY ASSURANCE CHECKLIST:\n",
        "    Before returning results, verify:\n",
        "    - ✅ Every KPI contains a specific numerical value\n",
        "    - ✅ Chart categories are paired with their quantitative data\n",
        "    - ✅ KPI descriptions are complete and self-explanatory\n",
        "    - ✅ Units are correctly identified and specified\n",
        "    - ✅ Context (time, location, category) is preserved when available\n",
        "    - Each KPI must have a specific numerical value\n",
        "    - Context must be clear and self-contained\n",
        "    - Avoid extracting the same data point multiple times\n",
        "    - Focus on sustainability/ESG metrics when possible\n",
        "\n",
        "    ## VALUE ESTIMATION GUIDELINES:\n",
        "    - **High confidence**: Numbers clearly visible in image\n",
        "    - **Medium confidence**: Numbers estimated using chart scales/grid lines\n",
        "    - **Low confidence**: Values approximated from proportional analysis\n",
        "    - **If no numerical data is visible, return empty array []**\n",
        "\n",
        "    ## IMPORTANT NOTES:\n",
        "    - Extract ALL visible data points, not just main highlights\n",
        "    - Include context in descriptions (e.g., \"According to pie chart showing emission sources\")\n",
        "    - If values are not clearly visible, make reasonable estimates and mark confidence as \"Low\"\n",
        "    - Return empty array [] ONLY if image contains no charts/graphs with quantifiable data\n",
        "    - For multi-year data, create separate KPIs for each year\n",
        "    - Pay special attention to small text and numbers\n",
        "    - Focus on extracting actual performance data, not just identifying chart elements\n",
        "    - If you can see numbers in the image, you MUST extract them\n",
        "    - Pie chart percentages are usually the most important data points\n",
        "    - Return empty array [] ONLY if no numerical data is visible\n",
        "\n",
        "    Now analyze the provided image and extract ALL quantifiable KPI data points:\n",
        "\"\"\").strip()"
      ],
      "metadata": {
        "id": "IonQ4PK2aGzy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ KPI Extraction Function ============\n",
        "def extract_page_from_chunk(chunk: str) -> str:\n",
        "    \"\"\"Extract page information from chunk\"\"\"\n",
        "    # Look for PAGE_X_TEXT: format\n",
        "    page_matches = re.findall(r'PAGE_(\\d+)_TEXT:', chunk)\n",
        "    if page_matches:\n",
        "        pages = [int(p) for p in page_matches]\n",
        "        if len(pages) == 1:\n",
        "            return str(pages[0])\n",
        "        else:\n",
        "            return f\"{min(pages)}-{max(pages)}\"\n",
        "\n",
        "    # Look for TABLE_START_PAGE_X_\n",
        "    table_matches = re.findall(r'TABLE_START_PAGE_(\\d+)_', chunk)\n",
        "    if table_matches:\n",
        "        pages = [int(p) for p in table_matches]\n",
        "        if len(pages) == 1:\n",
        "            return str(pages[0])\n",
        "        else:\n",
        "            return f\"{min(pages)}-{max(pages)}\"\n",
        "\n",
        "    return \"Unknown\"\n",
        "\n",
        "def contains_procedural_language(text: str) -> bool:\n",
        "    \"\"\"Check if text contains procedural language\"\"\"\n",
        "    procedural_words = [\n",
        "        'introduced', 'established', 'set up', 'implemented', 'created',\n",
        "        'launched', 'formed', 'built', 'installed', 'deployed',\n",
        "        'additionally introduced', 'procedure for', 'standardization management'\n",
        "    ]\n",
        "    text_lower = text.lower()\n",
        "    return any(word in text_lower for word in procedural_words)\n",
        "\n",
        "def is_data_fragment(kpi_text: str) -> bool:\n",
        "    \"\"\"Check if text is a meaningless data fragment\"\"\"\n",
        "    text = kpi_text.strip()\n",
        "\n",
        "    # Filter pure numbers or simple percentages without context\n",
        "    if re.match(r'^\\d+\\.?\\d*%?$', text):\n",
        "        return True\n",
        "\n",
        "    # Filter very short text (less than 4 meaningful words)\n",
        "    meaningful_words = [word for word in text.split() if len(word) > 2 and not word.isdigit()]\n",
        "    if len(meaningful_words) < 3:\n",
        "        return True\n",
        "\n",
        "    # Filter text with only numbers and common connecting words\n",
        "    words = text.lower().split()\n",
        "    non_functional_words = [word for word in words if word not in ['in', 'of', 'the', 'and', 'or', 'to', 'for', 'with', 'by']]\n",
        "    if len(non_functional_words) < 3:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def standardize_kpi_universal(kpi_item: Dict) -> Dict:\n",
        "    \"\"\"Universal KPI data standardization\"\"\"\n",
        "    standardized = kpi_item.copy()\n",
        "\n",
        "    # Standardize numerical formats\n",
        "    quantitative_value = str(standardized.get('quantitative_value', '')).strip()\n",
        "    kpi_text = standardized.get('kpi_text', '').lower()\n",
        "\n",
        "    # Smart handling of percentage formats\n",
        "    if quantitative_value and quantitative_value.replace('.', '').replace('-', '').replace(',', '').isdigit():\n",
        "        # Check if original text suggests this is a percentage\n",
        "        percentage_indicators = ['percent', 'percentage', '%', 'rate', 'ratio', 'proportion', 'share']\n",
        "        if any(indicator in kpi_text for indicator in percentage_indicators):\n",
        "            if not quantitative_value.endswith('%'):\n",
        "                standardized['quantitative_value'] = quantitative_value + '%'\n",
        "                if not standardized.get('unit'):\n",
        "                    standardized['unit'] = '%'\n",
        "\n",
        "    # Ensure unit field consistency\n",
        "    if '%' in str(standardized.get('quantitative_value', '')):\n",
        "        standardized['unit'] = '%'\n",
        "\n",
        "    # Clean and normalize KPI text\n",
        "    kpi_text_original = standardized.get('kpi_text', '').strip()\n",
        "    # Remove extra spaces and newlines\n",
        "    kpi_text_cleaned = ' '.join(kpi_text_original.split())\n",
        "    standardized['kpi_text'] = kpi_text_cleaned\n",
        "\n",
        "    return standardized\n",
        "\n",
        "def generate_universal_metric_key(kpi_item: Dict) -> str:\n",
        "    \"\"\"Generate universal metric key for deduplication\"\"\"\n",
        "    try:\n",
        "        # Extract core elements\n",
        "        category = kpi_item.get('kpi_category', '').lower().strip()\n",
        "        value = str(kpi_item.get('quantitative_value', '')).replace('%', '').replace(',', '').strip()\n",
        "        time_period = kpi_item.get('time_period', '').lower().strip()\n",
        "        unit = kpi_item.get('unit', '').lower().strip()\n",
        "\n",
        "        # Extract key semantic information from KPI text\n",
        "        kpi_text = kpi_item.get('kpi_text', '').lower()\n",
        "\n",
        "        # Extract primary number (for more precise matching)\n",
        "        numbers_in_text = re.findall(r'\\d+\\.?\\d*', kpi_text)\n",
        "        primary_number = numbers_in_text[0] if numbers_in_text else value\n",
        "\n",
        "        # Generate semantic signature: extract keywords from text\n",
        "        # Remove common stop words\n",
        "        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should'}\n",
        "\n",
        "        # Extract keywords (length>2 and not stop words)\n",
        "        words = re.findall(r'\\b\\w+\\b', kpi_text)\n",
        "        key_words = [word for word in words if len(word) > 2 and word not in stop_words and not word.isdigit()]\n",
        "\n",
        "        # Sort keywords to ensure consistency\n",
        "        key_words = sorted(set(key_words))[:5]  # Take at most 5 keywords\n",
        "        semantic_signature = '_'.join(key_words)\n",
        "\n",
        "        # Build universal metric key\n",
        "        key_components = []\n",
        "\n",
        "        if category:\n",
        "            key_components.append(f\"cat:{category}\")\n",
        "        if primary_number:\n",
        "            key_components.append(f\"val:{primary_number}\")\n",
        "        if time_period:\n",
        "            key_components.append(f\"time:{time_period}\")\n",
        "        if unit:\n",
        "            key_components.append(f\"unit:{unit}\")\n",
        "        if semantic_signature:\n",
        "            key_components.append(f\"sem:{semantic_signature}\")\n",
        "\n",
        "        # Generate final key\n",
        "        metric_key = \"|\".join(key_components)\n",
        "\n",
        "        # If all components are empty, use text hash\n",
        "        if not metric_key:\n",
        "            metric_key = f\"hash:{hash(kpi_text)}\"\n",
        "\n",
        "        return metric_key\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Error generating universal metric key: {e}\")\n",
        "        # Fallback to text hash\n",
        "        return f\"fallback:{hash(kpi_item.get('kpi_text', ''))}\"\n",
        "\n",
        "def extract_kpi_from_chunk_universal(chunk: str) -> List[Dict]:\n",
        "    \"\"\"Universal KPI extraction function for various sustainability reports\"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": UNIVERSAL_SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": f\"\"\"Extract ALL KPIs from this text. Requirements:\n",
        "\n",
        "1. Create COMPLETE, MEANINGFUL KPI descriptions with full context\n",
        "2. DO NOT extract standalone numbers without explanatory text\n",
        "3. Include all relevant context (time, location, metric type, etc.)\n",
        "4. Use consistent formatting for similar metrics\n",
        "5. Ensure each KPI is self-explanatory\n",
        "\n",
        "Text to analyze:\n",
        "{chunk}\"\"\"}\n",
        "            ],\n",
        "            temperature=0.0,\n",
        "            max_tokens=4000,\n",
        "            timeout=60\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Clean potential markdown formatting\n",
        "        if content.startswith('```json'):\n",
        "            content = content[7:]\n",
        "        if content.endswith('```'):\n",
        "            content = content[:-3]\n",
        "\n",
        "        if not content.strip().startswith(\"[\"):\n",
        "            logging.warning(f\"API response not JSON list: {content[:100]}...\")\n",
        "            return []\n",
        "\n",
        "        result = json.loads(content)\n",
        "\n",
        "        if not isinstance(result, list):\n",
        "            logging.warning(\"API response is not a list format\")\n",
        "            return []\n",
        "\n",
        "        # Extract page information\n",
        "        page_number = extract_page_from_chunk(chunk)\n",
        "\n",
        "        # Universal validation and deduplication logic\n",
        "        validated_result = []\n",
        "        seen_metrics = set()\n",
        "\n",
        "        for item in result:\n",
        "            if isinstance(item, dict) and 'kpi_text' in item and 'kpi_theme' in item:\n",
        "                if item['kpi_text'].strip() and item['kpi_theme'].strip():\n",
        "\n",
        "                    # Check procedural language\n",
        "                    if contains_procedural_language(item['kpi_text']):\n",
        "                        logging.debug(f\"Procedural statement filtered: {item['kpi_text'][:50]}...\")\n",
        "                        continue\n",
        "\n",
        "                    # Filter meaningless data fragments\n",
        "                    if is_data_fragment(item['kpi_text']):\n",
        "                        logging.debug(f\"Data fragment filtered: {item['kpi_text']}\")\n",
        "                        continue\n",
        "\n",
        "                    # Standardize KPI data\n",
        "                    standardized_item = standardize_kpi_universal(item)\n",
        "\n",
        "                    # Add page information\n",
        "                    standardized_item['source_page'] = page_number\n",
        "                    standardized_item['source_type'] = 'text'\n",
        "\n",
        "                    # Universal deduplication mechanism\n",
        "                    metric_key = generate_universal_metric_key(standardized_item)\n",
        "\n",
        "                    if metric_key not in seen_metrics:\n",
        "                        validated_result.append(standardized_item)\n",
        "                        seen_metrics.add(metric_key)\n",
        "                        logging.debug(f\"KPI extracted: {standardized_item['kpi_text'][:80]}...\")\n",
        "                    else:\n",
        "                        logging.debug(f\"Duplicate metric filtered: {standardized_item['kpi_text'][:50]}...\")\n",
        "\n",
        "        logging.info(f\"Chunk processed: {len(validated_result)} unique KPIs extracted\")\n",
        "        return validated_result\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        logging.warning(f\"JSON parsing failed: {e}\\nContent: {content[:300]}...\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        logging.error(f\"API call failed: {e}\")\n",
        "        return []\n",
        "\n",
        "def post_process_kpis_universal(kpis: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"Universal KPI post-processing for various report types\"\"\"\n",
        "    if not kpis:\n",
        "        return kpis\n",
        "\n",
        "    # Step 1: Deduplication based on metric keys\n",
        "    unique_kpis_dict = {}\n",
        "\n",
        "    for kpi in kpis:\n",
        "        metric_key = generate_universal_metric_key(kpi)\n",
        "\n",
        "        if metric_key not in unique_kpis_dict:\n",
        "            unique_kpis_dict[metric_key] = kpi\n",
        "        else:\n",
        "            # If duplicate, keep the more complete KPI description\n",
        "            existing_kpi = unique_kpis_dict[metric_key]\n",
        "            current_kpi = kpi\n",
        "\n",
        "            # Compare KPI text completeness\n",
        "            if len(current_kpi.get('kpi_text', '')) > len(existing_kpi.get('kpi_text', '')):\n",
        "                unique_kpis_dict[metric_key] = current_kpi\n",
        "                logging.debug(f\"Replaced with more complete KPI: {current_kpi.get('kpi_text', '')[:50]}...\")\n",
        "            else:\n",
        "                logging.debug(f\"Kept existing KPI: {existing_kpi.get('kpi_text', '')[:50]}...\")\n",
        "\n",
        "    # Step 2: Text similarity-based secondary deduplication\n",
        "    final_kpis = list(unique_kpis_dict.values())\n",
        "\n",
        "    # Use text similarity to check remaining potential duplicates\n",
        "    final_unique_kpis = []\n",
        "\n",
        "    for current_kpi in final_kpis:\n",
        "        is_duplicate = False\n",
        "        current_text = current_kpi.get('kpi_text', '')\n",
        "\n",
        "        for existing_kpi in final_unique_kpis:\n",
        "            existing_text = existing_kpi.get('kpi_text', '')\n",
        "\n",
        "            # Calculate text similarity\n",
        "            similarity = calculate_text_similarity(current_text, existing_text)\n",
        "\n",
        "            # If similarity is very high, consider it duplicate\n",
        "            if similarity > 0.8:\n",
        "                is_duplicate = True\n",
        "                logging.debug(f\"Text similarity duplicate filtered: {current_text[:50]}...\")\n",
        "                break\n",
        "\n",
        "        if not is_duplicate:\n",
        "            final_unique_kpis.append(current_kpi)\n",
        "\n",
        "    logging.info(f\"Universal post-processing: {len(final_unique_kpis)}/{len(kpis)} KPIs retained\")\n",
        "    return final_unique_kpis\n",
        "\n",
        "def calculate_text_similarity(text1: str, text2: str) -> float:\n",
        "    \"\"\"Calculate similarity between two texts\"\"\"\n",
        "    # Normalize texts\n",
        "    norm1 = ' '.join(text1.lower().split())\n",
        "    norm2 = ' '.join(text2.lower().split())\n",
        "\n",
        "    # Word sets\n",
        "    words1 = set(norm1.split())\n",
        "    words2 = set(norm2.split())\n",
        "\n",
        "    if len(words1) == 0 or len(words2) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    intersection = len(words1.intersection(words2))\n",
        "    union = len(words1.union(words2))\n",
        "\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "def validate_kpi_quality(kpis: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"Additional quality validation for extracted KPIs with relaxed filtering\"\"\"\n",
        "    if not ENABLE_QUALITY_VALIDATION:\n",
        "        return kpis\n",
        "\n",
        "    quality_kpis = []\n",
        "\n",
        "    for kpi in kpis:\n",
        "        kpi_text = kpi.get('kpi_text', '').lower()\n",
        "\n",
        "        # Exclude \"planned tone\" KPIs (not actual performance)\n",
        "        is_future_statement = any(word in kpi_text for word in [\n",
        "            'will', 'aim to', 'plan to', 'planning to', 'intend to',\n",
        "            'is expected to', 'is scheduled to', 'expects to', 'expected to',\n",
        "            'targeting', 'propose to', 'going to', 'shall', 'to be installed'\n",
        "        ])\n",
        "        if is_future_statement:\n",
        "            logging.debug(f\"KPI rejected (future plan): {kpi_text[:100]}...\")\n",
        "            continue\n",
        "\n",
        "        # Filter procedural language\n",
        "        if contains_procedural_language(kpi_text):\n",
        "            logging.debug(f\"KPI rejected (procedural language): {kpi_text[:100]}...\")\n",
        "            continue\n",
        "\n",
        "        # Filter for phrases like \"place name + percentage\" (not ESG KPIs, but distribution descriptions)\n",
        "        geo_percent_pattern = re.compile(r\"^[a-z\\s,:%-]+(?:\\s)?\\d{1,3}%$\")\n",
        "        if geo_percent_pattern.match(kpi_text.strip()) and len(kpi_text.strip().split()) <= 6:\n",
        "            logging.debug(f\"KPI rejected (geo+percent short form): {kpi_text}\")\n",
        "            continue\n",
        "\n",
        "        # Verb whitelist: must include action verbs\n",
        "        allowed_kpi_verbs = [\n",
        "            'reduce', 'reduced', 'achieve', 'achieved', 'improve', 'improved',\n",
        "            'diverted', 'trained', 'invested', 'decreased', 'increased',\n",
        "            'consumed', 'emitted', 'saved', 'reached', 'attained', 'completed',\n",
        "            'recorded', 'cut', 'lowered', 'targeted', 'complied', 'avoided',\n",
        "            'used', 'recycled', 'sourced', 'returned', 'measured', 'maintained',\n",
        "            'reported', 'accounted', 'utilized', 'were', 'was'  # Add state verbs\n",
        "        ]\n",
        "        if not any(verb in kpi_text for verb in allowed_kpi_verbs):\n",
        "            logging.debug(f\"KPI rejected (no action verb): {kpi_text[:100]}...\")\n",
        "            continue\n",
        "\n",
        "        # Greylist verbs (action words but not necessarily performance words) - remove problematic words\n",
        "        graylist_verbs = [\n",
        "            'launched',  # Keep some potentially useful words, but remove obvious procedural words\n",
        "            'formed', 'opened', 'started'\n",
        "        ]\n",
        "\n",
        "        contains_graylist = any(verb in kpi_text for verb in graylist_verbs)\n",
        "\n",
        "        # Check for quantitative indicators\n",
        "        has_numbers = any(char.isdigit() for char in kpi_text)\n",
        "        has_percentage = '%' in kpi_text\n",
        "\n",
        "        # Extended units and measurement indicators\n",
        "        has_units = any(unit in kpi_text for unit in [\n",
        "            'tonnes', 'tons', 'kg', 'mwh', 'kwh', 'gwh', 'litres', 'liters', 'gallons',\n",
        "            'employees', 'hours', 'million', 'billion', 'thousand', 'm³', 'co2e', 'tco2e',\n",
        "            'dollars', 'usd', 'eur', 'gbp', 'incidents', 'rate', 'ratio', 'intensity',\n",
        "            'frequency', 'recordable', 'fatalities', 'injuries', 'directors', 'board',\n",
        "            'workforce', 'leadership', 'diversity', 'inclusion', 'satisfaction', 'retention',\n",
        "            'turnover', 'training', 'safety', 'ltifr', 'trir', 'compliance', 'audit',\n",
        "            'assessment', 'screening', 'supplier', 'breach', 'violation', 'disclosure',\n",
        "            'assurance', 'coverage', 'participation', 'completion', 'investment',\n",
        "            'volunteering', 'engagement', 'grievance', 'whistleblower', 'compensation',\n",
        "            'people', 'staff', 'workers', 'positions', 'roles', 'headcount', 'fte',\n",
        "            'performance', 'score', 'index', 'metric', 'level', 'amount', 'value',\n",
        "            'average', 'median', 'total', 'sum', 'count', 'number', 'quantity'\n",
        "        ])\n",
        "\n",
        "        # More flexible time reference detection\n",
        "        has_time_ref = any(time_word in kpi_text for time_word in [\n",
        "            '2019', '2020', '2021', '2022', '2023', '2024', '2025', '2026', '2027', '2028', '2029', '2030',\n",
        "            '2031', '2032', '2033', '2034', '2035', '2040', '2045', '2050',\n",
        "            'annual', 'yearly', 'year', 'quarter', 'month', 'by', 'target', 'baseline', 'fy',\n",
        "            'per year', 'per annum', 'quarterly', 'monthly', 'daily', 'future', 'deadline',\n",
        "            'period', 'reporting', 'current', 'previous', 'next', 'last', 'this'\n",
        "        ])\n",
        "\n",
        "        # Enhanced sustainability context detection\n",
        "        has_sustainability_context = any(sus_word in kpi_text for sus_word in [\n",
        "            # Environmental keywords\n",
        "            'emission', 'carbon', 'energy', 'renewable', 'waste', 'water', 'recycl',\n",
        "            'environmental', 'ghg', 'scope', 'climate', 'biodiversity', 'circular',\n",
        "            'materials', 'intensity', 'consumption', 'efficiency', 'footprint',\n",
        "            'sustainable', 'sustainability', 'green', 'clean', 'eco', 'offset',\n",
        "            'tcfd', 'nature', 'habitat', 'ecosystem', 'pollution', 'discharge',\n",
        "            'electricity', 'gas', 'fuel', 'solar', 'wind', 'hydro', 'nuclear',\n",
        "\n",
        "            # Social keywords\n",
        "            'safety', 'training', 'employee', 'diversity', 'community', 'social',\n",
        "            'workforce', 'gender', 'women', 'female', 'male', 'disability', 'disabled',\n",
        "            'inclusion', 'equity', 'equality', 'lgbtq', 'minorities', 'ethnic',\n",
        "            'health', 'wellbeing', 'wellness', 'satisfaction', 'retention', 'turnover',\n",
        "            'injury', 'incident', 'fatality', 'ltifr', 'trir', 'recordable',\n",
        "            'human rights', 'labor', 'child labor', 'forced labor', 'slavery',\n",
        "            'freedom', 'association', 'collective bargaining', 'grievance',\n",
        "            'volunteering', 'investment', 'hiring', 'local', 'stakeholder',\n",
        "            'customer', 'supplier', 'supply chain', 'accessibility', 'parental',\n",
        "            'mental health', 'ppe', 'emergency', 'drill', 'compliance',\n",
        "            'people', 'staff', 'workers', 'employment', 'job', 'career',\n",
        "            'leadership', 'management', 'senior', 'executive', 'promotion',\n",
        "\n",
        "            # Governance keywords\n",
        "            'governance', 'board', 'director', 'independent', 'chair', 'ceo',\n",
        "            'executive', 'compensation', 'pay', 'ethics', 'compliance', 'corruption',\n",
        "            'bribery', 'code of conduct', 'whistleblower', 'transparency',\n",
        "            'disclosure', 'reporting', 'assurance', 'audit', 'risk', 'management',\n",
        "            'cybersecurity', 'data', 'privacy', 'gdpr', 'breach', 'policy',\n",
        "            'screening', 'assessment', 'due diligence', 'political', 'contribution',\n",
        "            'gri', 'sasb', 'oversight', 'expertise', 'separation', 'incentive',\n",
        "            'fine', 'penalty', 'violation', 'resolution', 'anti-corruption',\n",
        "\n",
        "            # General business performance that could be sustainability-related\n",
        "            'performance', 'quality', 'delivery', 'customer', 'service', 'product',\n",
        "            'operation', 'facility', 'site', 'location', 'region', 'business'\n",
        "        ])\n",
        "\n",
        "        # If it is a greylist verb sentence, but there is no performance content such as numbers, units, time, etc. → delete\n",
        "        if contains_graylist and not (has_numbers or has_units or has_percentage or has_time_ref or has_sustainability_context):\n",
        "            logging.debug(f\"KPI rejected (graylist verb, no quantitative data): {kpi_text[:100]}...\")\n",
        "            continue\n",
        "\n",
        "        # More lenient quality scoring - only require numbers and either units/percentage OR time reference OR sustainability context\n",
        "        basic_requirements = has_numbers and (has_percentage or has_units or has_time_ref or has_sustainability_context)\n",
        "\n",
        "        # Additional check for obvious ESG relevance\n",
        "        is_esg_relevant = any(esg_word in kpi_text for esg_word in [\n",
        "            'emission', 'carbon', 'energy', 'waste', 'water', 'renewable', 'employee',\n",
        "            'safety', 'training', 'diversity', 'governance', 'board', 'compliance',\n",
        "            'sustainability', 'environmental', 'social', 'ghg', 'co2', 'workforce',\n",
        "            'gender', 'health', 'injury', 'incident', 'ethics', 'transparency'\n",
        "        ])\n",
        "\n",
        "        if basic_requirements or is_esg_relevant:\n",
        "            quality_kpis.append(kpi)\n",
        "            logging.debug(f\"KPI accepted: {kpi_text[:100]}...\")\n",
        "        else:\n",
        "            logging.debug(f\"KPI filtered out for quality: {kpi_text[:100]}...\")\n",
        "\n",
        "    logging.info(f\"Quality validation: {len(quality_kpis)}/{len(kpis)} KPIs passed\")\n",
        "    return quality_kpis"
      ],
      "metadata": {
        "id": "sB_kDyLZaG1o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Image processing functions ============\n",
        "def extract_numeric_spans(page):\n",
        "    text_dict = page.get_text(\"dict\")\n",
        "    nums = []\n",
        "    for block in text_dict[\"blocks\"]:\n",
        "        for line in block.get(\"lines\", []):\n",
        "            for span in line.get(\"spans\", []):\n",
        "                s = span[\"text\"].strip()\n",
        "                if re.match(r\"[\\d,.]+%?$\", s):          # Pure number or number + %\n",
        "                    nums.append({\n",
        "                        \"text\": s,\n",
        "                        \"bbox\": span[\"bbox\"],           # (x0,y0,x1,y1)\n",
        "                        \"font\": span[\"size\"]\n",
        "                    })\n",
        "    return nums\n",
        "\n",
        "def extract_images_from_pdf_fixed(pdf_path: str) -> List[Dict]:\n",
        "    \"\"\"Extract images from PDF using PyMuPDF\"\"\"\n",
        "    images = []\n",
        "\n",
        "    try:\n",
        "        pdf_document = fitz.open(pdf_path)\n",
        "\n",
        "        for page_num in range(len(pdf_document)):\n",
        "            page = pdf_document[page_num]\n",
        "            image_list = page.get_images()\n",
        "\n",
        "            # 🔥 New: Extract page screenshots as an alternative\n",
        "            page_pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # high resolution\n",
        "            page_img = Image.frombytes(\"RGB\", [page_pix.width, page_pix.height], page_pix.samples)\n",
        "\n",
        "            # Add full page screenshot\n",
        "            images.append({\n",
        "                'image': page_img,\n",
        "                'page_number': page_num + 1,\n",
        "                'width': page_img.width,\n",
        "                'height': page_img.height,\n",
        "                'image_index': 'full_page',\n",
        "                'type': 'full_page'\n",
        "            })\n",
        "\n",
        "\n",
        "            for img_index, img in enumerate(image_list):\n",
        "                try:\n",
        "                    xref = img[0]\n",
        "                    base_image = pdf_document.extract_image(xref)\n",
        "                    image_bytes = base_image[\"image\"]\n",
        "\n",
        "                    image = Image.open(BytesIO(image_bytes))\n",
        "\n",
        "                    # Convert to RGB if needed\n",
        "                    if image.mode in ['RGBA', 'LA']:\n",
        "                        background = Image.new('RGB', image.size, (255, 255, 255))\n",
        "                        if image.mode == 'RGBA':\n",
        "                            background.paste(image, mask=image.split()[-1])\n",
        "                        else:\n",
        "                            background.paste(image)\n",
        "                        image = background\n",
        "                    elif image.mode != 'RGB':\n",
        "                        image = image.convert('RGB')\n",
        "\n",
        "                    # Filter small images\n",
        "                    if image.width >= 50 and image.height >= 50:\n",
        "                        images.append({\n",
        "                            'image': image,\n",
        "                            'page_number': page_num + 1,\n",
        "                            'width': image.width,\n",
        "                            'height': image.height,\n",
        "                            'image_index': img_index,\n",
        "                            'type': 'extracted'  # 🔥 Added type identifier\n",
        "                        })\n",
        "\n",
        "                except Exception as e:\n",
        "                    logging.warning(f\"Error extracting image {img_index} from page {page_num + 1}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        pdf_document.close()\n",
        "        logging.info(f\"Extracted {len(images)} images from PDF\")\n",
        "        return images\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error extracting images from PDF: {e}\")\n",
        "        return []\n",
        "\n",
        "def image_to_base64_fixed(image: Image.Image) -> str:\n",
        "    \"\"\"Convert image to base64 with error handling\"\"\"\n",
        "    try:\n",
        "        if image.mode not in ['RGB', 'L']:\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        # Resize large images\n",
        "        max_size = (1536, 1536)\n",
        "        if image.width > max_size[0] or image.height > max_size[1]:\n",
        "            # Calculate scaling to maintain aspect ratio\n",
        "            ratio = min(max_size[0]/image.width, max_size[1]/image.height)\n",
        "            new_size = (int(image.width * ratio), int(image.height * ratio))\n",
        "            image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
        "\n",
        "        buffered = BytesIO()\n",
        "        image.save(buffered, format=\"JPEG\", quality=95)\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "\n",
        "        return img_str\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error converting image to base64: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "Vfegv4osaG3b"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Multi-crop / multi-resolution generator (supports crop parameter 0)\n",
        "# ------------------------------------------------------------\n",
        "from itertools import product\n",
        "\n",
        "def generate_image_variants(img: Image.Image,\n",
        "                            max_side_full: int = 1200,\n",
        "                            crop_size: int = 768,\n",
        "                            stride: int = 512) -> List[Tuple[Image.Image, str]]:\n",
        "    \"\"\"\n",
        "    Returns [(variant_image, variant_tag), ...]\n",
        "    variant_tag value: original / resized / crop_{row}_{col}\n",
        "    \"\"\"\n",
        "    variants = []\n",
        "\n",
        "    # 0) Original image\n",
        "    variants.append((img, \"original\"))\n",
        "\n",
        "    # 1) Zoom (if the original image is too large)\n",
        "    w, h = img.size\n",
        "    if max(w, h) > max_side_full:\n",
        "        scale = max_side_full / float(max(w, h))\n",
        "        resized = img.resize((int(w * scale), int(h * scale)), Image.Resampling.LANCZOS)\n",
        "        variants.append((resized, \"resized\"))\n",
        "    else:\n",
        "        resized = img  # Keep the original image without scaling\n",
        "        variants.append((resized, \"resized\"))  # Unified plus resized version\n",
        "\n",
        "    # 2) Sliding window cropping (skipped when cropping size or step size is 0)\n",
        "    if crop_size > 0 and stride > 0:\n",
        "        base_img = variants[-1][0]\n",
        "        bw, bh = base_img.size\n",
        "        if bw > crop_size or bh > crop_size:\n",
        "            xs = list(range(0, max(bw - crop_size, 1), stride)) + [bw - crop_size]\n",
        "            ys = list(range(0, max(bh - crop_size, 1), stride)) + [bh - crop_size]\n",
        "            for r, c in product(range(len(ys)), range(len(xs))):\n",
        "                x, y = xs[c], ys[r]\n",
        "                crop = base_img.crop((x, y, x + crop_size, y + crop_size))\n",
        "                # Filter solid color areas\n",
        "                if np.array(crop.convert('L')).std() < 5:\n",
        "                    continue\n",
        "                variants.append((crop, f\"crop_{r}_{c}\"))\n",
        "\n",
        "    return variants"
      ],
      "metadata": {
        "id": "ma9D4crJaG5z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# 📊 A chart recognition function that replaces plotclassifier (Hugging Face model)\n",
        "# ---------------------------------------------\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "import torch\n",
        "# 🔧 Fix: Chart recognition with CLIP model\n",
        "def setup_chart_classifier():\n",
        "    \"\"\"Setting up the chart classifier\"\"\"\n",
        "    try:\n",
        "        from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "        # Loading CLIP Model\n",
        "        model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "        processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "        def is_chart_image_clip(image: Image.Image) -> bool:\n",
        "            \"\"\"Use CLIP to determine whether it is a chart\"\"\"\n",
        "            try:\n",
        "                # Defines text description related to the chart\n",
        "                chart_labels = [\n",
        "                    \"a chart\", \"a graph\", \"a bar chart\", \"a pie chart\",\n",
        "                    \"a line graph\", \"a table\", \"data visualization\",\n",
        "                    \"statistics\", \"a diagram\", \"an infographic\"\n",
        "                ]\n",
        "\n",
        "                # Processing Input\n",
        "                inputs = processor(\n",
        "                    text=chart_labels,\n",
        "                    images=image,\n",
        "                    return_tensors=\"pt\",\n",
        "                    padding=True\n",
        "                )\n",
        "\n",
        "                # Get prediction results\n",
        "                outputs = model(**inputs)\n",
        "                logits_per_image = outputs.logits_per_image\n",
        "                probs = logits_per_image.softmax(dim=1)\n",
        "\n",
        "                # If the probability of any chart label is greater than 0.25, it is considered to be a chart\n",
        "                max_prob = probs.max().item()\n",
        "                is_chart = max_prob > 0.25\n",
        "\n",
        "                logging.debug(f\"CLIP chart recognition: maximum probability = {max_prob:.3f}, result = {is_chart}\")\n",
        "                return is_chart\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.warning(f\"CLIP chart recognition failed: {e}\")\n",
        "                # Downgrade to statistical methods\n",
        "                gray = image.convert('L')\n",
        "                return np.array(gray).std() > 15\n",
        "\n",
        "        logging.info(\"✅ Graph recognition using CLIP model\")\n",
        "        return is_chart_image_clip\n",
        "\n",
        "    except ImportError:\n",
        "        logging.warning(\"CLIP model is not available, use statistical methods\")\n",
        "        def is_chart_image_stats(image: Image.Image) -> bool:\n",
        "            \"\"\"Statistical method to determine whether it is a chart\"\"\"\n",
        "            try:\n",
        "                gray = image.convert('L')\n",
        "                std_dev = np.array(gray).std()\n",
        "                return std_dev > 15\n",
        "            except:\n",
        "                return True\n",
        "\n",
        "        return is_chart_image_stats\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to set chart classifier: {e}\")\n",
        "        def is_chart_image_fallback(image: Image.Image) -> bool:\n",
        "            return True  # Conservative Strategy: When in Doubt, Analyze\n",
        "        return is_chart_image_fallback\n",
        "\n",
        "# Initialize the graph classifier\n",
        "is_chart_image = setup_chart_classifier()\n",
        "\n",
        "\n",
        "def extract_kpi_from_image_fixed(image: Image.Image, page_number: int, image_type: str = 'extracted') -> List[Dict]:\n",
        "    \"\"\"Extract KPIs from image with improved error handling\"\"\"\n",
        "    try:\n",
        "        # 🔥 New: Pre-filter: Check if it might be a chart\n",
        "        if not is_chart_image(image):\n",
        "            logging.debug(f\"Image on page {page_number} filtered out (not likely a chart)\")\n",
        "            return []\n",
        "\n",
        "        base64_image = image_to_base64_fixed(image)\n",
        "        if not base64_image:\n",
        "            return []\n",
        "\n",
        "        # 🔥 Change: Use enhanced prompt\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": ENHANCED_IMAGE_KPI_SYSTEM_PROMPT  # 🔥 Using the new prompt\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            # 🔥 New: Detailed user instructions\n",
        "                            \"text\": \"\"\"Analyze this image carefully for quantifiable performance data.\n",
        "\n",
        "IMPORTANT ANALYSIS PRINCIPLES:\n",
        "\n",
        "1. **Chart Type Recognition**:\n",
        "   - Stacked charts: Multiple colors/patterns layered in same position\n",
        "   - Grouped charts: Multiple elements side by side at same position\n",
        "   - Simple charts: One data point per position\n",
        "\n",
        "2. **Value Extraction Rules**:\n",
        "   - For STACKED charts: Read each layer separately, NOT the total height\n",
        "   - For GROUPED charts: Read each element individually\n",
        "   - For SIMPLE charts: Read data point values directly\n",
        "\n",
        "3. **Data Relevance Filter**:\n",
        "   ✅ EXTRACT: Performance outcomes, efficiency metrics, reduction rates, satisfaction scores, compliance rates\n",
        "   ❌ SKIP: Certification counts, project timelines, implementation schedules, organizational charts, process flows\n",
        "\n",
        "4. **Quality Standards**:\n",
        "   - Only extract clear, quantifiable performance indicators\n",
        "   - Each data point must have complete context\n",
        "   - If uncertain about values, don't estimate\n",
        "   - If chart shows mainly operational/administrative data, return empty array\n",
        "\n",
        "Please analyze this chart step by step:\n",
        "- First identify the chart type\n",
        "- Then determine if it contains performance KPIs\n",
        "- Finally extract all relevant performance data points\n",
        "\n",
        "Focus on measurable outcomes and achievements, not counts or processes.\"\"\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "                                \"detail\": \"high\"\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.1,\n",
        "            max_tokens=4000,\n",
        "            timeout=60\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        if not content:\n",
        "            return []\n",
        "\n",
        "        # Clean formatting\n",
        "        if content.startswith('```json'):\n",
        "            content = content[7:]\n",
        "        if content.endswith('```'):\n",
        "            content = content[:-3]\n",
        "\n",
        "        content = content.strip()\n",
        "\n",
        "        if not content.startswith(\"[\"):\n",
        "            logging.warning(f\"Image analysis response not JSON list: {content[:100]}...\")\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            result = json.loads(content)\n",
        "        except json.JSONDecodeError as e:\n",
        "            logging.warning(f\"JSON parsing failed for image analysis: {e}\")\n",
        "            return []\n",
        "\n",
        "        if not isinstance(result, list):\n",
        "            return []\n",
        "\n",
        "        # Process results\n",
        "        processed_result = []\n",
        "        for item in result:\n",
        "            if isinstance(item, dict) and 'kpi_text' in item:\n",
        "                if not item.get('kpi_text', '').strip():\n",
        "                    continue\n",
        "\n",
        "                item['source_page'] = page_number\n",
        "                item['source_type'] = 'image'\n",
        "                item['image_type'] = image_type  # 🔥 新增字段\n",
        "\n",
        "                # 🔥 更改：确保有chart标识\n",
        "                kpi_text = item['kpi_text']\n",
        "                if not any(marker in kpi_text.lower() for marker in ['chart', 'graph', 'table', 'figure']):\n",
        "                    chart_type = item.get('chart_type', 'chart')\n",
        "                    item['kpi_text'] = f\"[{chart_type.title()}] {kpi_text}\"\n",
        "\n",
        "                processed_result.append(item)\n",
        "\n",
        "        if processed_result:\n",
        "            logging.info(f\"✅ Extracted {len(processed_result)} KPIs from {image_type} on page {page_number}\")\n",
        "        else:\n",
        "            logging.debug(f\"❌ No KPIs found in {image_type} on page {page_number}\")\n",
        "\n",
        "        return processed_result\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error extracting KPIs from image: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def process_pdf_images_for_kpis_fixed(pdf_path: str) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Traverse each page of the PDF:\n",
        "        • Perform multiple cropping + Vision on all ‘extracted’ images on the page\n",
        "        • If the page has not captured the KPI, perform Vision on the entire page screenshot\n",
        "    \"\"\"\n",
        "    logging.info(\"Starting page-by-page image KPI extraction …\")\n",
        "\n",
        "    images = extract_images_from_pdf_fixed(pdf_path)\n",
        "    if not images:\n",
        "        return []\n",
        "\n",
        "    # Aggregate images by page\n",
        "    page_dict = {}\n",
        "    for info in images:\n",
        "        pg = info[\"page_number\"]\n",
        "        page_dict.setdefault(pg, {\"extracted\": [], \"full\": None})\n",
        "        if info[\"type\"] == \"extracted\":\n",
        "            page_dict[pg][\"extracted\"].append(info[\"image\"])\n",
        "        else:                    # full_page\n",
        "            page_dict[pg][\"full\"] = info[\"image\"]\n",
        "\n",
        "    all_image_kpis: List[Dict] = []\n",
        "\n",
        "    # —— Page by page processing ——\n",
        "    for pg in sorted(page_dict.keys()):\n",
        "        logging.info(f\"\\n=== Page {pg} ===\")\n",
        "        page_kpis: List[Dict] = []\n",
        "\n",
        "        # ① Individually extracted images\n",
        "        for idx, img in enumerate(page_dict[pg][\"extracted\"]):\n",
        "            for var_img, var_tag in generate_image_variants(img, 1200, 768, 512):\n",
        "                kpis = extract_kpi_from_image_fixed(\n",
        "                    var_img, pg, f\"extracted_{var_tag}\"\n",
        "                )\n",
        "                for k in kpis:\n",
        "                    key = generate_universal_metric_key(k)\n",
        "                    if key not in {generate_universal_metric_key(x) for x in page_kpis}:\n",
        "                        page_kpis.append(k)\n",
        "                time.sleep(0.8)\n",
        "\n",
        "        # ② If it is still empty, analyze the entire page again\n",
        "        if not page_kpis and page_dict[pg][\"full\"] is not None:\n",
        "            for var_img, var_tag in generate_image_variants(\n",
        "                    page_dict[pg][\"full\"], 1200, 0, 0):   # 只做 original/resized\n",
        "                kpis = extract_kpi_from_image_fixed(\n",
        "                    var_img, pg, f\"full_{var_tag}\"\n",
        "                )\n",
        "                for k in kpis:\n",
        "                    key = generate_universal_metric_key(k)\n",
        "                    if key not in {generate_universal_metric_key(x) for x in page_kpis}:\n",
        "                        page_kpis.append(k)\n",
        "                time.sleep(1.0)\n",
        "\n",
        "        logging.info(f\"  → Page {pg} KPI count: {len(page_kpis)}\")\n",
        "        all_image_kpis.extend(page_kpis)\n",
        "\n",
        "    logging.info(f\"Image KPI extraction finished: {len(all_image_kpis)} KPIs from {len(page_dict)} pages\")\n",
        "    return all_image_kpis"
      ],
      "metadata": {
        "id": "F5ZLpwL8Zok_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "0002286f577d4bd0b35496b02c9b3519",
            "e5ce56c0a551449b96971a00d033a463",
            "b48738c746ed492f82b3da267f58b057",
            "355143171293469486b2f3573683808d",
            "e68e0c22756b4ff79e29c8840a6d7042",
            "95f716ac47d34b7fb47a15d6c5c9978e",
            "5ce75021849c47ff8397414bfffb4f71",
            "387e067b34084caebcf299a3b7d642e3",
            "a9ea394c6e434dfebbeed25c80c04f65",
            "1f42a9810df04e7fb1a3e5bb4c313ee5",
            "39a6f8857aed4a18a3c02996a0ec4e19",
            "e7e7811c04314fc7ae1c664adc6635a9",
            "54d483cc303448f49157dd450ef578d6",
            "de0a9c121a6644ae822c32739445aede",
            "81644a7b4873436b9dd5cda5aa5e4832",
            "8a9f31cd90694d708f460da8510e41e3",
            "bb55b387423f468ea48450d00a2c33b7",
            "b9bc1a5bf49c407f89c611c17ba6f23b",
            "090eae0e4cc54e8783f149c0a3a668e2",
            "b42f2070c9cf47ca92b3a75d56b3d763",
            "e42798b138be456fa4f7f550641d9ec5",
            "2dfa72a8849d4be984c33d5dcbed5891",
            "2771b3bbc87540fca43a137b7c1ac783",
            "7af0ce88614649d18248a2eebf07327a",
            "bcb9d8d65c374a11bcf0830871c60f47",
            "572640eddf76421ca426a2348ab71353",
            "deb9ba6e70194f2683fb03593c3450ef",
            "7b6874147fe34db9995cafa47dc474cc",
            "1116ffc0d0e64cde83929cc5243a604b",
            "eb5419e5a1ad46048bed98c5102494ad",
            "eee252faec204616913e8c51c8260755",
            "6d224af04a1d4a1993e75a5812748d5f",
            "e0a5e549dede4523a4eae5d5e9b68a26",
            "3fca65d8785a44aabc8a8f6a974ad242",
            "fb36a2f0db0a491e83fdb981b687cf54",
            "7cb7bb19ecdd4aed9e68c873cbc345c1",
            "7c43d77187ec49d6ad05a386bb39a601",
            "0bb02190fa7548898065afb695f6e00c",
            "987ac61b1b3c41ddaa1b86a43826cc50",
            "27065dbbeec042b69c7801cdfc2ac902",
            "8cc3059dc28a4a568a425d37f2c4e2d2",
            "d1203b85ee004f62833434b6070dc495",
            "41d337248952404dbdcf1ed32f3e3c0c",
            "ce4bffb0b443499db52091a1aecab6ae",
            "b3e7b49859dc4f2c9f1f2e9b5571bf96",
            "0bc5b5a260ef4f018edbf3e0851e02b2",
            "3abcacc2a37b4cda9bfd633d9e671429",
            "e5cdfe8762374b33818dc7fec867bb0e",
            "cf18674534f2445894d59c0d6b9a02db",
            "afd4e05d78f545dfb642636f9f5888a3",
            "ce5670c75ee4463caba04c64c66de9fc",
            "46a156259f674bbcb6ced8c4f9bd5d28",
            "77cb59c859db4992a028fd63299a4bef",
            "a41ba7e0d26648e58601f953b151958c",
            "229554cef136486c8a5aa0e9e6d20c8e",
            "74baab93f4f94f57acfdf742ef54ed54",
            "27fe1dfa34214aef88464e80fe1010bb",
            "376393e1d7264fff9e1c85af9f3054d8",
            "66ac5ed6caec4c5d98fbb53d8f65faab",
            "fb3c8486c260492e9ed975861bcbc763",
            "43790ce901b742d9bae31d2d128ad5eb",
            "edf80fa27da2420b9f2aceb9593f81dc",
            "8293433bbd3b41b7a87018156c5abcdf",
            "688f485dd12f4858ad6110c8952ad57e",
            "4b88acf2e8334cc0b2c6d886d972e9f6",
            "ca4e2047755449128384196c8f2e5a62",
            "8fa5668fd8eb4fc49ae889c6fc7e65f9",
            "dae2fc0f22004fda97bfeb5a3b04aa85",
            "e3e5b11809bb4d16a0c5467cad6a2102",
            "cd7e1ffc0a36427bbab78efd74caaeab",
            "6e300209165540dbb9fa07573cde758b",
            "d4a9908e479e4158941718735f028171",
            "c0dfbc01035944fabc7eb65fda855bbb",
            "9cd422a23cb74016b5ef5780a02ac300",
            "4deb4215098447b4955a446eb07724d9",
            "c2ba8725a29c4a6cb5ae2978be823639",
            "687184aa7f29424ea1827269dfc4200f",
            "983f3416c7274f5ea89fcdccbd825716",
            "89d40ada26c949f397eb0dd3f95c5ba1",
            "7951f52ca7a44e18a6680e894986ebd0",
            "8507a09ada164c078953a257017130ba",
            "1442095b5f764d9aad2ba4eb85b5ec55",
            "86f73c9eb4a3458d8329b7445bd5b435",
            "01f54f8e653c4ba19775eee1c672fe89",
            "36fa5650a069406fa308133891f05607",
            "d842cc33814a4cf3bb2a31eeb16c0bb5",
            "4ed5d7b0b19643e7bde3a3962ef7cd06",
            "1290f7e1dde2436cb12b5804f8954e9c",
            "c1128ba2c510436e9f85e3f2e09e8367",
            "7a1c4f5c79d8408db37e19cc989f16b4",
            "9af452734876489e8b4152c029edf54f",
            "23e8f9fd2e1742fd812fecf5bb8d4095",
            "a2c302d015b0434bb61297b6c14a8d0b",
            "1fb2205d93d544bfaeb221f672dde4a7",
            "1f1b7697582640be8c2519d68885f6e1",
            "0014b16d79144e98ad74be78121a3b42",
            "fc46109850b04f68911b971854cbd4b2",
            "15ea70c578ed49cca24bbe7018305772",
            "bcfb67e1505a49ba91fbe44458bdc4ec"
          ]
        },
        "outputId": "9af70fdc-3d0a-48e7-d0e9-d95b30bb5fc9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0002286f577d4bd0b35496b02c9b3519"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7e7811c04314fc7ae1c664adc6635a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2771b3bbc87540fca43a137b7c1ac783"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fca65d8785a44aabc8a8f6a974ad242"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3e7b49859dc4f2c9f1f2e9b5571bf96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74baab93f4f94f57acfdf742ef54ed54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fa5668fd8eb4fc49ae889c6fc7e65f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "983f3416c7274f5ea89fcdccbd825716"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1128ba2c510436e9f85e3f2e09e8367"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Conservative image filter\n",
        "def conservative_image_filter(image: Image.Image) -> Tuple[bool, str]:\n",
        "    \"\"\"Conservative image filtering - only filters obviously useless images\"\"\"\n",
        "    try:\n",
        "        # Only filter very small images (maybe logos, icons)\n",
        "        if image.width < 40 or image.height < 40:\n",
        "            return False, \"too_small_icon\"\n",
        "\n",
        "        # Filter only images of almost pure colors (decorative elements)\n",
        "        gray = np.array(image.convert('L'))\n",
        "        std_dev = gray.std()\n",
        "\n",
        "        # Very conservative threshold - only images with completely pure colors are filtered\n",
        "        if std_dev < 3:\n",
        "            return False, \"pure_color\"\n",
        "\n",
        "        # Check if it is a pure white background (blank area)\n",
        "        mean_val = gray.mean()\n",
        "        if mean_val > 250 and std_dev < 8:\n",
        "            return False, \"blank_white\"\n",
        "\n",
        "        # Default: Process all other images to ensure integrity\n",
        "        return True, \"keep_for_analysis\"\n",
        "    except Exception:\n",
        "        return True, \"filter_error_keep\"\n",
        "\n",
        "# 2. Cache mechanism\n",
        "class FastKPICache:\n",
        "    def __init__(self, cache_dir: str = \"fast_kpi_cache\"):\n",
        "        self.cache_dir = cache_dir\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "        self.hit_count = 0\n",
        "        self.miss_count = 0\n",
        "\n",
        "    def get_image_hash(self, image: Image.Image) -> str:\n",
        "        \"\"\"Fast image fingerprint generation\"\"\"\n",
        "        width, height = image.size\n",
        "        if width > 100 and height > 100:\n",
        "            center_crop = image.crop((\n",
        "                width//4, height//4,\n",
        "                3*width//4, 3*height//4\n",
        "            )).resize((32, 32))\n",
        "            img_bytes = BytesIO()\n",
        "            center_crop.save(img_bytes, format='JPEG', quality=50)\n",
        "            sample_hash = hashlib.md5(img_bytes.getvalue()).hexdigest()[:16]\n",
        "        else:\n",
        "            sample_hash = hashlib.md5(str(width * height).encode()).hexdigest()[:16]\n",
        "\n",
        "        return f\"{width}x{height}_{sample_hash}\"\n",
        "\n",
        "    def get_cached_kpis(self, image_hash: str) -> Optional[List[Dict]]:\n",
        "        cache_file = os.path.join(self.cache_dir, f\"{image_hash}.pkl\")\n",
        "        if os.path.exists(cache_file):\n",
        "            try:\n",
        "                with open(cache_file, 'rb') as f:\n",
        "                    self.hit_count += 1\n",
        "                    return pickle.load(f)\n",
        "            except:\n",
        "                pass\n",
        "        self.miss_count += 1\n",
        "        return None\n",
        "\n",
        "    def cache_kpis(self, image_hash: str, kpis: List[Dict]):\n",
        "        cache_file = os.path.join(self.cache_dir, f\"{image_hash}.pkl\")\n",
        "        try:\n",
        "            with open(cache_file, 'wb') as f:\n",
        "                pickle.dump(kpis, f)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    def get_stats(self):\n",
        "        total = self.hit_count + self.miss_count\n",
        "        hit_rate = self.hit_count / total if total > 0 else 0\n",
        "        return f\"Cache: {self.hit_count} hits, {self.miss_count} misses (hit rate: {hit_rate:.1%})\"\n",
        "\n",
        "# Initialize the cache\n",
        "fast_cache = FastKPICache()\n",
        "\n",
        "# 3. Optimized API calls\n",
        "COMPREHENSIVE_EXTRACTION_PROMPT = \"\"\"\n",
        "You are an expert data analyst. Extract ALL quantifiable performance indicators from this image.\n",
        "\n",
        "CRITICAL REQUIREMENTS:\n",
        "1. Extract EVERY visible number, percentage, and metric\n",
        "2. Include ALL data points from charts, graphs, and tables\n",
        "3. Do not skip any quantifiable information\n",
        "\n",
        "Return complete JSON array:\n",
        "[\n",
        "  {\n",
        "    \"kpi_text\": \"Complete contextual description with the specific number\",\n",
        "    \"quantitative_value\": \"exact number only\",\n",
        "    \"unit\": \"unit of measurement\",\n",
        "    \"kpi_theme\": \"Environmental/Social/Governance\",\n",
        "    \"kpi_category\": \"specific category\",\n",
        "    \"time_period\": \"year/period if visible\"\n",
        "  }\n",
        "]\n",
        "\n",
        "COMPLETENESS IS CRITICAL - Extract everything quantifiable.\n",
        "\"\"\"\n",
        "\n",
        "def extract_kpi_optimized(image: Image.Image, page_number: int) -> List[Dict]:\n",
        "    \"\"\"Optimized KPI extraction\"\"\"\n",
        "    try:\n",
        "        # Check the cache\n",
        "        image_hash = fast_cache.get_image_hash(image)\n",
        "        cached_kpis = fast_cache.get_cached_kpis(image_hash)\n",
        "        if cached_kpis is not None:\n",
        "            for kpi in cached_kpis:\n",
        "                kpi['source_page'] = page_number\n",
        "            return cached_kpis\n",
        "\n",
        "        # Optimizing image encoding\n",
        "        base64_image = image_to_base64_optimized(image)\n",
        "        if not base64_image:\n",
        "            return []\n",
        "\n",
        "        # API Calls\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": COMPREHENSIVE_EXTRACTION_PROMPT},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "                        \"detail\": \"high\"\n",
        "                    }}\n",
        "                ]\n",
        "            }],\n",
        "            temperature=0.0,\n",
        "            max_tokens=2000,\n",
        "            timeout=60\n",
        "        )\n",
        "\n",
        "        # Parsing results\n",
        "        kpis = parse_optimized_response(response, page_number)\n",
        "\n",
        "        # Caching results\n",
        "        fast_cache.cache_kpis(image_hash, kpis)\n",
        "\n",
        "        return kpis\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Optimized KPI extraction failed for page {page_number}: {e}\")\n",
        "        return []\n",
        "\n",
        "def image_to_base64_optimized(image: Image.Image) -> str:\n",
        "    \"\"\"Optimized image encoding\"\"\"\n",
        "    try:\n",
        "        max_dimension = 1400  # Maintain high quality\n",
        "        width, height = image.size\n",
        "\n",
        "        if max(width, height) > max_dimension:\n",
        "            scale = max_dimension / max(width, height)\n",
        "            new_size = (int(width * scale), int(height * scale))\n",
        "            image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            if image.mode in ['RGBA', 'LA']:\n",
        "                background = Image.new('RGB', image.size, (255, 255, 255))\n",
        "                if image.mode == 'RGBA':\n",
        "                    background.paste(image, mask=image.split()[-1])\n",
        "                else:\n",
        "                    background.paste(image)\n",
        "                image = background\n",
        "            else:\n",
        "                image = image.convert('RGB')\n",
        "\n",
        "        buffered = BytesIO()\n",
        "        image.save(buffered, format=\"JPEG\", quality=92, optimize=True)\n",
        "        return base64.b64encode(buffered.getvalue()).decode()\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Optimized image encoding failed: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def parse_optimized_response(response, page_number: int) -> List[Dict]:\n",
        "    \"\"\"Optimized response parsing\"\"\"\n",
        "    try:\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        if content.startswith('```json'):\n",
        "            content = content[7:]\n",
        "        if content.endswith('```'):\n",
        "            content = content[:-3]\n",
        "        content = content.strip()\n",
        "\n",
        "        if not content.startswith('['):\n",
        "            return []\n",
        "\n",
        "        result = json.loads(content)\n",
        "        if not isinstance(result, list):\n",
        "            return []\n",
        "\n",
        "        validated_kpis = []\n",
        "        for item in result:\n",
        "            if (isinstance(item, dict) and\n",
        "                item.get('kpi_text', '').strip() and\n",
        "                item.get('quantitative_value', '').strip()):\n",
        "\n",
        "                kpi = {\n",
        "                    'kpi_text': item.get('kpi_text', '').strip(),\n",
        "                    'quantitative_value': str(item.get('quantitative_value', '')).strip(),\n",
        "                    'unit': item.get('unit', '').strip(),\n",
        "                    'kpi_theme': item.get('kpi_theme', 'Environmental').strip(),\n",
        "                    'kpi_category': item.get('kpi_category', '').strip(),\n",
        "                    'time_period': item.get('time_period', '').strip(),\n",
        "                    'source_page': page_number,\n",
        "                    'source_type': 'image'\n",
        "                }\n",
        "                validated_kpis.append(kpi)\n",
        "\n",
        "        return validated_kpis\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Optimized response parsing failed: {e}\")\n",
        "        return []\n",
        "\n",
        "# 4. Parallel image processing\n",
        "def process_images_in_parallel(image_data: List[Dict], max_workers: int = 3) -> List[Dict]:\n",
        "    \"\"\"Parallel image processing\"\"\"\n",
        "    if not image_data:\n",
        "        return []\n",
        "\n",
        "    print(f\"🔄 Processing {len(image_data)} images in parallel...\")\n",
        "\n",
        "    all_kpis = []\n",
        "    completed_count = 0\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_info = {}\n",
        "        for img_info in image_data:\n",
        "            future = executor.submit(\n",
        "                extract_kpi_optimized,\n",
        "                img_info['image'],\n",
        "                img_info['page_number']\n",
        "            )\n",
        "            future_to_info[future] = img_info\n",
        "\n",
        "        for future in concurrent.futures.as_completed(future_to_info):\n",
        "            img_info = future_to_info[future]\n",
        "            try:\n",
        "                kpis = future.result(timeout=90)\n",
        "                all_kpis.extend(kpis)\n",
        "                completed_count += 1\n",
        "\n",
        "                if completed_count % 5 == 0:\n",
        "                    progress = completed_count / len(image_data) * 100\n",
        "                    print(f\"   📈 Progress: {completed_count}/{len(image_data)} ({progress:.1f}%)\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.warning(f\"Image processing failed for page {img_info['page_number']}: {e}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"📊 Parallel processing completed: {len(all_kpis)} KPIs extracted\")\n",
        "    print(f\"📋 {fast_cache.get_stats()}\")\n",
        "\n",
        "    return all_kpis"
      ],
      "metadata": {
        "id": "7j4_GQ6Llw8e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "N7yh-bSwZonF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239f0b3b-faa7-43c4-d715-4e7869c5ba09"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Main processing function ============\n",
        "def process_sustainability_report_with_enhanced_images(pdf_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Main processing function with image analysis\"\"\"\n",
        "    logging.info(\"Starting enhanced PDF processing with image analysis...\")\n",
        "\n",
        "    # Step 1: Text and table extraction\n",
        "    logging.info(\"Step 1/5: Reading PDF text and tables...\")\n",
        "    full_text = pdf_to_text_and_tables(pdf_path)\n",
        "\n",
        "    camelot_tables = camelot_extra_tables_enhanced(pdf_path)\n",
        "    if camelot_tables:\n",
        "        full_text += \"\\n\\n\" + \"\\n\\n\".join(camelot_tables)\n",
        "\n",
        "    logging.info(\"Step 2/5: Chunking text...\")\n",
        "    chunks = split_into_chunks(full_text, MAX_TOKENS_CHUNK)\n",
        "\n",
        "    logging.info(\"Step 3/5: Extracting KPIs from text...\")\n",
        "    text_kpis = []\n",
        "    for idx, chunk in enumerate(chunks, 1):\n",
        "        logging.info(f\"Processing text chunk {idx}/{len(chunks)}\")\n",
        "        if chunk.strip():\n",
        "            chunk_kpis = extract_kpi_from_chunk_universal(chunk)\n",
        "            text_kpis.extend(chunk_kpis)\n",
        "            if idx < len(chunks):\n",
        "                time.sleep(SLEEP_SEC)\n",
        "\n",
        "    # Step 4: Image KPI extraction\n",
        "    logging.info(\"Step 4/5: Extracting KPIs from images...\")\n",
        "    image_kpis = process_pdf_images_for_kpis_fixed(pdf_path)\n",
        "\n",
        "    # Step 5: Combine and process\n",
        "    logging.info(\"Step 5/5: Combining and processing all KPIs...\")\n",
        "\n",
        "    for kpi in text_kpis:\n",
        "        if 'source_type' not in kpi:\n",
        "            kpi['source_type'] = 'text'\n",
        "\n",
        "    all_kpis = text_kpis + image_kpis\n",
        "    all_kpis = post_process_kpis_universal(all_kpis)\n",
        "\n",
        "    df_auto = pd.DataFrame(all_kpis)\n",
        "\n",
        "    if not df_auto.empty:\n",
        "        if 'source_type' not in df_auto.columns:\n",
        "            df_auto['source_type'] = 'text'\n",
        "\n",
        "        initial_count = len(df_auto)\n",
        "        df_auto = df_auto.drop_duplicates(subset=['kpi_text'], keep='first')\n",
        "        final_count = len(df_auto)\n",
        "\n",
        "        logging.info(f\"Removed {initial_count - final_count} duplicate KPIs\")\n",
        "\n",
        "        try:\n",
        "            df_auto = df_auto.sort_values(['source_type', 'kpi_theme', 'kpi_category'], na_position='last')\n",
        "        except KeyError:\n",
        "            pass\n",
        "\n",
        "        text_kpi_count = len([kpi for kpi in all_kpis if kpi.get('source_type', 'text') != 'image'])\n",
        "        image_kpi_count = len([kpi for kpi in all_kpis if kpi.get('source_type') == 'image'])\n",
        "\n",
        "        logging.info(f\"KPI Summary: {text_kpi_count} from text/tables, {image_kpi_count} from images\")\n",
        "\n",
        "    return df_auto\n"
      ],
      "metadata": {
        "id": "Mr1OIB2BZosj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Optimize moderator processing function ============\n",
        "def process_sustainability_report_OPTIMIZED(pdf_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Optimize moderator processing functions - improve performance while ensuring integrity\"\"\"\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(\"⚡ Starting OPTIMIZED processing with completeness guarantee...\")\n",
        "\n",
        "    try:\n",
        "        # Parallel text and image preprocessing\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
        "            print(\"🔄 Starting parallel text and image preprocessing...\")\n",
        "\n",
        "            # Text processing (using your existing logic)\n",
        "            def extract_text_kpis():\n",
        "                full_text = pdf_to_text_and_tables(pdf_path)\n",
        "                camelot_tables = camelot_extra_tables_enhanced(pdf_path)\n",
        "                if camelot_tables:\n",
        "                    full_text += \"\\n\\n\" + \"\\n\\n\".join(camelot_tables)\n",
        "\n",
        "                chunks = split_into_chunks(full_text, MAX_TOKENS_CHUNK)\n",
        "                text_kpis = []\n",
        "                for idx, chunk in enumerate(chunks, 1):\n",
        "                    if chunk.strip():\n",
        "                        chunk_kpis = extract_kpi_from_chunk_universal(chunk)\n",
        "                        text_kpis.extend(chunk_kpis)\n",
        "                        if idx < len(chunks):\n",
        "                            time.sleep(SLEEP_SEC)\n",
        "                return text_kpis\n",
        "\n",
        "            #Image preprocessing (using optimized filtering)\n",
        "            def extract_and_filter_images():\n",
        "                all_images = extract_images_from_pdf_fixed(pdf_path)\n",
        "                filtered_images = []\n",
        "\n",
        "                for img_info in all_images:\n",
        "                    should_process, reason = conservative_image_filter(img_info['image'])\n",
        "                    if should_process:\n",
        "                        filtered_images.append(img_info)\n",
        "\n",
        "                print(f\"📊 Conservative filtering: Kept {len(filtered_images)}/{len(all_images)} images\")\n",
        "                return filtered_images\n",
        "\n",
        "            text_future = executor.submit(extract_text_kpis)\n",
        "            image_future = executor.submit(extract_and_filter_images)\n",
        "\n",
        "            text_kpis = text_future.result()\n",
        "            image_data = image_future.result()\n",
        "\n",
        "        preprocessing_time = time.time() - start_time\n",
        "        print(f\"⏱️  Preprocessing completed in {preprocessing_time:.1f}s\")\n",
        "\n",
        "        # Parallel Image KPI Extraction\n",
        "        image_start = time.time()\n",
        "        image_kpis = process_images_in_parallel(image_data, max_workers=3)\n",
        "        image_time = time.time() - image_start\n",
        "        print(f\"⏱️  Image processing completed in {image_time:.1f}s\")\n",
        "\n",
        "        # Post-processing\n",
        "        all_kpis = text_kpis + image_kpis\n",
        "        all_kpis = post_process_kpis_universal(all_kpis)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df_auto = pd.DataFrame(all_kpis)\n",
        "\n",
        "        if not df_auto.empty:\n",
        "            initial_count = len(df_auto)\n",
        "            df_auto = df_auto.drop_duplicates(subset=['kpi_text'], keep='first')\n",
        "            final_count = len(df_auto)\n",
        "\n",
        "            if 'source_type' not in df_auto.columns:\n",
        "                df_auto['source_type'] = 'text'\n",
        "\n",
        "            print(f\"🔄 Removed {initial_count - final_count} exact duplicates\")\n",
        "\n",
        "        # Performance Statistics\n",
        "        total_time = time.time() - start_time\n",
        "        text_count = len([k for k in all_kpis if k.get('source_type') != 'image'])\n",
        "        image_count = len([k for k in all_kpis if k.get('source_type') == 'image'])\n",
        "\n",
        "        print(f\"\\n⚡ OPTIMIZED processing completed!\")\n",
        "        print(f\"⏱️  Total time: {total_time:.1f}s ({total_time/60:.1f}min)\")\n",
        "        print(f\"📊 Results:\")\n",
        "        print(f\"   - Text/Tables: {text_count} KPIs\")\n",
        "        print(f\"   - Images/Charts: {image_count} KPIs\")\n",
        "        print(f\"   - Total unique: {len(df_auto)} KPIs\")\n",
        "        print(f\"⚡ Performance: {len(df_auto)/total_time:.1f} KPIs/second\")\n",
        "\n",
        "        return df_auto\n",
        "\n",
        "    except Exception as e:\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"❌ Optimized processing failed after {total_time:.1f}s: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return pd.DataFrame()"
      ],
      "metadata": {
        "id": "YWPKhJAPmHg7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Result saving and comparison functions ============\n",
        "def infer_stakeholder(row) -> str:\n",
        "    \"\"\"Infer affected stakeholders based on KPI theme and category\"\"\"\n",
        "    theme = row.get('kpi_theme', '').lower()\n",
        "    category = row.get('kpi_category', '').lower()\n",
        "    kpi_text = row.get('kpi_text', '').lower()\n",
        "\n",
        "    if theme == 'environmental':\n",
        "        return \"Environment, Community, Future Generations\"\n",
        "    elif theme == 'social':\n",
        "        if 'employee' in category or 'workforce' in category or 'gender' in category:\n",
        "            return \"Employees\"\n",
        "        elif 'customer' in category or 'safety' in category:\n",
        "            return \"Customers, Community\"\n",
        "        elif 'community' in category:\n",
        "            return \"Local Communities\"\n",
        "        elif 'supply' in category or 'supplier' in kpi_text:\n",
        "            return \"Suppliers, Business Partners\"\n",
        "        else:\n",
        "            return \"Employees, Community\"\n",
        "    elif theme == 'governance':\n",
        "        if 'board' in category:\n",
        "            return \"Shareholders, Investors\"\n",
        "        elif 'cyber' in category or 'data' in category:\n",
        "            return \"Customers, Employees, Business Partners\"\n",
        "        else:\n",
        "            return \"Shareholders, Investors, Stakeholders\"\n",
        "    else:\n",
        "        return \"All Stakeholders\"\n",
        "\n",
        "def save_results(df_auto: pd.DataFrame, output_path: str, pdf_path: str = \"\") -> None:\n",
        "    \"\"\"Save results to Excel file with proper formatting\"\"\"\n",
        "    try:\n",
        "        os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
        "\n",
        "        if not df_auto.empty:\n",
        "            # Add metadata columns\n",
        "            pdf_filename = os.path.basename(pdf_path) if pdf_path else \"Unknown\"\n",
        "            df_auto['PDF file name'] = pdf_filename\n",
        "            df_auto['Title of the report'] = \"\"\n",
        "\n",
        "            if 'source_page' in df_auto.columns:\n",
        "                df_auto['Absolute Page Number'] = df_auto['source_page']\n",
        "                df_auto = df_auto.drop('source_page', axis=1)\n",
        "            else:\n",
        "                df_auto['Absolute Page Number'] = \"Unknown\"\n",
        "\n",
        "            df_auto['Impacted Stakeholder'] = df_auto.apply(infer_stakeholder, axis=1)\n",
        "\n",
        "            # Reorder columns\n",
        "            original_columns = [col for col in df_auto.columns if col not in\n",
        "                              ['PDF file name', 'Title of the report', 'Absolute Page Number', 'Impacted Stakeholder']]\n",
        "            new_column_order = ['PDF file name', 'Title of the report', 'Absolute Page Number', 'Impacted Stakeholder'] + original_columns\n",
        "            df_auto = df_auto[new_column_order]\n",
        "\n",
        "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
        "            df_auto.to_excel(writer, sheet_name='Auto_KPIs', index=False)\n",
        "\n",
        "            if not df_auto.empty:\n",
        "                # Theme summary\n",
        "                theme_summary = df_auto.groupby('kpi_theme').size().reset_index(name='count')\n",
        "                theme_summary.to_excel(writer, sheet_name='Theme_Summary', index=False)\n",
        "\n",
        "                # Category summary\n",
        "                category_summary = df_auto.groupby(['kpi_theme', 'kpi_category']).size().reset_index(name='count')\n",
        "                category_summary.to_excel(writer, sheet_name='Category_Summary', index=False)\n",
        "\n",
        "        logging.info(f\"Results saved to {output_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error saving results: {e}\")"
      ],
      "metadata": {
        "id": "kucPzNTdZouV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Main execution function ============\n",
        "def main():\n",
        "    \"\"\"Enhanced main execution function with validation\"\"\"\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s - %(levelname)s: %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        if not os.path.exists(PDF_PATH):\n",
        "            logging.error(f\"PDF file not found: {PDF_PATH}\")\n",
        "            return\n",
        "\n",
        "        # Process the PDF\n",
        "        df_auto = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "\n",
        "        # Save results\n",
        "        save_results(df_auto, EXPORT_AUTO_XLSX, PDF_PATH)\n",
        "        logging.info(f\"KPI extraction completed: {len(df_auto)} KPIs extracted\")\n",
        "\n",
        "        # Enhanced validation with comprehensive analysis\n",
        "        if MANUAL_XLSX and Path(MANUAL_XLSX).exists():\n",
        "            print(\"\\n🔍 Running comprehensive validation...\")\n",
        "            validation_results = enhanced_compare_with_manual_kpis(\n",
        "                df_auto, MANUAL_XLSX, \"comprehensive_validation\"\n",
        "            )\n",
        "\n",
        "            if validation_results:\n",
        "                print(\"✅ Validation completed with detailed analysis!\")\n",
        "                print(f\"📁 Detailed results saved to: comprehensive_validation/\")\n",
        "            else:\n",
        "                print(\"⚠️ Validation encountered issues\")\n",
        "        else:\n",
        "            logging.info(\"Manual KPI file not found, skipping validation.\")\n",
        "\n",
        "        # Display summary\n",
        "        if not df_auto.empty:\n",
        "            print(f\"\\n=== Extraction Summary ===\")\n",
        "            print(f\"Total KPIs extracted: {len(df_auto)}\")\n",
        "\n",
        "            # Source statistics\n",
        "            if 'source_type' in df_auto.columns:\n",
        "                source_counts = df_auto['source_type'].value_counts()\n",
        "                print(f\"From text/tables: {source_counts.get('text', 0)}\")\n",
        "                print(f\"From images/charts: {source_counts.get('image', 0)}\")\n",
        "\n",
        "            # Theme statistics\n",
        "            if 'kpi_theme' in df_auto.columns:\n",
        "                theme_counts = df_auto['kpi_theme'].value_counts()\n",
        "                print(f\"\\nKPI Distribution by Theme:\")\n",
        "                for theme, count in theme_counts.items():\n",
        "                    print(f\"  {theme}: {count}\")\n",
        "        else:\n",
        "            print(\"\\nNo KPIs were extracted from the document.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in main execution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "uSueutkDZowK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Auxiliary functions ============\n",
        "def install_dependencies():\n",
        "    \"\"\"Install required dependencies\"\"\"\n",
        "    try:\n",
        "        import subprocess\n",
        "        import sys\n",
        "\n",
        "        dependencies = [\n",
        "            \"openai\",\n",
        "            \"python-dotenv\",\n",
        "            \"pdfplumber\",\n",
        "            \"tiktoken\",\n",
        "            \"pandas\",\n",
        "            \"PyMuPDF\",\n",
        "            \"Pillow\",\n",
        "            \"openpyxl\"\n",
        "        ]\n",
        "\n",
        "        for dep in dependencies:\n",
        "            try:\n",
        "                __import__(dep.replace('-', '_'))\n",
        "                print(f\"✅ {dep} is already installed\")\n",
        "            except ImportError:\n",
        "                print(f\"Installing {dep}...\")\n",
        "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", dep])\n",
        "                print(f\"✅ Installed {dep}\")\n",
        "\n",
        "        # Optional Camelot installation\n",
        "        try:\n",
        "            import camelot\n",
        "            print(\"✅ Camelot is already installed\")\n",
        "        except ImportError:\n",
        "            print(\"Installing Camelot (optional)...\")\n",
        "            try:\n",
        "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"camelot-py[cv]\"])\n",
        "                print(\"✅ Installed Camelot\")\n",
        "            except:\n",
        "                print(\"⚠️ Camelot installation failed (optional dependency)\")\n",
        "\n",
        "        print(\"🎉 All dependencies checked/installed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error with dependencies: {e}\")\n",
        "\n",
        "def validate_environment():\n",
        "    \"\"\"Validate environment setup\"\"\"\n",
        "    issues = []\n",
        "\n",
        "    # Check API key\n",
        "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "        issues.append(\"OPENAI_API_KEY not found in environment variables\")\n",
        "\n",
        "    # Check PDF file\n",
        "    if not os.path.exists(PDF_PATH):\n",
        "        issues.append(f\"PDF file not found: {PDF_PATH}\")\n",
        "\n",
        "    # Check required imports\n",
        "    required_modules = ['openai', 'pdfplumber', 'pandas', 'tiktoken', 'PIL', 'fitz']\n",
        "    for module in required_modules:\n",
        "        try:\n",
        "            __import__(module)\n",
        "        except ImportError:\n",
        "            issues.append(f\"Required module '{module}' not installed\")\n",
        "\n",
        "    if issues:\n",
        "        print(\"❌ Environment validation failed:\")\n",
        "        for issue in issues:\n",
        "            print(f\"  - {issue}\")\n",
        "        return False\n",
        "    else:\n",
        "        print(\"✅ Environment validation passed\")\n",
        "        return True\n"
      ],
      "metadata": {
        "id": "qcCShhlea6ZK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Simplified execution interface ============\n",
        "def run_kpi_extraction():\n",
        "    \"\"\"Simplified interface to run KPI extraction\"\"\"\n",
        "    print(\"🚀 Starting KPI extraction process...\")\n",
        "\n",
        "    # Validate environment\n",
        "    if not validate_environment():\n",
        "        print(\"Please fix the environment issues before running.\")\n",
        "        return\n",
        "\n",
        "    # Run main function\n",
        "    main()"
      ],
      "metadata": {
        "id": "Qw6B5H8ga6bl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Optimized execution interface ============\n",
        "def run_optimized_kpi_extraction():\n",
        "    \"\"\"Run optimized KPI extraction\"\"\"\n",
        "    print(\"⚡ Starting OPTIMIZED KPI extraction...\")\n",
        "    print(\"🎯 Goal: Extract ALL KPIs with 60-70% better performance\")\n",
        "\n",
        "    # Verify the environment\n",
        "    if not validate_environment():\n",
        "        print(\"Please fix the environment issues before running.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Run optimization process\n",
        "        df_results = process_sustainability_report_OPTIMIZED(PDF_PATH)\n",
        "\n",
        "        # Save the results\n",
        "        output_file = \"OPTIMIZED_\" + EXPORT_AUTO_XLSX\n",
        "        save_results(df_results, output_file, PDF_PATH)\n",
        "        print(f\"💾 Results saved to: {output_file}\")\n",
        "\n",
        "        # Show Statistics\n",
        "        if not df_results.empty and 'source_type' in df_results.columns:\n",
        "            source_counts = df_results['source_type'].value_counts()\n",
        "            print(f\"\\n📈 Final Statistics:\")\n",
        "            for source, count in source_counts.items():\n",
        "                print(f\"   - {source}: {count} KPIs\")\n",
        "\n",
        "        return df_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Optimized extraction failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def compare_original_vs_optimized():\n",
        "    \"\"\"Compare the performance of the original version and the optimized version\"\"\"\n",
        "    print(\"🔬 Performance Comparison Test\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Test the original version\n",
        "    print(\"\\n📊 Testing Original Version...\")\n",
        "    original_start = time.time()\n",
        "    try:\n",
        "        original_df = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "        original_time = time.time() - original_start\n",
        "        print(f\"⏱️  Original version: {original_time:.1f}s, {len(original_df)} KPIs\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Original version failed: {e}\")\n",
        "        original_time = 999\n",
        "        original_df = pd.DataFrame()\n",
        "\n",
        "    # Test optimized version\n",
        "    print(\"\\n⚡ Testing Optimized Version...\")\n",
        "    optimized_start = time.time()\n",
        "    try:\n",
        "        optimized_df = process_sustainability_report_OPTIMIZED(PDF_PATH)\n",
        "        optimized_time = time.time() - optimized_start\n",
        "        print(f\"⏱️  Optimized version: {optimized_time:.1f}s, {len(optimized_df)} KPIs\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Optimized version failed: {e}\")\n",
        "        optimized_time = 999\n",
        "        optimized_df = pd.DataFrame()\n",
        "\n",
        "    # Performance comparison\n",
        "    if original_time < 999 and optimized_time < 999:\n",
        "        speedup = original_time / optimized_time\n",
        "        time_saved = original_time - optimized_time\n",
        "        kpi_diff = abs(len(optimized_df) - len(original_df))\n",
        "\n",
        "        print(f\"\\n🚀 Performance Results:\")\n",
        "        print(f\"   - Speed improvement: {speedup:.1f}x faster\")\n",
        "        print(f\"   - Time saved: {time_saved:.1f}s ({time_saved/60:.1f}min)\")\n",
        "        print(f\"   - KPI difference: {kpi_diff} KPIs\")\n",
        "        print(f\"   - Completeness: {len(optimized_df)/len(original_df)*100:.1f}% of original\" if len(original_df) > 0 else \"\")\n",
        "\n",
        "        return {\"original\": original_df, \"optimized\": optimized_df, \"speedup\": speedup}\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "aJrVHLTgmPJw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KPIValidationPipeline:\n",
        "    \"\"\"Comprehensive KPI validation and evaluation system\"\"\"\n",
        "\n",
        "    def __init__(self, manual_excel_path: str, auto_excel_path: str,\n",
        "                 output_dir: str = \"validation_results\"):\n",
        "        \"\"\"\n",
        "        Initialize validation pipeline\n",
        "\n",
        "        Args:\n",
        "            manual_excel_path: Path to manual KPI annotations\n",
        "            auto_excel_path: Path to automatically extracted KPIs\n",
        "            output_dir: Directory to save validation results\n",
        "        \"\"\"\n",
        "        self.manual_path = manual_excel_path\n",
        "        self.auto_path = auto_excel_path\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Load data\n",
        "        self.manual_df = self._load_excel_safe(manual_excel_path, \"manual\")\n",
        "        self.auto_df = self._load_excel_safe(auto_excel_path, \"auto\")\n",
        "\n",
        "        # Validation results\n",
        "        self.validation_results = {}\n",
        "        self.detailed_analysis = {}\n",
        "\n",
        "        # Similarity thresholds\n",
        "        self.similarity_thresholds = {\n",
        "            'exact': 1.0,\n",
        "            'high': 0.9,\n",
        "            'medium': 0.7,\n",
        "            'low': 0.5\n",
        "        }\n",
        "\n",
        "        logging.info(f\"Validation pipeline initialized:\")\n",
        "        logging.info(f\"  Manual KPIs: {len(self.manual_df)}\")\n",
        "        logging.info(f\"  Auto KPIs: {len(self.auto_df)}\")\n",
        "\n",
        "    def _load_excel_safe(self, filepath: str, source_type: str) -> pd.DataFrame:\n",
        "        \"\"\"Safely load Excel file with error handling\"\"\"\n",
        "        try:\n",
        "            if not Path(filepath).exists():\n",
        "                logging.warning(f\"{source_type.title()} file not found: {filepath}\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            df = pd.read_excel(filepath)\n",
        "            logging.info(f\"Loaded {source_type} file: {len(df)} rows\")\n",
        "\n",
        "            # Standardize column names\n",
        "            df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "            # Ensure required columns exist\n",
        "            required_cols = ['kpi_text']\n",
        "            for col in required_cols:\n",
        "                if col not in df.columns:\n",
        "                    # Try to find similar column names\n",
        "                    similar_cols = [c for c in df.columns if 'kpi' in c.lower() or 'text' in c.lower()]\n",
        "                    if similar_cols:\n",
        "                        df['kpi_text'] = df[similar_cols[0]]\n",
        "                        logging.info(f\"Using column '{similar_cols[0]}' as kpi_text\")\n",
        "                    else:\n",
        "                        logging.warning(f\"Required column '{col}' not found in {source_type} file\")\n",
        "                        df['kpi_text'] = \"\"\n",
        "\n",
        "            # Clean text data\n",
        "            df['kpi_text'] = df['kpi_text'].astype(str).str.strip()\n",
        "            df = df[df['kpi_text'] != ''].reset_index(drop=True)\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error loading {source_type} file: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def normalize_text(self, text: str) -> str:\n",
        "        \"\"\"Normalize text for comparison\"\"\"\n",
        "        if pd.isna(text) or text == '':\n",
        "            return \"\"\n",
        "\n",
        "        # Convert to string and lowercase\n",
        "        text = str(text).lower().strip()\n",
        "\n",
        "        # Remove extra whitespace\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        # Remove common punctuation but keep percentages and numbers\n",
        "        text = re.sub(r'[^\\w\\s\\%\\.\\,\\-]', ' ', text)\n",
        "\n",
        "        # Normalize number formats\n",
        "        text = re.sub(r'\\b(\\d+),(\\d+)\\b', r'\\1\\2', text)  # Remove commas in numbers\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Normalize spaces\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    def calculate_text_similarity(self, text1: str, text2: str) -> Dict[str, float]:\n",
        "        \"\"\"Calculate multiple similarity metrics between two texts\"\"\"\n",
        "        norm1 = self.normalize_text(text1)\n",
        "        norm2 = self.normalize_text(text2)\n",
        "\n",
        "        if not norm1 or not norm2:\n",
        "            return {'sequence': 0.0, 'cosine': 0.0, 'jaccard': 0.0, 'combined': 0.0}\n",
        "\n",
        "        # 1. Sequence similarity (exact match)\n",
        "        sequence_sim = SequenceMatcher(None, norm1, norm2).ratio()\n",
        "\n",
        "        # 2. Cosine similarity (semantic)\n",
        "        try:\n",
        "            vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1)\n",
        "            tfidf_matrix = vectorizer.fit_transform([norm1, norm2])\n",
        "            cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "        except:\n",
        "            cosine_sim = 0.0\n",
        "\n",
        "        # 3. Jaccard similarity (token overlap)\n",
        "        tokens1 = set(norm1.split())\n",
        "        tokens2 = set(norm2.split())\n",
        "        if tokens1 or tokens2:\n",
        "            jaccard_sim = len(tokens1.intersection(tokens2)) / len(tokens1.union(tokens2))\n",
        "        else:\n",
        "            jaccard_sim = 0.0\n",
        "\n",
        "        # 4. Combined similarity\n",
        "        combined_sim = (sequence_sim * 0.4 + cosine_sim * 0.4 + jaccard_sim * 0.2)\n",
        "\n",
        "        return {\n",
        "            'sequence': sequence_sim,\n",
        "            'cosine': cosine_sim,\n",
        "            'jaccard': jaccard_sim,\n",
        "            'combined': combined_sim\n",
        "        }\n",
        "\n",
        "    def find_matches(self, threshold: float = 0.7, similarity_type: str = 'combined') -> pd.DataFrame:\n",
        "        \"\"\"Find matches between manual and auto KPIs\"\"\"\n",
        "        matches = []\n",
        "        auto_matched = set()\n",
        "\n",
        "        for manual_idx, manual_row in self.manual_df.iterrows():\n",
        "            manual_text = manual_row['kpi_text']\n",
        "            best_match = None\n",
        "            best_similarity = 0.0\n",
        "\n",
        "            for auto_idx, auto_row in self.auto_df.iterrows():\n",
        "                if auto_idx in auto_matched:\n",
        "                    continue\n",
        "\n",
        "                auto_text = auto_row['kpi_text']\n",
        "                similarities = self.calculate_text_similarity(manual_text, auto_text)\n",
        "                similarity = similarities[similarity_type]\n",
        "\n",
        "                if similarity > best_similarity and similarity >= threshold:\n",
        "                    best_similarity = similarity\n",
        "                    best_match = {\n",
        "                        'manual_idx': manual_idx,\n",
        "                        'auto_idx': auto_idx,\n",
        "                        'manual_text': manual_text,\n",
        "                        'auto_text': auto_text,\n",
        "                        'similarity': similarity,\n",
        "                        'all_similarities': similarities\n",
        "                    }\n",
        "\n",
        "            if best_match:\n",
        "                matches.append(best_match)\n",
        "                auto_matched.add(best_match['auto_idx'])\n",
        "\n",
        "        return pd.DataFrame(matches)\n",
        "\n",
        "    def calculate_metrics_at_threshold(self, threshold: float = 0.7,\n",
        "                                     similarity_type: str = 'combined') -> Dict[str, float]:\n",
        "        \"\"\"Calculate precision, recall, F1 at specific threshold\"\"\"\n",
        "        matches_df = self.find_matches(threshold, similarity_type)\n",
        "\n",
        "        true_positives = len(matches_df)\n",
        "        false_positives = len(self.auto_df) - true_positives\n",
        "        false_negatives = len(self.manual_df) - true_positives\n",
        "\n",
        "        # Calculate metrics\n",
        "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
        "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "        return {\n",
        "            'threshold': threshold,\n",
        "            'similarity_type': similarity_type,\n",
        "            'true_positives': true_positives,\n",
        "            'false_positives': false_positives,\n",
        "            'false_negatives': false_negatives,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1_score,\n",
        "            'total_manual': len(self.manual_df),\n",
        "            'total_auto': len(self.auto_df),\n",
        "            'match_rate': true_positives / len(self.manual_df) if len(self.manual_df) > 0 else 0.0\n",
        "        }\n",
        "\n",
        "    def run_comprehensive_evaluation(self) -> Dict[str, any]:\n",
        "        \"\"\"Run comprehensive evaluation across multiple thresholds and similarity types\"\"\"\n",
        "        logging.info(\"Running comprehensive evaluation...\")\n",
        "\n",
        "        results = {\n",
        "            'threshold_analysis': [],\n",
        "            'similarity_type_analysis': [],\n",
        "            'category_analysis': {},\n",
        "            'detailed_matches': {},\n",
        "            'false_positives': [],\n",
        "            'false_negatives': []\n",
        "        }\n",
        "\n",
        "        # 1. Threshold analysis\n",
        "        thresholds = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "        similarity_types = ['combined', 'sequence', 'cosine', 'jaccard']\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            for sim_type in similarity_types:\n",
        "                metrics = self.calculate_metrics_at_threshold(threshold, sim_type)\n",
        "                results['threshold_analysis'].append(metrics)\n",
        "\n",
        "        # 2. Find optimal threshold\n",
        "        best_f1 = 0.0\n",
        "        best_config = None\n",
        "        for metrics in results['threshold_analysis']:\n",
        "            if metrics['f1_score'] > best_f1:\n",
        "                best_f1 = metrics['f1_score']\n",
        "                best_config = (metrics['threshold'], metrics['similarity_type'])\n",
        "\n",
        "        # 3. Detailed analysis at optimal threshold\n",
        "        if best_config:\n",
        "            optimal_threshold, optimal_sim_type = best_config\n",
        "            logging.info(f\"Optimal configuration: threshold={optimal_threshold}, similarity={optimal_sim_type}\")\n",
        "\n",
        "            matches_df = self.find_matches(optimal_threshold, optimal_sim_type)\n",
        "            results['detailed_matches'] = matches_df.to_dict('records')\n",
        "\n",
        "            # Find false positives and false negatives\n",
        "            matched_auto_indices = set(matches_df['auto_idx'].tolist()) if not matches_df.empty else set()\n",
        "            matched_manual_indices = set(matches_df['manual_idx'].tolist()) if not matches_df.empty else set()\n",
        "\n",
        "            # False positives (auto KPIs not matched to manual)\n",
        "            fp_indices = set(range(len(self.auto_df))) - matched_auto_indices\n",
        "            results['false_positives'] = [\n",
        "                {\n",
        "                    'index': idx,\n",
        "                    'kpi_text': self.auto_df.iloc[idx]['kpi_text'],\n",
        "                    'category': self.auto_df.iloc[idx].get('kpi_category', 'Unknown'),\n",
        "                    'theme': self.auto_df.iloc[idx].get('kpi_theme', 'Unknown'),\n",
        "                    'source': self.auto_df.iloc[idx].get('source_type', 'Unknown')\n",
        "                }\n",
        "                for idx in fp_indices\n",
        "            ]\n",
        "\n",
        "            # False negatives (manual KPIs not matched by auto)\n",
        "            fn_indices = set(range(len(self.manual_df))) - matched_manual_indices\n",
        "            results['false_negatives'] = [\n",
        "                {\n",
        "                    'index': idx,\n",
        "                    'kpi_text': self.manual_df.iloc[idx]['kpi_text'],\n",
        "                    'category': self.manual_df.iloc[idx].get('kpi_category', 'Unknown'),\n",
        "                    'theme': self.manual_df.iloc[idx].get('kpi_theme', 'Unknown')\n",
        "                }\n",
        "                for idx in fn_indices\n",
        "            ]\n",
        "\n",
        "        # 4. Category-level analysis\n",
        "        if 'kpi_category' in self.manual_df.columns and 'kpi_category' in self.auto_df.columns:\n",
        "            results['category_analysis'] = self._analyze_by_category()\n",
        "\n",
        "        # 5. Theme-level analysis\n",
        "        if 'kpi_theme' in self.manual_df.columns and 'kpi_theme' in self.auto_df.columns:\n",
        "            results['theme_analysis'] = self._analyze_by_theme()\n",
        "\n",
        "        self.validation_results = results\n",
        "        return results\n",
        "\n",
        "    def _analyze_by_category(self) -> Dict[str, Dict]:\n",
        "        \"\"\"Analyze performance by KPI category\"\"\"\n",
        "        category_results = {}\n",
        "\n",
        "        manual_categories = self.manual_df['kpi_category'].value_counts()\n",
        "        auto_categories = self.auto_df['kpi_category'].value_counts()\n",
        "\n",
        "        all_categories = set(manual_categories.index) | set(auto_categories.index)\n",
        "\n",
        "        for category in all_categories:\n",
        "            manual_count = manual_categories.get(category, 0)\n",
        "            auto_count = auto_categories.get(category, 0)\n",
        "\n",
        "            # Find matches within this category\n",
        "            manual_cat_df = self.manual_df[self.manual_df['kpi_category'] == category]\n",
        "            auto_cat_df = self.auto_df[self.auto_df['kpi_category'] == category]\n",
        "\n",
        "            category_matches = 0\n",
        "            if not manual_cat_df.empty and not auto_cat_df.empty:\n",
        "                for _, manual_row in manual_cat_df.iterrows():\n",
        "                    best_sim = 0.0\n",
        "                    for _, auto_row in auto_cat_df.iterrows():\n",
        "                        sim = self.calculate_text_similarity(\n",
        "                            manual_row['kpi_text'],\n",
        "                            auto_row['kpi_text']\n",
        "                        )['combined']\n",
        "                        best_sim = max(best_sim, sim)\n",
        "                    if best_sim >= 0.7:\n",
        "                        category_matches += 1\n",
        "\n",
        "            category_precision = category_matches / auto_count if auto_count > 0 else 0.0\n",
        "            category_recall = category_matches / manual_count if manual_count > 0 else 0.0\n",
        "            category_f1 = 2 * (category_precision * category_recall) / (category_precision + category_recall) if (category_precision + category_recall) > 0 else 0.0\n",
        "\n",
        "            category_results[category] = {\n",
        "                'manual_count': manual_count,\n",
        "                'auto_count': auto_count,\n",
        "                'matches': category_matches,\n",
        "                'precision': category_precision,\n",
        "                'recall': category_recall,\n",
        "                'f1_score': category_f1\n",
        "            }\n",
        "\n",
        "        return category_results\n",
        "\n",
        "    def _analyze_by_theme(self) -> Dict[str, Dict]:\n",
        "        \"\"\"Analyze performance by KPI theme\"\"\"\n",
        "        theme_results = {}\n",
        "\n",
        "        manual_themes = self.manual_df['kpi_theme'].value_counts()\n",
        "        auto_themes = self.auto_df['kpi_theme'].value_counts()\n",
        "\n",
        "        all_themes = set(manual_themes.index) | set(auto_themes.index)\n",
        "\n",
        "        for theme in all_themes:\n",
        "            manual_count = manual_themes.get(theme, 0)\n",
        "            auto_count = auto_themes.get(theme, 0)\n",
        "\n",
        "            theme_results[theme] = {\n",
        "                'manual_count': manual_count,\n",
        "                'auto_count': auto_count,\n",
        "                'coverage': auto_count / manual_count if manual_count > 0 else 0.0\n",
        "            }\n",
        "\n",
        "        return theme_results\n",
        "\n",
        "    def generate_visualizations(self):\n",
        "        \"\"\"Generate comprehensive visualizations\"\"\"\n",
        "        if not self.validation_results:\n",
        "            logging.warning(\"No validation results found. Run evaluation first.\")\n",
        "            return\n",
        "\n",
        "        # Set style\n",
        "        try:\n",
        "            plt.style.use('seaborn-v0_8')\n",
        "        except:\n",
        "            plt.style.use('seaborn')  # 备用样式\n",
        "        fig = plt.figure(figsize=(20, 16))\n",
        "\n",
        "        # 1. Threshold analysis\n",
        "        threshold_df = pd.DataFrame(self.validation_results['threshold_analysis'])\n",
        "\n",
        "        plt.subplot(3, 3, 1)\n",
        "        for sim_type in threshold_df['similarity_type'].unique():\n",
        "            data = threshold_df[threshold_df['similarity_type'] == sim_type]\n",
        "            plt.plot(data['threshold'], data['f1_score'], marker='o', label=sim_type)\n",
        "        plt.xlabel('Similarity Threshold')\n",
        "        plt.ylabel('F1 Score')\n",
        "        plt.title('F1 Score vs Threshold by Similarity Type')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 2. Precision-Recall curve\n",
        "        plt.subplot(3, 3, 2)\n",
        "        for sim_type in threshold_df['similarity_type'].unique():\n",
        "            data = threshold_df[threshold_df['similarity_type'] == sim_type]\n",
        "            plt.plot(data['recall'], data['precision'], marker='o', label=sim_type)\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('Precision-Recall Curves')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. Category analysis\n",
        "        if 'category_analysis' in self.validation_results:\n",
        "            plt.subplot(3, 3, 3)\n",
        "            cat_analysis = self.validation_results['category_analysis']\n",
        "            categories = list(cat_analysis.keys())[:10]  # Top 10 categories\n",
        "            f1_scores = [cat_analysis[cat]['f1_score'] for cat in categories]\n",
        "\n",
        "            plt.barh(categories, f1_scores)\n",
        "            plt.xlabel('F1 Score')\n",
        "            plt.title('F1 Score by Category (Top 10)')\n",
        "            plt.tight_layout()\n",
        "\n",
        "        # 4. Theme distribution comparison\n",
        "        plt.subplot(3, 3, 4)\n",
        "        if 'kpi_theme' in self.manual_df.columns:\n",
        "            manual_themes = self.manual_df['kpi_theme'].value_counts()\n",
        "            auto_themes = self.auto_df['kpi_theme'].value_counts()\n",
        "\n",
        "            x = np.arange(len(manual_themes))\n",
        "            width = 0.35\n",
        "\n",
        "            plt.bar(x - width/2, manual_themes.values, width, label='Manual', alpha=0.8)\n",
        "            plt.bar(x + width/2, auto_themes.reindex(manual_themes.index, fill_value=0).values,\n",
        "                   width, label='Auto', alpha=0.8)\n",
        "\n",
        "            plt.xlabel('Theme')\n",
        "            plt.ylabel('Count')\n",
        "            plt.title('KPI Count by Theme')\n",
        "            plt.xticks(x, manual_themes.index, rotation=45)\n",
        "            plt.legend()\n",
        "\n",
        "        # 5. Similarity distribution\n",
        "        plt.subplot(3, 3, 5)\n",
        "        if self.validation_results['detailed_matches']:\n",
        "            similarities = [match['similarity'] for match in self.validation_results['detailed_matches']]\n",
        "            plt.hist(similarities, bins=20, edgecolor='black', alpha=0.7)\n",
        "            plt.xlabel('Similarity Score')\n",
        "            plt.ylabel('Frequency')\n",
        "            plt.title('Distribution of Similarity Scores (Matches)')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 6. Error analysis\n",
        "        plt.subplot(3, 3, 6)\n",
        "        fp_count = len(self.validation_results['false_positives'])\n",
        "        fn_count = len(self.validation_results['false_negatives'])\n",
        "        tp_count = len(self.validation_results['detailed_matches'])\n",
        "\n",
        "        labels = ['True Positives', 'False Positives', 'False Negatives']\n",
        "        counts = [tp_count, fp_count, fn_count]\n",
        "        colors = ['green', 'red', 'orange']\n",
        "\n",
        "        plt.pie(counts, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "        plt.title('Classification Results')\n",
        "\n",
        "        # 7. Coverage by source type\n",
        "        plt.subplot(3, 3, 7)\n",
        "        if 'source_type' in self.auto_df.columns:\n",
        "            source_counts = self.auto_df['source_type'].value_counts()\n",
        "            plt.pie(source_counts.values, labels=source_counts.index, autopct='%1.1f%%')\n",
        "            plt.title('Auto KPIs by Source Type')\n",
        "\n",
        "        # 8. Performance metrics summary\n",
        "        plt.subplot(3, 3, 8)\n",
        "        best_metrics = max(self.validation_results['threshold_analysis'],\n",
        "                          key=lambda x: x['f1_score'])\n",
        "\n",
        "        metrics = ['Precision', 'Recall', 'F1 Score']\n",
        "        values = [best_metrics['precision'], best_metrics['recall'], best_metrics['f1_score']]\n",
        "\n",
        "        bars = plt.bar(metrics, values, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "        plt.ylabel('Score')\n",
        "        plt.title(f'Best Performance Metrics\\n(Threshold: {best_metrics[\"threshold\"]})')\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar, value in zip(bars, values):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                    f'{value:.3f}', ha='center', va='bottom')\n",
        "\n",
        "        # 9. Match quality distribution\n",
        "        plt.subplot(3, 3, 9)\n",
        "        if self.validation_results['detailed_matches']:\n",
        "            match_similarities = [match['similarity'] for match in self.validation_results['detailed_matches']]\n",
        "            quality_bins = [0.5, 0.7, 0.8, 0.9, 1.0]\n",
        "            quality_labels = ['Medium', 'Good', 'Very Good', 'Excellent']\n",
        "\n",
        "            quality_counts = []\n",
        "            for i in range(len(quality_bins)-1):\n",
        "                count = sum(1 for sim in match_similarities\n",
        "                          if quality_bins[i] <= sim < quality_bins[i+1])\n",
        "                quality_counts.append(count)\n",
        "\n",
        "            plt.bar(quality_labels, quality_counts, color='lightblue', edgecolor='black')\n",
        "            plt.ylabel('Number of Matches')\n",
        "            plt.title('Match Quality Distribution')\n",
        "            plt.xticks(rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save visualization\n",
        "        viz_path = self.output_dir / \"validation_visualizations.png\"\n",
        "        plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        logging.info(f\"Visualizations saved to {viz_path}\")\n",
        "\n",
        "    def generate_detailed_report(self) -> str:\n",
        "        \"\"\"Generate comprehensive validation report\"\"\"\n",
        "        if not self.validation_results:\n",
        "            logging.warning(\"No validation results found. Run evaluation first.\")\n",
        "            return \"\"\n",
        "\n",
        "        # Find best configuration\n",
        "        best_metrics = max(self.validation_results['threshold_analysis'],\n",
        "                          key=lambda x: x['f1_score'])\n",
        "\n",
        "        report = f\"\"\"\n",
        "# KPI Extraction Validation Report\n",
        "Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "## Dataset Overview\n",
        "- **Manual KPIs**: {len(self.manual_df)} annotations\n",
        "- **Auto KPIs**: {len(self.auto_df)} extractions\n",
        "- **Manual file**: {self.manual_path}\n",
        "- **Auto file**: {self.auto_path}\n",
        "\n",
        "## Best Performance Configuration\n",
        "- **Similarity Type**: {best_metrics['similarity_type']}\n",
        "- **Threshold**: {best_metrics['threshold']}\n",
        "- **Precision**: {best_metrics['precision']:.3f}\n",
        "- **Recall**: {best_metrics['recall']:.3f}\n",
        "- **F1 Score**: {best_metrics['f1_score']:.3f}\n",
        "\n",
        "## Detailed Metrics\n",
        "- **True Positives**: {best_metrics['true_positives']}\n",
        "- **False Positives**: {best_metrics['false_positives']}\n",
        "- **False Negatives**: {best_metrics['false_negatives']}\n",
        "- **Match Rate**: {best_metrics['match_rate']:.3f}\n",
        "\n",
        "## Error Analysis\n",
        "\n",
        "### False Positives ({len(self.validation_results['false_positives'])})\n",
        "KPIs extracted automatically but not in manual annotations:\n",
        "\"\"\"\n",
        "\n",
        "        # Add false positives\n",
        "        for i, fp in enumerate(self.validation_results['false_positives'][:10], 1):\n",
        "            report += f\"\\n{i}. **{fp['category']}** | {fp['kpi_text']}\\n\"\n",
        "\n",
        "        if len(self.validation_results['false_positives']) > 10:\n",
        "            report += f\"\\n... and {len(self.validation_results['false_positives']) - 10} more\\n\"\n",
        "\n",
        "        report += f\"\"\"\n",
        "### False Negatives ({len(self.validation_results['false_negatives'])})\n",
        "KPIs in manual annotations but missed by extraction:\n",
        "\"\"\"\n",
        "\n",
        "        # Add false negatives\n",
        "        for i, fn in enumerate(self.validation_results['false_negatives'][:10], 1):\n",
        "            report += f\"\\n{i}. **{fn['category']}** | {fn['kpi_text']}\\n\"\n",
        "\n",
        "        if len(self.validation_results['false_negatives']) > 10:\n",
        "            report += f\"\\n... and {len(self.validation_results['false_negatives']) - 10} more\\n\"\n",
        "\n",
        "        # Category analysis\n",
        "        if 'category_analysis' in self.validation_results:\n",
        "            report += \"\\n## Category-wise Performance\\n\\n\"\n",
        "            report += \"| Category | Manual | Auto | Matches | Precision | Recall | F1 |\\n\"\n",
        "            report += \"|----------|--------|------|---------|-----------|--------|----|\\\\n\"\n",
        "\n",
        "            for category, metrics in self.validation_results['category_analysis'].items():\n",
        "                report += f\"| {category[:20]} | {metrics['manual_count']} | {metrics['auto_count']} | {metrics['matches']} | {metrics['precision']:.3f} | {metrics['recall']:.3f} | {metrics['f1_score']:.3f} |\\n\"\n",
        "\n",
        "        # Theme analysis\n",
        "        if 'theme_analysis' in self.validation_results:\n",
        "            report += \"\\n## Theme-wise Coverage\\n\\n\"\n",
        "            report += \"| Theme | Manual Count | Auto Count | Coverage |\\n\"\n",
        "            report += \"|-------|--------------|------------|----------|\\n\"\n",
        "\n",
        "            for theme, metrics in self.validation_results['theme_analysis'].items():\n",
        "                report += f\"| {theme} | {metrics['manual_count']} | {metrics['auto_count']} | {metrics['coverage']:.3f} |\\n\"\n",
        "\n",
        "        # Recommendations\n",
        "        report += f\"\"\"\n",
        "## Recommendations\n",
        "\n",
        "### Strengths\n",
        "- Overall F1 Score: {best_metrics['f1_score']:.3f}\n",
        "- Precision: {best_metrics['precision']:.3f} (low false positive rate)\n",
        "- Recall: {best_metrics['recall']:.3f} (good coverage)\n",
        "\n",
        "### Areas for Improvement\n",
        "\"\"\"\n",
        "\n",
        "        if best_metrics['precision'] < 0.8:\n",
        "            report += \"- **Precision**: Consider stricter filtering to reduce false positives\\n\"\n",
        "\n",
        "        if best_metrics['recall'] < 0.8:\n",
        "            report += \"- **Recall**: Improve extraction to catch more manual KPIs\\n\"\n",
        "\n",
        "        if best_metrics['f1_score'] < 0.7:\n",
        "            report += \"- **Overall Performance**: Significant room for improvement in both precision and recall\\n\"\n",
        "\n",
        "        # Source-specific recommendations\n",
        "        if 'source_type' in self.auto_df.columns:\n",
        "            text_kpis = len(self.auto_df[self.auto_df['source_type'] == 'text'])\n",
        "            image_kpis = len(self.auto_df[self.auto_df['source_type'] == 'image'])\n",
        "\n",
        "            report += f\"\"\"\n",
        "### Source Type Analysis\n",
        "- **Text/Table KPIs**: {text_kpis}\n",
        "- **Image/Chart KPIs**: {image_kpis}\n",
        "- **Image Coverage**: {image_kpis / (text_kpis + image_kpis) * 100:.1f}%\n",
        "\"\"\"\n",
        "\n",
        "        return report\n",
        "\n",
        "    # 🔥 在这里添加新方法（在类的最后，但在类结束之前）\n",
        "    def generate_enhanced_table_report(self) -> str:\n",
        "        \"\"\"生成带有详细表格的验证报告\"\"\"\n",
        "        if not self.validation_results:\n",
        "            logging.warning(\"No validation results found. Run evaluation first.\")\n",
        "            return \"\"\n",
        "\n",
        "        best_metrics = max(self.validation_results['threshold_analysis'],\n",
        "                          key=lambda x: x['f1_score'])\n",
        "\n",
        "        report = f\"\"\"\n",
        "# KPI Extraction Validation Report\n",
        "Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "## Performance Summary Table\n",
        "\n",
        "| Metric | Value | Benchmark |\n",
        "|--------|-------|-----------|\n",
        "| **F1 Score** | {best_metrics['f1_score']:.3f} | > 0.8 (Excellent), > 0.7 (Good) |\n",
        "| **Precision** | {best_metrics['precision']:.3f} | > 0.85 (Excellent), > 0.75 (Good) |\n",
        "| **Recall** | {best_metrics['recall']:.3f} | > 0.8 (Excellent), > 0.7 (Good) |\n",
        "| **True Positives** | {best_metrics['true_positives']} | - |\n",
        "| **False Positives** | {best_metrics['false_positives']} | < 10% of total |\n",
        "| **False Negatives** | {best_metrics['false_negatives']} | < 15% of manual |\n",
        "\n",
        "## Threshold Analysis Table\n",
        "\n",
        "| Threshold | Similarity Type | Precision | Recall | F1 Score | TP | FP | FN |\n",
        "|-----------|----------------|-----------|--------|----------|----|----|----|\n",
        "\"\"\"\n",
        "\n",
        "        # 添加阈值分析表格\n",
        "        threshold_df = pd.DataFrame(self.validation_results['threshold_analysis'])\n",
        "\n",
        "        # 按F1分数排序，显示前10个最佳配置\n",
        "        top_configs = threshold_df.nlargest(10, 'f1_score')\n",
        "\n",
        "        for _, row in top_configs.iterrows():\n",
        "            report += f\"| {row['threshold']:.1f} | {row['similarity_type']} | {row['precision']:.3f} | {row['recall']:.3f} | {row['f1_score']:.3f} | {row['true_positives']} | {row['false_positives']} | {row['false_negatives']} |\\n\"\n",
        "\n",
        "        # 如果有分类分析，添加分类表格\n",
        "        if 'category_analysis' in self.validation_results:\n",
        "            report += \"\\n## Category Performance Table\\n\\n\"\n",
        "            report += \"| Category | Manual Count | Auto Count | Matches | Precision | Recall | F1 Score |\\n\"\n",
        "            report += \"|----------|--------------|------------|---------|-----------|--------|---------|\\n\"\n",
        "\n",
        "            for category, metrics in self.validation_results['category_analysis'].items():\n",
        "                report += f\"| {category[:25]} | {metrics['manual_count']} | {metrics['auto_count']} | {metrics['matches']} | {metrics['precision']:.3f} | {metrics['recall']:.3f} | {metrics['f1_score']:.3f} |\\n\"\n",
        "\n",
        "        return report\n",
        "\n",
        "    def save_results_with_enhanced_tables(self):\n",
        "        \"\"\"保存包含增强表格的结果\"\"\"\n",
        "        # 保存详细的表格到Excel\n",
        "        with pd.ExcelWriter(self.output_dir / \"validation_summary_tables.xlsx\", engine='openpyxl') as writer:\n",
        "\n",
        "            # 1. 性能摘要表\n",
        "            performance_data = []\n",
        "            best_metrics = max(self.validation_results['threshold_analysis'], key=lambda x: x['f1_score'])\n",
        "\n",
        "            performance_data.append({\n",
        "                'Metric': 'F1 Score',\n",
        "                'Value': best_metrics['f1_score'],\n",
        "                'Benchmark': '> 0.8 (Excellent), > 0.7 (Good)',\n",
        "                'Status': 'Excellent' if best_metrics['f1_score'] > 0.8 else 'Good' if best_metrics['f1_score'] > 0.7 else 'Needs Improvement'\n",
        "            })\n",
        "\n",
        "            performance_data.append({\n",
        "                'Metric': 'Precision',\n",
        "                'Value': best_metrics['precision'],\n",
        "                'Benchmark': '> 0.85 (Excellent), > 0.75 (Good)',\n",
        "                'Status': 'Excellent' if best_metrics['precision'] > 0.85 else 'Good' if best_metrics['precision'] > 0.75 else 'Needs Improvement'\n",
        "            })\n",
        "\n",
        "            performance_data.append({\n",
        "                'Metric': 'Recall',\n",
        "                'Value': best_metrics['recall'],\n",
        "                'Benchmark': '> 0.8 (Excellent), > 0.7 (Good)',\n",
        "                'Status': 'Excellent' if best_metrics['recall'] > 0.8 else 'Good' if best_metrics['recall'] > 0.7 else 'Needs Improvement'\n",
        "            })\n",
        "\n",
        "            performance_df = pd.DataFrame(performance_data)\n",
        "            performance_df.to_excel(writer, sheet_name='Performance_Summary', index=False)\n",
        "\n",
        "            # 2. 阈值分析表（完整版）\n",
        "            threshold_df = pd.DataFrame(self.validation_results['threshold_analysis'])\n",
        "            threshold_df = threshold_df.sort_values('f1_score', ascending=False)\n",
        "            threshold_df.to_excel(writer, sheet_name='Threshold_Analysis', index=False)\n",
        "\n",
        "            # 3. 分类性能表\n",
        "            if 'category_analysis' in self.validation_results:\n",
        "                category_data = []\n",
        "                for category, metrics in self.validation_results['category_analysis'].items():\n",
        "                    category_data.append({\n",
        "                        'Category': category,\n",
        "                        'Manual_Count': metrics['manual_count'],\n",
        "                        'Auto_Count': metrics['auto_count'],\n",
        "                        'Matches': metrics['matches'],\n",
        "                        'Precision': metrics['precision'],\n",
        "                        'Recall': metrics['recall'],\n",
        "                        'F1_Score': metrics['f1_score']\n",
        "                    })\n",
        "\n",
        "                category_df = pd.DataFrame(category_data)\n",
        "                category_df = category_df.sort_values('F1_Score', ascending=False)\n",
        "                category_df.to_excel(writer, sheet_name='Category_Performance', index=False)\n",
        "\n",
        "        print(f\"📊 Enhanced validation tables saved to: {self.output_dir}/validation_summary_tables.xlsx\")\n",
        "\n",
        "    # 类在这里结束\n",
        "\n",
        "    def save_results(self):\n",
        "        \"\"\"Save all validation results to files\"\"\"\n",
        "        # Save detailed results as JSON\n",
        "        results_path = self.output_dir / \"validation_results.json\"\n",
        "        with open(results_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.validation_results, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "        # Save matches as Excel\n",
        "        if self.validation_results['detailed_matches']:\n",
        "            matches_df = pd.DataFrame(self.validation_results['detailed_matches'])\n",
        "            matches_path = self.output_dir / \"detailed_matches.xlsx\"\n",
        "            matches_df.to_excel(matches_path, index=False)\n",
        "\n",
        "        # Save false positives and negatives\n",
        "        fp_df = pd.DataFrame(self.validation_results['false_positives'])\n",
        "        fn_df = pd.DataFrame(self.validation_results['false_negatives'])\n",
        "\n",
        "        with pd.ExcelWriter(self.output_dir / \"error_analysis.xlsx\") as writer:\n",
        "            fp_df.to_excel(writer, sheet_name='False_Positives', index=False)\n",
        "            fn_df.to_excel(writer, sheet_name='False_Negatives', index=False)\n",
        "\n",
        "        # Save report\n",
        "        report = self.generate_detailed_report()\n",
        "        report_path = self.output_dir / \"validation_report.md\"\n",
        "        with open(report_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(report)\n",
        "\n",
        "        # Save metrics summary\n",
        "        threshold_df = pd.DataFrame(self.validation_results['threshold_analysis'])\n",
        "        threshold_df.to_excel(self.output_dir / \"threshold_analysis.xlsx\", index=False)\n",
        "\n",
        "        logging.info(f\"All validation results saved to {self.output_dir}\")\n",
        "\n",
        "        return {\n",
        "            'results_json': results_path,\n",
        "            'matches_excel': self.output_dir / \"detailed_matches.xlsx\",\n",
        "            'error_analysis': self.output_dir / \"error_analysis.xlsx\",\n",
        "            'report_markdown': report_path,\n",
        "            'threshold_analysis': self.output_dir / \"threshold_analysis.xlsx\",\n",
        "            'visualizations': self.output_dir / \"validation_visualizations.png\"\n",
        "        }\n",
        "\n",
        "    def run_full_validation(self) -> Dict[str, any]:\n",
        "        \"\"\"Run complete validation pipeline\"\"\"\n",
        "        logging.info(\"Starting full validation pipeline...\")\n",
        "\n",
        "        # Step 1: Run comprehensive evaluation\n",
        "        self.run_comprehensive_evaluation()\n",
        "\n",
        "        # Step 2: Generate visualizations\n",
        "        self.generate_visualizations()\n",
        "\n",
        "        # Step 3: Save all results\n",
        "        saved_files = self.save_results()\n",
        "\n",
        "        # Step 4: Print summary\n",
        "        best_metrics = max(self.validation_results['threshold_analysis'],\n",
        "                          key=lambda x: x['f1_score'])\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"KPI EXTRACTION VALIDATION SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"📊 Dataset: {len(self.manual_df)} manual vs {len(self.auto_df)} auto KPIs\")\n",
        "        print(f\"🎯 Best F1 Score: {best_metrics['f1_score']:.3f}\")\n",
        "        print(f\"📈 Precision: {best_metrics['precision']:.3f}\")\n",
        "        print(f\"📉 Recall: {best_metrics['recall']:.3f}\")\n",
        "        print(f\"✅ True Positives: {best_metrics['true_positives']}\")\n",
        "        print(f\"❌ False Positives: {best_metrics['false_positives']}\")\n",
        "        print(f\"⚠️  False Negatives: {best_metrics['false_negatives']}\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"📁 Results saved to: {self.output_dir}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return {\n",
        "            'validation_results': self.validation_results,\n",
        "            'saved_files': saved_files,\n",
        "            'best_metrics': best_metrics\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "UfLJWwsd4nDX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ LLM验证相关类 ============\n",
        "\n",
        "class LLMAssistedValidation:\n",
        "    \"\"\"LLM辅助验证类\"\"\"\n",
        "\n",
        "    def __init__(self, openai_client, validation_pipeline):\n",
        "        self.client = openai_client\n",
        "        self.main_validator = validation_pipeline\n",
        "        self.llm_validations = []\n",
        "\n",
        "    def llm_validate_kpi_pair(self, manual_kpi: str, auto_kpi: str,\n",
        "                             traditional_similarity: float) -> Dict:\n",
        "        \"\"\"使用LLM验证KPI对的语义等价性\"\"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are an expert in sustainability reporting and KPI analysis.\n",
        "\n",
        "Please evaluate whether these two KPIs express the same performance indicator:\n",
        "\n",
        "MANUAL KPI: {manual_kpi}\n",
        "AUTO KPI: {auto_kpi}\n",
        "\n",
        "Consider:\n",
        "1. Do they measure the same metric/outcome?\n",
        "2. Are the numerical values equivalent?\n",
        "3. Do they refer to the same time period?\n",
        "4. Are they semantically equivalent despite different wording?\n",
        "\n",
        "Respond with a JSON object:\n",
        "{{\n",
        "    \"are_equivalent\": true/false,\n",
        "    \"confidence\": 0.0-1.0,\n",
        "    \"reasoning\": \"detailed explanation\",\n",
        "    \"numerical_match\": true/false/null,\n",
        "    \"temporal_match\": true/false/null,\n",
        "    \"semantic_match\": true/false/null,\n",
        "    \"suggested_action\": \"accept\"/\"reject\"/\"human_review\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.1,\n",
        "                max_tokens=1000\n",
        "            )\n",
        "\n",
        "            content = response.choices[0].message.content.strip()\n",
        "\n",
        "            # 清理JSON格式\n",
        "            if content.startswith('```json'):\n",
        "                content = content[7:]\n",
        "            if content.endswith('```'):\n",
        "                content = content[:-3]\n",
        "\n",
        "            llm_result = json.loads(content)\n",
        "\n",
        "            # 添加传统相似度分数用于比较\n",
        "            llm_result['traditional_similarity'] = traditional_similarity\n",
        "\n",
        "            return llm_result\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"LLM validation failed: {e}\")\n",
        "            return {\n",
        "                \"are_equivalent\": None,\n",
        "                \"confidence\": 0.0,\n",
        "                \"reasoning\": f\"LLM validation failed: {str(e)}\",\n",
        "                \"error\": True,\n",
        "                \"traditional_similarity\": traditional_similarity\n",
        "            }\n",
        "\n",
        "    def run_llm_validation_on_matches(self, sample_size: int = None) -> Dict:\n",
        "        \"\"\"对匹配的KPI对运行LLM验证\"\"\"\n",
        "\n",
        "        if not hasattr(self.main_validator, 'validation_results'):\n",
        "            logging.error(\"Main validator must run first\")\n",
        "            return {}\n",
        "\n",
        "        matches = self.main_validator.validation_results.get('detailed_matches', [])\n",
        "        if not matches:\n",
        "            return {}\n",
        "\n",
        "        # 如果指定了样本大小，随机采样\n",
        "        if sample_size and len(matches) > sample_size:\n",
        "            import random\n",
        "            matches = random.sample(matches, sample_size)\n",
        "\n",
        "        print(f\"🤖 Running LLM validation on {len(matches)} KPI pairs...\")\n",
        "\n",
        "        llm_results = []\n",
        "        agreement_count = 0\n",
        "        disagreement_count = 0\n",
        "\n",
        "        for i, match in enumerate(matches, 1):\n",
        "            manual_text = match['manual_text']\n",
        "            auto_text = match['auto_text']\n",
        "            traditional_sim = match['similarity']\n",
        "\n",
        "            print(f\"   Validating pair {i}/{len(matches)}...\")\n",
        "\n",
        "            llm_result = self.llm_validate_kpi_pair(manual_text, auto_text, traditional_sim)\n",
        "\n",
        "            # 判断LLM和传统方法是否一致\n",
        "            traditional_accepts = traditional_sim >= 0.7  # 假设0.7是接受阈值\n",
        "            llm_accepts = llm_result.get('are_equivalent', False)\n",
        "\n",
        "            if traditional_accepts == llm_accepts:\n",
        "                agreement_count += 1\n",
        "            else:\n",
        "                disagreement_count += 1\n",
        "\n",
        "            llm_result.update({\n",
        "                'manual_text': manual_text,\n",
        "                'auto_text': auto_text,\n",
        "                'pair_index': i,\n",
        "                'traditional_accepts': traditional_accepts,\n",
        "                'llm_accepts': llm_accepts,\n",
        "                'agreement': traditional_accepts == llm_accepts\n",
        "            })\n",
        "\n",
        "            llm_results.append(llm_result)\n",
        "\n",
        "            # API rate limiting\n",
        "            time.sleep(1)\n",
        "\n",
        "        # 计算统计信息\n",
        "        total_validated = len([r for r in llm_results if not r.get('error', False)])\n",
        "        agreement_rate = agreement_count / total_validated if total_validated > 0 else 0\n",
        "\n",
        "        summary = {\n",
        "            'total_pairs_validated': len(matches),\n",
        "            'successful_llm_validations': total_validated,\n",
        "            'agreement_count': agreement_count,\n",
        "            'disagreement_count': disagreement_count,\n",
        "            'agreement_rate': agreement_rate,\n",
        "            'llm_results': llm_results\n",
        "        }\n",
        "\n",
        "        print(f\"🎯 LLM Validation Summary:\")\n",
        "        print(f\"   Agreement with traditional method: {agreement_rate:.1%}\")\n",
        "        print(f\"   Successful validations: {total_validated}/{len(matches)}\")\n",
        "\n",
        "        self.llm_validations = summary\n",
        "        return summary\n",
        "\n",
        "    def generate_llm_comparison_report(self) -> str:\n",
        "        \"\"\"生成LLM与传统方法的对比报告\"\"\"\n",
        "        if not self.llm_validations:\n",
        "            return \"No LLM validations performed.\"\n",
        "\n",
        "        results = self.llm_validations\n",
        "\n",
        "        report = f\"\"\"\n",
        "# LLM vs Traditional Validation Comparison\n",
        "\n",
        "## Summary Statistics\n",
        "\n",
        "| Metric | Value |\n",
        "|--------|-------|\n",
        "| **Total Pairs Validated** | {results['total_pairs_validated']} |\n",
        "| **Successful LLM Validations** | {results['successful_llm_validations']} |\n",
        "| **Agreement Rate** | {results['agreement_rate']:.1%} |\n",
        "| **Disagreements** | {results['disagreement_count']} |\n",
        "\n",
        "## Disagreement Analysis\n",
        "\n",
        "Cases where LLM and traditional methods disagree:\n",
        "\n",
        "| Pair | Traditional Sim | Traditional Decision | LLM Decision | LLM Confidence | Reasoning |\n",
        "|------|----------------|---------------------|--------------|----------------|-----------|\n",
        "\"\"\"\n",
        "\n",
        "        disagreements = [r for r in results['llm_results'] if not r.get('agreement', True)]\n",
        "\n",
        "        for i, disagreement in enumerate(disagreements[:10], 1):  # Show first 10 disagreements\n",
        "            report += f\"| {i} | {disagreement.get('traditional_similarity', 0):.3f} | {'Accept' if disagreement.get('traditional_accepts', False) else 'Reject'} | {'Accept' if disagreement.get('llm_accepts', False) else 'Reject'} | {disagreement.get('confidence', 0):.2f} | {disagreement.get('reasoning', '')[:50]}... |\\n\"\n",
        "\n",
        "        return report\n",
        "\n"
      ],
      "metadata": {
        "id": "7xm2wXtTgY8I"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ 兼容性函数 ============\n",
        "def extract_kpi_from_chunk(chunk: str) -> List[Dict]:\n",
        "    \"\"\"Backward compatibility function\"\"\"\n",
        "    return extract_kpi_from_chunk_universal(chunk)\n",
        "\n",
        "def process_sustainability_report(pdf_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Backward compatibility function for text-only processing\"\"\"\n",
        "    return process_text_only()\n",
        "\n",
        "def process_sustainability_report_with_images(pdf_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Backward compatibility function for full processing\"\"\"\n",
        "    return process_sustainability_report_with_enhanced_images(pdf_path)\n"
      ],
      "metadata": {
        "id": "uhyRnexga6fA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dmSZamf7iRrD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ 使用示例 ============\n",
        "def example_usage():\n",
        "    \"\"\"Usage examples\"\"\"\n",
        "    print(\"=== KPI Extraction Tool Usage Examples ===\\n\")\n",
        "\n",
        "    print(\"1. Full extraction (text + images):\")\n",
        "    print(\"   df_results = process_sustainability_report_with_enhanced_images(PDF_PATH)\")\n",
        "    print(\"   save_results(df_results, EXPORT_AUTO_XLSX, PDF_PATH)\\n\")\n",
        "\n",
        "    print(\"2. Text-only extraction:\")\n",
        "    print(\"   df_results = process_text_only()\")\n",
        "    print(\"   # Results automatically saved\\n\")\n",
        "\n",
        "    print(\"3. Simple run:\")\n",
        "    print(\"   run_kpi_extraction()  # Complete pipeline with validation\\n\")\n",
        "\n",
        "    print(\"4. Debug single component:\")\n",
        "    print(\"   test_text_extraction_only()  # Test first 3 chunks\")\n",
        "    print(\"   debug_single_image_analysis('path/to/image.jpg')\\n\")\n",
        "\n",
        "    print(\"5. Install dependencies:\")\n",
        "    print(\"   install_dependencies()  # Install all required packages\\n\")\n"
      ],
      "metadata": {
        "id": "fldjMEkaa6g1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MetadataValidationExtension:\n",
        "    \"\"\"元数据验证扩展 - 验证KPI文本以外的字段准确性\"\"\"\n",
        "\n",
        "    def __init__(self, validation_pipeline: KPIValidationPipeline):\n",
        "        \"\"\"\n",
        "        基于现有的KPIValidationPipeline扩展元数据验证功能\n",
        "\n",
        "        Args:\n",
        "            validation_pipeline: 现有的验证管道实例\n",
        "        \"\"\"\n",
        "        self.main_validator = validation_pipeline\n",
        "        self.metadata_results = {}\n",
        "\n",
        "        # 需要验证的元数据字段配置\n",
        "        self.metadata_fields = {\n",
        "            # 文档相关字段\n",
        "            'document_fields': {\n",
        "                'PDF file name': {'weight': 0.05, 'type': 'exact'},\n",
        "                'Title of the report': {'weight': 0.05, 'type': 'exact'},\n",
        "                'Absolute Page Number': {'weight': 0.15, 'type': 'exact'},  # 您提到的问题字段\n",
        "                'Impacted Stakeholder': {'weight': 0.10, 'type': 'similarity'}\n",
        "            },\n",
        "\n",
        "            # KPI分类字段\n",
        "            'classification_fields': {\n",
        "                'kpi_theme': {'weight': 0.15, 'type': 'exact'},  # 您提到的问题字段\n",
        "                'kpi_category': {'weight': 0.15, 'type': 'similarity'}\n",
        "            },\n",
        "\n",
        "            # 数值相关字段\n",
        "            'quantitative_fields': {\n",
        "                'quantitative_value': {'weight': 0.20, 'type': 'numerical'},  # 您提到的问题字段\n",
        "                'unit': {'weight': 0.10, 'type': 'similarity'},\n",
        "                'time_period': {'weight': 0.05, 'type': 'similarity'}\n",
        "            },\n",
        "\n",
        "            # 其他分析字段\n",
        "            'analysis_fields': {\n",
        "                'target_or_actual': {'weight': 0.05, 'type': 'exact'},\n",
        "                'source_type': {'weight': 0.05, 'type': 'exact'},\n",
        "                'chart_type': {'weight': 0.03, 'type': 'similarity'},\n",
        "                'estimation_confidence': {'weight': 0.02, 'type': 'exact'},\n",
        "                'chart_title': {'weight': 0.03, 'type': 'similarity'},\n",
        "                'data_source': {'weight': 0.02, 'type': 'similarity'},\n",
        "                'image_type': {'weight': 0.02, 'type': 'exact'}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # 问题字段标记（您特别关注的字段）\n",
        "        self.problematic_fields = {\n",
        "            'Absolute Page Number': 'page_number_issues',\n",
        "            'kpi_theme': 'theme_classification_issues',\n",
        "            'quantitative_value': 'value_extraction_issues'\n",
        "        }\n",
        "\n",
        "        logging.info(\"元数据验证扩展初始化完成\")\n",
        "\n",
        "    def validate_single_field(self, manual_value, auto_value, field_name: str, validation_type: str) -> Dict[str, any]:\n",
        "        \"\"\"\n",
        "        验证单个字段的准确性\n",
        "\n",
        "        Args:\n",
        "            manual_value: 手动标注值\n",
        "            auto_value: 自动提取值\n",
        "            field_name: 字段名称\n",
        "            validation_type: 验证类型 ('exact', 'similarity', 'numerical')\n",
        "\n",
        "        Returns:\n",
        "            验证结果字典\n",
        "        \"\"\"\n",
        "        result = {\n",
        "            'field_name': field_name,\n",
        "            'manual_value': manual_value,\n",
        "            'auto_value': auto_value,\n",
        "            'validation_type': validation_type,\n",
        "            'is_correct': False,\n",
        "            'score': 0.0,\n",
        "            'error_type': None,\n",
        "            'notes': \"\"\n",
        "        }\n",
        "\n",
        "        # 处理空值情况\n",
        "        manual_clean = str(manual_value).strip() if pd.notna(manual_value) else \"\"\n",
        "        auto_clean = str(auto_value).strip() if pd.notna(auto_value) else \"\"\n",
        "\n",
        "        if not manual_clean and not auto_clean:\n",
        "            result.update({'is_correct': True, 'score': 1.0, 'notes': 'Both values empty'})\n",
        "            return result\n",
        "        elif not manual_clean or not auto_clean:\n",
        "            result.update({'error_type': 'missing_value', 'notes': 'One value is missing'})\n",
        "            return result\n",
        "\n",
        "        # 根据验证类型进行比较\n",
        "        if validation_type == 'exact':\n",
        "            is_match = manual_clean.lower() == auto_clean.lower()\n",
        "            result.update({\n",
        "                'is_correct': is_match,\n",
        "                'score': 1.0 if is_match else 0.0,\n",
        "                'error_type': None if is_match else 'exact_mismatch'\n",
        "            })\n",
        "\n",
        "        elif validation_type == 'similarity':\n",
        "            # 使用主验证器的文本相似度算法\n",
        "            similarity_scores = self.main_validator.calculate_text_similarity(manual_clean, auto_clean)\n",
        "            similarity = similarity_scores['combined']\n",
        "\n",
        "            # 对于元数据，使用更高的相似度阈值\n",
        "            threshold = 0.8\n",
        "            is_match = similarity >= threshold\n",
        "\n",
        "            result.update({\n",
        "                'is_correct': is_match,\n",
        "                'score': similarity,\n",
        "                'similarity_details': similarity_scores,\n",
        "                'error_type': None if is_match else 'similarity_mismatch',\n",
        "                'notes': f'Similarity: {similarity:.3f}'\n",
        "            })\n",
        "\n",
        "        elif validation_type == 'numerical':\n",
        "            try:\n",
        "                # 标准化数值格式\n",
        "                manual_num = self._normalize_numerical_value(manual_clean)\n",
        "                auto_num = self._normalize_numerical_value(auto_clean)\n",
        "\n",
        "                if manual_num is not None and auto_num is not None:\n",
        "                    # 允许小幅度差异（适应提取中的舍入误差）\n",
        "                    tolerance = 0.01 if abs(manual_num) < 10 else abs(manual_num) * 0.001\n",
        "                    is_match = abs(manual_num - auto_num) <= tolerance\n",
        "\n",
        "                    result.update({\n",
        "                        'is_correct': is_match,\n",
        "                        'score': 1.0 if is_match else max(0.0, 1.0 - abs(manual_num - auto_num) / max(abs(manual_num), 1)),\n",
        "                        'error_type': None if is_match else 'numerical_mismatch',\n",
        "                        'manual_parsed': manual_num,\n",
        "                        'auto_parsed': auto_num,\n",
        "                        'notes': f'Manual: {manual_num}, Auto: {auto_num}'\n",
        "                    })\n",
        "                else:\n",
        "                    result.update({\n",
        "                        'error_type': 'numerical_parse_error',\n",
        "                        'notes': f'Failed to parse numerical values: \"{manual_clean}\" vs \"{auto_clean}\"'\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                result.update({\n",
        "                    'error_type': 'numerical_validation_error',\n",
        "                    'notes': f'Numerical validation failed: {str(e)}'\n",
        "                })\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _normalize_numerical_value(self, value_str: str) -> float:\n",
        "        \"\"\"标准化数值字符串为float\"\"\"\n",
        "        if not value_str:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # 移除常见的非数字字符，保留数字、小数点、负号\n",
        "            cleaned = re.sub(r'[^\\d\\.\\-\\+]', '', str(value_str))\n",
        "            if cleaned:\n",
        "                return float(cleaned)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # 尝试提取第一个数字\n",
        "        numbers = re.findall(r'-?\\d+\\.?\\d*', str(value_str))\n",
        "        if numbers:\n",
        "            try:\n",
        "                return float(numbers[0])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        return None\n",
        "\n",
        "    def validate_metadata_for_matched_pairs(self) -> Dict[str, any]:\n",
        "        \"\"\"\n",
        "        对已匹配的KPI对进行元数据验证\n",
        "\n",
        "        Returns:\n",
        "            元数据验证结果\n",
        "        \"\"\"\n",
        "        logging.info(\"开始元数据验证...\")\n",
        "\n",
        "        # 获取主验证器的匹配结果\n",
        "        if not hasattr(self.main_validator, 'validation_results') or not self.main_validator.validation_results:\n",
        "            logging.error(\"主验证器尚未运行，请先运行文本验证\")\n",
        "            return {}\n",
        "\n",
        "        matched_pairs = self.main_validator.validation_results.get('detailed_matches', [])\n",
        "        if not matched_pairs:\n",
        "            logging.warning(\"没有找到匹配的KPI对，无法进行元数据验证\")\n",
        "            return {}\n",
        "\n",
        "        metadata_results = {\n",
        "            'total_pairs': len(matched_pairs),\n",
        "            'field_results': {},\n",
        "            'overall_scores': {},\n",
        "            'problematic_field_analysis': {},\n",
        "            'detailed_results': []\n",
        "        }\n",
        "\n",
        "        # 初始化字段结果统计\n",
        "        all_fields = {}\n",
        "        for category, fields in self.metadata_fields.items():\n",
        "            all_fields.update(fields)\n",
        "\n",
        "        for field_name in all_fields.keys():\n",
        "            metadata_results['field_results'][field_name] = {\n",
        "                'total_comparisons': 0,\n",
        "                'correct_count': 0,\n",
        "                'total_score': 0.0,\n",
        "                'error_types': {},\n",
        "                'examples': {'correct': [], 'incorrect': []}\n",
        "            }\n",
        "\n",
        "        # 对每个匹配对进行元数据验证\n",
        "        for pair_idx, match_pair in enumerate(matched_pairs):\n",
        "            manual_idx = match_pair['manual_idx']\n",
        "            auto_idx = match_pair['auto_idx']\n",
        "            text_similarity = match_pair['similarity']\n",
        "\n",
        "            # 获取完整的KPI记录\n",
        "            manual_kpi = self.main_validator.manual_df.iloc[manual_idx]\n",
        "            auto_kpi = self.main_validator.auto_df.iloc[auto_idx]\n",
        "\n",
        "            pair_results = {\n",
        "                'pair_index': pair_idx,\n",
        "                'manual_idx': manual_idx,\n",
        "                'auto_idx': auto_idx,\n",
        "                'text_similarity': text_similarity,\n",
        "                'manual_text': match_pair['manual_text'],\n",
        "                'auto_text': match_pair['auto_text'],\n",
        "                'field_validations': {},\n",
        "                'pair_metadata_score': 0.0\n",
        "            }\n",
        "\n",
        "            total_weight = 0.0\n",
        "            weighted_score = 0.0\n",
        "\n",
        "            # 验证每个元数据字段\n",
        "            for field_name, field_config in all_fields.items():\n",
        "                manual_value = manual_kpi.get(field_name, '')\n",
        "                auto_value = auto_kpi.get(field_name, '')\n",
        "\n",
        "                field_result = self.validate_single_field(\n",
        "                    manual_value, auto_value, field_name, field_config['type']\n",
        "                )\n",
        "\n",
        "                pair_results['field_validations'][field_name] = field_result\n",
        "\n",
        "                # 更新字段统计\n",
        "                field_stats = metadata_results['field_results'][field_name]\n",
        "                field_stats['total_comparisons'] += 1\n",
        "                field_stats['total_score'] += field_result['score']\n",
        "\n",
        "                if field_result['is_correct']:\n",
        "                    field_stats['correct_count'] += 1\n",
        "                    if len(field_stats['examples']['correct']) < 3:\n",
        "                        field_stats['examples']['correct'].append({\n",
        "                            'manual': manual_value,\n",
        "                            'auto': auto_value,\n",
        "                            'pair_idx': pair_idx\n",
        "                        })\n",
        "                else:\n",
        "                    error_type = field_result.get('error_type', 'unknown')\n",
        "                    field_stats['error_types'][error_type] = field_stats['error_types'].get(error_type, 0) + 1\n",
        "\n",
        "                    if len(field_stats['examples']['incorrect']) < 3:\n",
        "                        field_stats['examples']['incorrect'].append({\n",
        "                            'manual': manual_value,\n",
        "                            'auto': auto_value,\n",
        "                            'error_type': error_type,\n",
        "                            'pair_idx': pair_idx,\n",
        "                            'notes': field_result.get('notes', '')\n",
        "                        })\n",
        "\n",
        "                # 计算加权分数\n",
        "                weight = field_config['weight']\n",
        "                weighted_score += field_result['score'] * weight\n",
        "                total_weight += weight\n",
        "\n",
        "            # 计算该对KPI的元数据总分\n",
        "            if total_weight > 0:\n",
        "                pair_results['pair_metadata_score'] = weighted_score / total_weight\n",
        "\n",
        "            metadata_results['detailed_results'].append(pair_results)\n",
        "\n",
        "        # 计算整体分数\n",
        "        self._calculate_overall_metadata_scores(metadata_results, all_fields)\n",
        "\n",
        "        # 分析问题字段\n",
        "        self._analyze_problematic_fields(metadata_results)\n",
        "\n",
        "        self.metadata_results = metadata_results\n",
        "        logging.info(f\"元数据验证完成，共验证 {len(matched_pairs)} 对KPI\")\n",
        "\n",
        "        return metadata_results\n",
        "\n",
        "    def _calculate_overall_metadata_scores(self, metadata_results: Dict, all_fields: Dict):\n",
        "        \"\"\"计算整体元数据分数\"\"\"\n",
        "        overall_scores = metadata_results['overall_scores']\n",
        "\n",
        "        # 按类别计算分数\n",
        "        for category, fields in self.metadata_fields.items():\n",
        "            category_score = 0.0\n",
        "            category_weight = 0.0\n",
        "\n",
        "            for field_name, field_config in fields.items():\n",
        "                field_stats = metadata_results['field_results'][field_name]\n",
        "                if field_stats['total_comparisons'] > 0:\n",
        "                    field_accuracy = field_stats['correct_count'] / field_stats['total_comparisons']\n",
        "                    field_avg_score = field_stats['total_score'] / field_stats['total_comparisons']\n",
        "\n",
        "                    # 使用平均分数而不是简单的正确率\n",
        "                    category_score += field_avg_score * field_config['weight']\n",
        "                    category_weight += field_config['weight']\n",
        "\n",
        "            if category_weight > 0:\n",
        "                overall_scores[category] = category_score / category_weight\n",
        "            else:\n",
        "                overall_scores[category] = 0.0\n",
        "\n",
        "        # 计算总体元数据分数\n",
        "        total_score = 0.0\n",
        "        total_weight = 0.0\n",
        "\n",
        "        for field_name, field_config in all_fields.items():\n",
        "            field_stats = metadata_results['field_results'][field_name]\n",
        "            if field_stats['total_comparisons'] > 0:\n",
        "                field_avg_score = field_stats['total_score'] / field_stats['total_comparisons']\n",
        "                total_score += field_avg_score * field_config['weight']\n",
        "                total_weight += field_config['weight']\n",
        "\n",
        "        if total_weight > 0:\n",
        "            overall_scores['overall_metadata_score'] = total_score / total_weight\n",
        "        else:\n",
        "            overall_scores['overall_metadata_score'] = 0.0\n",
        "\n",
        "    def _analyze_problematic_fields(self, metadata_results: Dict):\n",
        "        \"\"\"分析问题字段的详细情况\"\"\"\n",
        "        problematic_analysis = metadata_results['problematic_field_analysis']\n",
        "\n",
        "        for field_name, issue_type in self.problematic_fields.items():\n",
        "            if field_name in metadata_results['field_results']:\n",
        "                field_stats = metadata_results['field_results'][field_name]\n",
        "\n",
        "                if field_stats['total_comparisons'] > 0:\n",
        "                    accuracy = field_stats['correct_count'] / field_stats['total_comparisons']\n",
        "                    avg_score = field_stats['total_score'] / field_stats['total_comparisons']\n",
        "\n",
        "                    problematic_analysis[field_name] = {\n",
        "                        'issue_type': issue_type,\n",
        "                        'accuracy': accuracy,\n",
        "                        'average_score': avg_score,\n",
        "                        'total_errors': field_stats['total_comparisons'] - field_stats['correct_count'],\n",
        "                        'error_breakdown': field_stats['error_types'],\n",
        "                        'severity': self._assess_field_severity(accuracy, field_name),\n",
        "                        'improvement_priority': self._get_improvement_priority(field_name, accuracy)\n",
        "                    }\n",
        "\n",
        "    def _assess_field_severity(self, accuracy: float, field_name: str) -> str:\n",
        "        \"\"\"评估字段问题的严重程度\"\"\"\n",
        "        if accuracy >= 0.9:\n",
        "            return \"low\"\n",
        "        elif accuracy >= 0.7:\n",
        "            return \"medium\"\n",
        "        elif accuracy >= 0.5:\n",
        "            return \"high\"\n",
        "        else:\n",
        "            return \"critical\"\n",
        "\n",
        "    def _get_improvement_priority(self, field_name: str, accuracy: float) -> str:\n",
        "        \"\"\"获取改进优先级\"\"\"\n",
        "        field_importance = {\n",
        "            'Absolute Page Number': 'medium',  # 您说会升级\n",
        "            'kpi_theme': 'high',  # 重要分类字段\n",
        "            'quantitative_value': 'critical'  # 最重要的数值字段\n",
        "        }\n",
        "\n",
        "        importance = field_importance.get(field_name, 'low')\n",
        "\n",
        "        if accuracy < 0.5 and importance in ['high', 'critical']:\n",
        "            return 'urgent'\n",
        "        elif accuracy < 0.7 and importance == 'critical':\n",
        "            return 'high'\n",
        "        elif accuracy < 0.8 and importance in ['high', 'critical']:\n",
        "            return 'medium'\n",
        "        else:\n",
        "            return 'low'\n",
        "\n",
        "    def generate_metadata_report(self) -> str:\n",
        "        \"\"\"生成元数据验证报告\"\"\"\n",
        "        if not self.metadata_results:\n",
        "            return \"No metadata validation results available. Please run validate_metadata_for_matched_pairs() first.\"\n",
        "\n",
        "        results = self.metadata_results\n",
        "        overall_scores = results['overall_scores']\n",
        "\n",
        "        report = f\"\"\"\n",
        "# 元数据验证报告 (KPI文本验证独立报告)\n",
        "\n",
        "## 验证概览\n",
        "- **验证KPI对数**: {results['total_pairs']}\n",
        "- **总体元数据分数**: {overall_scores.get('overall_metadata_score', 0):.3f}\n",
        "- **验证时间**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "## 分类得分\n",
        "\n",
        "### 文档相关字段 ({overall_scores.get('document_fields', 0):.3f})\n",
        "\"\"\"\n",
        "\n",
        "        # 添加各类别详细分数\n",
        "        for category, category_score in overall_scores.items():\n",
        "            if category.endswith('_fields'):\n",
        "                category_name = category.replace('_', ' ').title()\n",
        "                report += f\"- **{category_name}**: {category_score:.3f}\\n\"\n",
        "\n",
        "        report += \"\\n## 字段详细分析\\n\\n\"\n",
        "        report += \"| 字段名 | 准确率 | 平均分数 | 错误数 | 主要错误类型 |\\n\"\n",
        "        report += \"|--------|--------|----------|--------|-------------|\\n\"\n",
        "\n",
        "        # 按准确率排序显示字段\n",
        "        field_items = list(results['field_results'].items())\n",
        "        field_items.sort(key=lambda x: x[1]['correct_count'] / max(x[1]['total_comparisons'], 1))\n",
        "\n",
        "        for field_name, field_stats in field_items:\n",
        "            if field_stats['total_comparisons'] > 0:\n",
        "                accuracy = field_stats['correct_count'] / field_stats['total_comparisons']\n",
        "                avg_score = field_stats['total_score'] / field_stats['total_comparisons']\n",
        "                error_count = field_stats['total_comparisons'] - field_stats['correct_count']\n",
        "\n",
        "                main_error = max(field_stats['error_types'].items(),\n",
        "                               key=lambda x: x[1], default=('none', 0))[0]\n",
        "\n",
        "                report += f\"| {field_name} | {accuracy:.3f} | {avg_score:.3f} | {error_count} | {main_error} |\\n\"\n",
        "\n",
        "        # 问题字段重点分析\n",
        "        if results['problematic_field_analysis']:\n",
        "            report += \"\\n## 重点关注字段分析\\n\\n\"\n",
        "\n",
        "            for field_name, analysis in results['problematic_field_analysis'].items():\n",
        "                report += f\"### {field_name} ({analysis['issue_type']})\\n\"\n",
        "                report += f\"- **准确率**: {analysis['accuracy']:.3f}\\n\"\n",
        "                report += f\"- **平均分数**: {analysis['average_score']:.3f}\\n\"\n",
        "                report += f\"- **错误数**: {analysis['total_errors']}\\n\"\n",
        "                report += f\"- **严重程度**: {analysis['severity']}\\n\"\n",
        "                report += f\"- **改进优先级**: {analysis['improvement_priority']}\\n\"\n",
        "\n",
        "                if analysis['error_breakdown']:\n",
        "                    report += \"- **错误类型分布**:\\n\"\n",
        "                    for error_type, count in analysis['error_breakdown'].items():\n",
        "                        report += f\"  - {error_type}: {count}\\n\"\n",
        "                report += \"\\n\"\n",
        "\n",
        "        # 改进建议\n",
        "        report += \"## 改进建议\\n\\n\"\n",
        "\n",
        "        critical_fields = [name for name, analysis in results['problematic_field_analysis'].items()\n",
        "                          if analysis['improvement_priority'] in ['urgent', 'high']]\n",
        "\n",
        "        if critical_fields:\n",
        "            report += \"### 优先改进字段:\\n\"\n",
        "            for field in critical_fields:\n",
        "                analysis = results['problematic_field_analysis'][field]\n",
        "                report += f\"- **{field}**: {analysis['issue_type']} (优先级: {analysis['improvement_priority']})\\n\"\n",
        "\n",
        "        report += \"\\n### 具体建议:\\n\"\n",
        "        if 'Absolute Page Number' in results['problematic_field_analysis']:\n",
        "            report += \"- **页码提取**: 考虑改进PDF页码识别算法\\n\"\n",
        "        if 'kpi_theme' in results['problematic_field_analysis']:\n",
        "            report += \"- **主题分类**: 优化KPI主题分类逻辑\\n\"\n",
        "        if 'quantitative_value' in results['problematic_field_analysis']:\n",
        "            report += \"- **数值提取**: 加强数值识别和标准化处理\\n\"\n",
        "\n",
        "        return report\n",
        "\n",
        "    def save_metadata_validation_results(self, output_dir: str = None):\n",
        "        \"\"\"保存元数据验证结果\"\"\"\n",
        "        if not self.metadata_results:\n",
        "            logging.warning(\"No metadata results to save\")\n",
        "            return {}\n",
        "\n",
        "        if output_dir is None:\n",
        "            output_dir = self.main_validator.output_dir / \"metadata_validation\"\n",
        "\n",
        "        output_path = Path(output_dir)\n",
        "        output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        saved_files = {}\n",
        "\n",
        "        # 1. 保存详细结果JSON\n",
        "        results_file = output_path / \"metadata_validation_results.json\"\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.metadata_results, f, indent=2, ensure_ascii=False, default=str)\n",
        "        saved_files['detailed_json'] = results_file\n",
        "\n",
        "        # 2. 保存字段分析Excel\n",
        "        field_analysis_data = []\n",
        "        for field_name, field_stats in self.metadata_results['field_results'].items():\n",
        "            if field_stats['total_comparisons'] > 0:\n",
        "                accuracy = field_stats['correct_count'] / field_stats['total_comparisons']\n",
        "                avg_score = field_stats['total_score'] / field_stats['total_comparisons']\n",
        "\n",
        "                field_analysis_data.append({\n",
        "                    'Field Name': field_name,\n",
        "                    'Total Comparisons': field_stats['total_comparisons'],\n",
        "                    'Correct Count': field_stats['correct_count'],\n",
        "                    'Accuracy': accuracy,\n",
        "                    'Average Score': avg_score,\n",
        "                    'Error Count': field_stats['total_comparisons'] - field_stats['correct_count'],\n",
        "                    'Main Error Type': max(field_stats['error_types'].items(),\n",
        "                                         key=lambda x: x[1], default=('none', 0))[0]\n",
        "                })\n",
        "\n",
        "        field_df = pd.DataFrame(field_analysis_data)\n",
        "        field_df = field_df.sort_values('Accuracy')\n",
        "\n",
        "        excel_file = output_path / \"metadata_field_analysis.xlsx\"\n",
        "        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
        "            field_df.to_excel(writer, sheet_name='Field Analysis', index=False)\n",
        "\n",
        "            # 问题字段详细分析\n",
        "            if self.metadata_results['problematic_field_analysis']:\n",
        "                prob_data = []\n",
        "                for field_name, analysis in self.metadata_results['problematic_field_analysis'].items():\n",
        "                    prob_data.append({\n",
        "                        'Field Name': field_name,\n",
        "                        'Issue Type': analysis['issue_type'],\n",
        "                        'Accuracy': analysis['accuracy'],\n",
        "                        'Average Score': analysis['average_score'],\n",
        "                        'Total Errors': analysis['total_errors'],\n",
        "                        'Severity': analysis['severity'],\n",
        "                        'Improvement Priority': analysis['improvement_priority']\n",
        "                    })\n",
        "\n",
        "                prob_df = pd.DataFrame(prob_data)\n",
        "                prob_df.to_excel(writer, sheet_name='Problematic Fields', index=False)\n",
        "\n",
        "        saved_files['field_analysis_excel'] = excel_file\n",
        "\n",
        "        # 3. 保存元数据报告\n",
        "        report = self.generate_metadata_report()\n",
        "        report_file = output_path / \"metadata_validation_report.md\"\n",
        "        with open(report_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(report)\n",
        "        saved_files['report_markdown'] = report_file\n",
        "\n",
        "        logging.info(f\"元数据验证结果已保存到: {output_path}\")\n",
        "        return saved_files\n",
        "\n",
        "# 集成函数：在主验证流程中添加元数据验证\n",
        "def run_complete_validation_with_metadata(df_auto: pd.DataFrame, manual_xlsx_path: str,\n",
        "                                         output_dir: str = \"complete_validation\") -> Dict[str, any]:\n",
        "    \"\"\"\n",
        "    运行完整验证（文本验证 + 元数据验证）\n",
        "\n",
        "    Args:\n",
        "        df_auto: 自动提取的KPI DataFrame\n",
        "        manual_xlsx_path: 手动标注文件路径\n",
        "        output_dir: 输出目录\n",
        "\n",
        "    Returns:\n",
        "        完整验证结果\n",
        "    \"\"\"\n",
        "    logging.info(\"开始运行完整验证（文本 + 元数据）...\")\n",
        "\n",
        "    # Step 1: 运行文本验证\n",
        "    print(\"🔍 Step 1: 运行文本验证...\")\n",
        "    text_validation_results = enhanced_compare_with_manual_kpis(\n",
        "        df_auto, manual_xlsx_path, f\"{output_dir}/text_validation\"\n",
        "    )\n",
        "\n",
        "    if not text_validation_results:\n",
        "        logging.error(\"文本验证失败，无法继续元数据验证\")\n",
        "        return {}\n",
        "\n",
        "    # Step 2: 运行元数据验证\n",
        "    print(\"📊 Step 2: 运行元数据验证...\")\n",
        "\n",
        "    # 获取文本验证器实例\n",
        "    temp_auto_path = Path(f\"{output_dir}/text_validation\") / \"temp_auto_kpis.xlsx\"\n",
        "    if not temp_auto_path.exists():\n",
        "        temp_auto_path = Path(output_dir) / \"temp_auto_kpis.xlsx\"\n",
        "        df_auto.to_excel(temp_auto_path, index=False)\n",
        "\n",
        "    main_validator = KPIValidationPipeline(\n",
        "        manual_excel_path=manual_xlsx_path,\n",
        "        auto_excel_path=str(temp_auto_path),\n",
        "        output_dir=f\"{output_dir}/text_validation\"\n",
        "    )\n",
        "\n",
        "    # 确保文本验证已运行\n",
        "    if not hasattr(main_validator, 'validation_results') or not main_validator.validation_results:\n",
        "        main_validator.run_comprehensive_evaluation()\n",
        "\n",
        "    # 创建元数据验证扩展\n",
        "    metadata_validator = MetadataValidationExtension(main_validator)\n",
        "    metadata_results = metadata_validator.validate_metadata_for_matched_pairs()\n",
        "\n",
        "    # 保存元数据验证结果\n",
        "    metadata_saved_files = metadata_validator.save_metadata_validation_results(f\"{output_dir}/metadata_validation\")\n",
        "\n",
        "    # Step 3: 生成综合报告\n",
        "    print(\"📋 Step 3: 生成综合报告...\")\n",
        "    complete_results = {\n",
        "        'text_validation': text_validation_results,\n",
        "        'metadata_validation': metadata_results,\n",
        "        'saved_files': {\n",
        "            'text_validation_files': text_validation_results.get('saved_files', {}),\n",
        "            'metadata_validation_files': metadata_saved_files\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # 打印摘要\n",
        "    text_best = text_validation_results.get('best_metrics', {})\n",
        "    metadata_overall = metadata_results.get('overall_scores', {})\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"完整验证结果摘要\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"📝 文本验证 F1 分数: {text_best.get('f1_score', 0):.3f}\")\n",
        "    print(f\"📊 元数据总体分数: {metadata_overall.get('overall_metadata_score', 0):.3f}\")\n",
        "    print(f\"🎯 验证KPI对数: {metadata_results.get('total_pairs', 0)}\")\n",
        "\n",
        "    print(f\"\\n📂 元数据分类得分:\")\n",
        "    for category, score in metadata_overall.items():\n",
        "        if category.endswith('_fields'):\n",
        "            category_name = category.replace('_', ' ').title()\n",
        "            print(f\"   {category_name}: {score:.3f}\")\n",
        "\n",
        "    # 显示问题字段\n",
        "    if metadata_results.get('problematic_field_analysis'):\n",
        "        print(f\"\\n⚠️  需要关注的字段:\")\n",
        "        for field_name, analysis in metadata_results['problematic_field_analysis'].items():\n",
        "            print(f\"   {field_name}: {analysis['accuracy']:.3f} (优先级: {analysis['improvement_priority']})\")\n",
        "\n",
        "    print(f\"\\n📁 完整结果保存在: {output_dir}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # 清理临时文件\n",
        "    if temp_auto_path.exists():\n",
        "        temp_auto_path.unlink()\n",
        "\n",
        "    return complete_results\n",
        "\n",
        "# 便捷使用函数\n",
        "def add_metadata_validation_to_existing_pipeline():\n",
        "    \"\"\"为现有验证流程添加元数据验证的示例函数\"\"\"\n",
        "\n",
        "    def enhanced_main_with_metadata():\n",
        "        \"\"\"增强版main函数，包含元数据验证\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format=\"%(asctime)s - %(levelname)s: %(message)s\",\n",
        "            datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            if not os.path.exists(PDF_PATH):\n",
        "                logging.error(f\"PDF file not found: {PDF_PATH}\")\n",
        "                return\n",
        "\n",
        "            # 原有的KPI提取流程\n",
        "            df_auto = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "            save_results(df_auto, EXPORT_AUTO_XLSX, PDF_PATH)\n",
        "            logging.info(f\"KPI extraction completed: {len(df_auto)} KPIs extracted\")\n",
        "\n",
        "            # 增强的验证流程（文本 + 元数据）\n",
        "            if MANUAL_XLSX and Path(MANUAL_XLSX).exists():\n",
        "                print(\"\\n🔍 Running complete validation (text + metadata)...\")\n",
        "                complete_validation_results = run_complete_validation_with_metadata(\n",
        "                    df_auto, MANUAL_XLSX, \"complete_validation\"\n",
        "                )\n",
        "\n",
        "                if complete_validation_results:\n",
        "                    print(\"✅ Complete validation finished with detailed analysis!\")\n",
        "                    print(f\"📁 Detailed results saved to: complete_validation/\")\n",
        "                else:\n",
        "                    print(\"⚠️ Validation encountered issues\")\n",
        "            else:\n",
        "                logging.info(\"Manual KPI file not found, skipping validation.\")\n",
        "\n",
        "            # 显示提取摘要（保持原有逻辑）\n",
        "            if not df_auto.empty:\n",
        "                print(f\"\\n=== Extraction Summary ===\")\n",
        "                print(f\"Total KPIs extracted: {len(df_auto)}\")\n",
        "\n",
        "                if 'source_type' in df_auto.columns:\n",
        "                    source_counts = df_auto['source_type'].value_counts()\n",
        "                    print(f\"From text/tables: {source_counts.get('text', 0)}\")\n",
        "                    print(f\"From images/charts: {source_counts.get('image', 0)}\")\n",
        "\n",
        "                if 'kpi_theme' in df_auto.columns:\n",
        "                    theme_counts = df_auto['kpi_theme'].value_counts()\n",
        "                    print(f\"\\nKPI Distribution by Theme:\")\n",
        "                    for theme, count in theme_counts.items():\n",
        "                        print(f\"  {theme}: {count}\")\n",
        "            else:\n",
        "                print(\"\\nNo KPIs were extracted from the document.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in enhanced main execution: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    return enhanced_main_with_metadata\n",
        "\n",
        "#     # 🔥 在这里添加新方法（在类的最后，但在类结束之前）\n",
        "#     def explain_quantitative_value_validation(self) -> str:\n",
        "#         \"\"\"详细解释 quantitative_value 字段的验证逻辑\"\"\"\n",
        "\n",
        "#         explanation = \"\"\"\n",
        "# # Quantitative Value Validation Explained\n",
        "\n",
        "# ## What is 'quantitative_value'?\n",
        "\n",
        "# The 'quantitative_value' field contains the specific numerical data extracted from KPI text. This is arguably the most important field because it contains the actual performance data.\n",
        "\n",
        "# ### Examples:\n",
        "\n",
        "# | KPI Text | quantitative_value | Notes |\n",
        "# |----------|-------------------|--------|\n",
        "# | \"Reduced emissions by 25.5%\" | \"25.5\" | Percentage extracted without % symbol |\n",
        "# | \"Invested $1.5 million in clean energy\" | \"1.5\" | Million extracted, units in separate field |\n",
        "# | \"89.4% renewable energy usage\" | \"89.4\" | Decimal percentage format |\n",
        "# | \"Zero workplace fatalities\" | \"0\" | Zero values are still quantitative |\n",
        "\n",
        "# ## Validation Challenges:\n",
        "\n",
        "# ### 1. Number Format Variations\n",
        "# Manual: \"1,500 employees\"     → quantitative_value: \"1500\"\n",
        "# Auto:   \"1500 employees\"      → quantitative_value: \"1500\"\n",
        "# Result: ✅ Match (after normalization)\n",
        "# Manual: \"25.50%\"              → quantitative_value: \"25.5\"\n",
        "# Auto:   \"25.5%\"               → quantitative_value: \"25.5\"\n",
        "# Result: ✅ Match\n",
        "\n",
        "# ### 2. Unit Handling\n",
        "# Manual: \"25 kg CO2\"           → quantitative_value: \"25\"\n",
        "# Auto:   \"25kg CO2\"            → quantitative_value: \"25kg\"\n",
        "# Result: ❌ Mismatch (units shouldn't be in quantitative_value)\n",
        "\n",
        "# ### 3. Precision Differences\n",
        "# Manual: \"25.48%\"              → quantitative_value: \"25.48\"\n",
        "# Auto:   \"25.5%\"               → quantitative_value: \"25.5\"\n",
        "# Result: ⚠️  Close match (within tolerance)\n",
        "\n",
        "# ## Why This Validation Matters:\n",
        "\n",
        "# 1. **Data Accuracy**: Ensures the core numerical data is correctly extracted\n",
        "# 2. **Downstream Analysis**: Incorrect values affect all subsequent calculations\n",
        "# 3. **Compliance**: Financial and regulatory reporting requires precise numbers\n",
        "# 4. **Trust**: Stakeholders rely on accurate performance data\n",
        "\n",
        "# ## Validation Methodology:\n",
        "\n",
        "# Our validation uses tolerance-based comparison:\n",
        "\n",
        "# ```python\n",
        "# def _normalize_numerical_value(self, value_str: str) -> float:\n",
        "#     # Remove common non-numeric characters\n",
        "#     cleaned = re.sub(r'[^\\\\d\\\\.\\\\-\\\\+]', '', str(value_str))\n",
        "#     return float(cleaned) if cleaned else None\n",
        "\n",
        "# def validate_numerical_field(self, manual_value, auto_value):\n",
        "#     manual_num = self._normalize_numerical_value(manual_value)\n",
        "#     auto_num = self._normalize_numerical_value(auto_value)\n",
        "\n",
        "#     # Allow small tolerance for rounding differences\n",
        "#     tolerance = 0.01 if abs(manual_num) < 10 else abs(manual_num) * 0.001\n",
        "#     is_match = abs(manual_num - auto_num) <= tolerance\n",
        "\n",
        "# This approach handles:\n",
        "\n",
        "# Format differences (commas, spaces)\n",
        "# Minor rounding differences\n",
        "# Different precision levels\n",
        "# Scientific notation\n",
        "\n",
        "# The validation helps identify systematic extraction errors and improves the overall quality of KPI data extraction.\n",
        "# \"\"\"\n",
        "#     return explanation\n",
        "\n",
        "#     def generate_field_explanation_report(self) -> str:\n",
        "#     \"\"\"生成字段解释报告\"\"\"\n",
        "\n",
        "#     # 详细的字段解释\n",
        "#     self.field_explanations = {\n",
        "#         'quantitative_value': {\n",
        "#             'description': 'The specific numerical value extracted from KPI text',\n",
        "#             'examples': ['25.5', '1500', '89.4%', '0.73'],\n",
        "#             'importance': 'Critical - this is the core data point of any KPI',\n",
        "#             'validation_challenges': [\n",
        "#                 'Different number formats (1,500 vs 1500)',\n",
        "#                 'Percentage vs decimal (25% vs 0.25)',\n",
        "#                 'Units included in value (25kg vs 25)',\n",
        "#                 'Precision differences (25.5 vs 25.48)'\n",
        "#             ],\n",
        "#             'why_validate': 'Ensures numerical accuracy of extracted data'\n",
        "#         },\n",
        "#         'kpi_theme': {\n",
        "#             'description': 'High-level categorization of KPI (Environmental/Social/Governance)',\n",
        "#             'examples': ['Environmental', 'Social', 'Governance'],\n",
        "#             'importance': 'High - enables proper categorization and reporting',\n",
        "#             'validation_challenges': [\n",
        "#                 'Borderline cases (employee safety: Social or Governance?)',\n",
        "#                 'Inconsistent classification between manual and auto'\n",
        "#             ],\n",
        "#             'why_validate': 'Ensures consistent thematic classification'\n",
        "#         },\n",
        "#         'Absolute Page Number': {\n",
        "#             'description': 'The page number in the PDF where the KPI was found',\n",
        "#             'examples': ['15', '23-24', 'Unknown'],\n",
        "#             'importance': 'Medium - helps with source verification and auditing',\n",
        "#             'validation_challenges': [\n",
        "#                 'Different page numbering systems',\n",
        "#                 'Multi-page KPIs',\n",
        "#                 'Table/image spanning multiple pages'\n",
        "#             ],\n",
        "#             'why_validate': 'Enables source traceability and verification'\n",
        "#         }\n",
        "#     }\n",
        "\n",
        "#     report =\n",
        "#     \"\"\"\n",
        "#     Metadata Validation Field Explanations\n",
        "#     This report explains what each metadata field represents and why its validation is important for KPI extraction quality.\n",
        "#     \"\"\"\n",
        "#     for field_name, info in self.field_explanations.items():\n",
        "#         report += f\"\"\"\n",
        "#         {field_name}\n",
        "#         Description: {info['description']}\n",
        "#         Examples: {', '.join(info['examples'])}\n",
        "#         Importance Level: {info['importance']}\n",
        "#         Why We Validate This Field:\n",
        "#         {info['why_validate']}\n",
        "#         Validation Challenges:\n",
        "#     \"\"\"\n",
        "#     for challenge in info['validation_challenges']:\n",
        "#     report += f\"- {challenge}\\n\"\n",
        "#     # 添加quantitative_value的详细解释\n",
        "#     report += \"\\n\" + self.explain_quantitative_value_validation()\n",
        "\n",
        "#     return report\n",
        "\n",
        "#     # 类在这里结束\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HfzJhUgy3OtK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "e66e1186-bf39-41e4-a3ed-d17596d7c709"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 783 (ipython-input-456360646.py, line 784)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-456360646.py\"\u001b[0;36m, line \u001b[0;32m784\u001b[0m\n\u001b[0;31m    \"\"\"生成字段解释报告\"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any\n",
        "import pandas as pd\n",
        "\n",
        "class MetadataValidationExtension:\n",
        "    \"\"\"元数据验证扩展 - 验证KPI文本以外的字段准确性\"\"\"\n",
        "\n",
        "    def __init__(self, validation_pipeline):\n",
        "        \"\"\"\n",
        "        基于现有的KPIValidationPipeline扩展元数据验证功能\n",
        "\n",
        "        Args:\n",
        "            validation_pipeline: 现有的验证管道实例\n",
        "        \"\"\"\n",
        "        self.main_validator = validation_pipeline\n",
        "        self.metadata_results = {}\n",
        "\n",
        "        # 需要验证的元数据字段配置\n",
        "        self.metadata_fields = {\n",
        "            # 文档相关字段\n",
        "            'document_fields': {\n",
        "                'PDF file name': {'weight': 0.05, 'type': 'exact'},\n",
        "                'Title of the report': {'weight': 0.05, 'type': 'exact'},\n",
        "                'Absolute Page Number': {'weight': 0.15, 'type': 'exact'},  # 您提到的问题字段\n",
        "                'Impacted Stakeholder': {'weight': 0.10, 'type': 'similarity'}\n",
        "            },\n",
        "\n",
        "            # KPI分类字段\n",
        "            'classification_fields': {\n",
        "                'kpi_theme': {'weight': 0.15, 'type': 'exact'},  # 您提到的问题字段\n",
        "                'kpi_category': {'weight': 0.15, 'type': 'similarity'}\n",
        "            },\n",
        "\n",
        "            # 数值相关字段\n",
        "            'quantitative_fields': {\n",
        "                'quantitative_value': {'weight': 0.20, 'type': 'numerical'},  # 您提到的问题字段\n",
        "                'unit': {'weight': 0.10, 'type': 'similarity'},\n",
        "                'time_period': {'weight': 0.05, 'type': 'similarity'}\n",
        "            },\n",
        "\n",
        "            # 其他分析字段\n",
        "            'analysis_fields': {\n",
        "                'target_or_actual': {'weight': 0.05, 'type': 'exact'},\n",
        "                'source_type': {'weight': 0.05, 'type': 'exact'},\n",
        "                'chart_type': {'weight': 0.03, 'type': 'similarity'},\n",
        "                'estimation_confidence': {'weight': 0.02, 'type': 'exact'},\n",
        "                'chart_title': {'weight': 0.03, 'type': 'similarity'},\n",
        "                'data_source': {'weight': 0.02, 'type': 'similarity'},\n",
        "                'image_type': {'weight': 0.02, 'type': 'exact'}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # 问题字段标记（您特别关注的字段）\n",
        "        self.problematic_fields = {\n",
        "            'Absolute Page Number': 'page_number_issues',\n",
        "            'kpi_theme': 'theme_classification_issues',\n",
        "            'quantitative_value': 'value_extraction_issues'\n",
        "        }\n",
        "\n",
        "        logging.info(\"元数据验证扩展初始化完成\")\n",
        "\n",
        "    def validate_single_field(self, manual_value, auto_value, field_name: str, validation_type: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        验证单个字段的准确性\n",
        "\n",
        "        Args:\n",
        "            manual_value: 手动标注值\n",
        "            auto_value: 自动提取值\n",
        "            field_name: 字段名称\n",
        "            validation_type: 验证类型 ('exact', 'similarity', 'numerical')\n",
        "\n",
        "        Returns:\n",
        "            验证结果字典\n",
        "        \"\"\"\n",
        "        result = {\n",
        "            'field_name': field_name,\n",
        "            'manual_value': manual_value,\n",
        "            'auto_value': auto_value,\n",
        "            'validation_type': validation_type,\n",
        "            'is_correct': False,\n",
        "            'score': 0.0,\n",
        "            'error_type': None,\n",
        "            'notes': \"\"\n",
        "        }\n",
        "\n",
        "        # 处理空值情况\n",
        "        manual_clean = str(manual_value).strip() if pd.notna(manual_value) else \"\"\n",
        "        auto_clean = str(auto_value).strip() if pd.notna(auto_value) else \"\"\n",
        "\n",
        "        if not manual_clean and not auto_clean:\n",
        "            result.update({'is_correct': True, 'score': 1.0, 'notes': 'Both values empty'})\n",
        "            return result\n",
        "        elif not manual_clean or not auto_clean:\n",
        "            result.update({'error_type': 'missing_value', 'notes': 'One value is missing'})\n",
        "            return result\n",
        "\n",
        "        # 根据验证类型进行比较\n",
        "        if validation_type == 'exact':\n",
        "            is_match = manual_clean.lower() == auto_clean.lower()\n",
        "            result.update({\n",
        "                'is_correct': is_match,\n",
        "                'score': 1.0 if is_match else 0.0,\n",
        "                'error_type': None if is_match else 'exact_mismatch'\n",
        "            })\n",
        "\n",
        "        elif validation_type == 'similarity':\n",
        "            # 使用主验证器的文本相似度算法\n",
        "            similarity_scores = self.main_validator.calculate_text_similarity(manual_clean, auto_clean)\n",
        "            similarity = similarity_scores['combined']\n",
        "\n",
        "            # 对于元数据，使用更高的相似度阈值\n",
        "            threshold = 0.8\n",
        "            is_match = similarity >= threshold\n",
        "\n",
        "            result.update({\n",
        "                'is_correct': is_match,\n",
        "                'score': similarity,\n",
        "                'similarity_details': similarity_scores,\n",
        "                'error_type': None if is_match else 'similarity_mismatch',\n",
        "                'notes': f'Similarity: {similarity:.3f}'\n",
        "            })\n",
        "\n",
        "        elif validation_type == 'numerical':\n",
        "            try:\n",
        "                # 标准化数值格式\n",
        "                manual_num = self._normalize_numerical_value(manual_clean)\n",
        "                auto_num = self._normalize_numerical_value(auto_clean)\n",
        "\n",
        "                if manual_num is not None and auto_num is not None:\n",
        "                    # 允许小幅度差异（适应提取中的舍入误差）\n",
        "                    tolerance = 0.01 if abs(manual_num) < 10 else abs(manual_num) * 0.001\n",
        "                    is_match = abs(manual_num - auto_num) <= tolerance\n",
        "\n",
        "                    result.update({\n",
        "                        'is_correct': is_match,\n",
        "                        'score': 1.0 if is_match else max(0.0, 1.0 - abs(manual_num - auto_num) / max(abs(manual_num), 1)),\n",
        "                        'error_type': None if is_match else 'numerical_mismatch',\n",
        "                        'manual_parsed': manual_num,\n",
        "                        'auto_parsed': auto_num,\n",
        "                        'notes': f'Manual: {manual_num}, Auto: {auto_num}'\n",
        "                    })\n",
        "                else:\n",
        "                    result.update({\n",
        "                        'error_type': 'numerical_parse_error',\n",
        "                        'notes': f'Failed to parse numerical values: \"{manual_clean}\" vs \"{auto_clean}\"'\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                result.update({\n",
        "                    'error_type': 'numerical_validation_error',\n",
        "                    'notes': f'Numerical validation failed: {str(e)}'\n",
        "                })\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _normalize_numerical_value(self, value_str: str) -> float:\n",
        "        \"\"\"标准化数值字符串为float\"\"\"\n",
        "        if not value_str:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # 移除常见的非数字字符，保留数字、小数点、负号\n",
        "            cleaned = re.sub(r'[^\\d\\.\\-\\+]', '', str(value_str))\n",
        "            if cleaned:\n",
        "                return float(cleaned)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # 尝试提取第一个数字\n",
        "        numbers = re.findall(r'-?\\d+\\.?\\d*', str(value_str))\n",
        "        if numbers:\n",
        "            try:\n",
        "                return float(numbers[0])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        return None\n",
        "\n",
        "    def validate_metadata_for_matched_pairs(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        对已匹配的KPI对进行元数据验证\n",
        "\n",
        "        Returns:\n",
        "            元数据验证结果\n",
        "        \"\"\"\n",
        "        logging.info(\"开始元数据验证...\")\n",
        "\n",
        "        # 获取主验证器的匹配结果\n",
        "        if not hasattr(self.main_validator, 'validation_results') or not self.main_validator.validation_results:\n",
        "            logging.error(\"主验证器尚未运行，请先运行文本验证\")\n",
        "            return {}\n",
        "\n",
        "        matched_pairs = self.main_validator.validation_results.get('detailed_matches', [])\n",
        "        if not matched_pairs:\n",
        "            logging.warning(\"没有找到匹配的KPI对，无法进行元数据验证\")\n",
        "            return {}\n",
        "\n",
        "        metadata_results = {\n",
        "            'total_pairs': len(matched_pairs),\n",
        "            'field_results': {},\n",
        "            'overall_scores': {},\n",
        "            'problematic_field_analysis': {},\n",
        "            'detailed_results': []\n",
        "        }\n",
        "\n",
        "        # 初始化字段结果统计\n",
        "        all_fields = {}\n",
        "        for category, fields in self.metadata_fields.items():\n",
        "            all_fields.update(fields)\n",
        "\n",
        "        for field_name in all_fields.keys():\n",
        "            metadata_results['field_results'][field_name] = {\n",
        "                'total_comparisons': 0,\n",
        "                'correct_count': 0,\n",
        "                'total_score': 0.0,\n",
        "                'error_types': {},\n",
        "                'examples': {'correct': [], 'incorrect': []}\n",
        "            }\n",
        "\n",
        "        # 对每个匹配对进行元数据验证\n",
        "        for pair_idx, match_pair in enumerate(matched_pairs):\n",
        "            manual_idx = match_pair['manual_idx']\n",
        "            auto_idx = match_pair['auto_idx']\n",
        "            text_similarity = match_pair['similarity']\n",
        "\n",
        "            # 获取完整的KPI记录\n",
        "            manual_kpi = self.main_validator.manual_df.iloc[manual_idx]\n",
        "            auto_kpi = self.main_validator.auto_df.iloc[auto_idx]\n",
        "\n",
        "            pair_results = {\n",
        "                'pair_index': pair_idx,\n",
        "                'manual_idx': manual_idx,\n",
        "                'auto_idx': auto_idx,\n",
        "                'text_similarity': text_similarity,\n",
        "                'manual_text': match_pair['manual_text'],\n",
        "                'auto_text': match_pair['auto_text'],\n",
        "                'field_validations': {},\n",
        "                'pair_metadata_score': 0.0\n",
        "            }\n",
        "\n",
        "            total_weight = 0.0\n",
        "            weighted_score = 0.0\n",
        "\n",
        "            # 验证每个元数据字段\n",
        "            for field_name, field_config in all_fields.items():\n",
        "                manual_value = manual_kpi.get(field_name, '')\n",
        "                auto_value = auto_kpi.get(field_name, '')\n",
        "\n",
        "                field_result = self.validate_single_field(\n",
        "                    manual_value, auto_value, field_name, field_config['type']\n",
        "                )\n",
        "\n",
        "                pair_results['field_validations'][field_name] = field_result\n",
        "\n",
        "                # 更新字段统计\n",
        "                field_stats = metadata_results['field_results'][field_name]\n",
        "                field_stats['total_comparisons'] += 1\n",
        "                field_stats['total_score'] += field_result['score']\n",
        "\n",
        "                if field_result['is_correct']:\n",
        "                    field_stats['correct_count'] += 1\n",
        "                    if len(field_stats['examples']['correct']) < 3:\n",
        "                        field_stats['examples']['correct'].append({\n",
        "                            'manual': manual_value,\n",
        "                            'auto': auto_value,\n",
        "                            'pair_idx': pair_idx\n",
        "                        })\n",
        "                else:\n",
        "                    error_type = field_result.get('error_type', 'unknown')\n",
        "                    field_stats['error_types'][error_type] = field_stats['error_types'].get(error_type, 0) + 1\n",
        "\n",
        "                    if len(field_stats['examples']['incorrect']) < 3:\n",
        "                        field_stats['examples']['incorrect'].append({\n",
        "                            'manual': manual_value,\n",
        "                            'auto': auto_value,\n",
        "                            'error_type': error_type,\n",
        "                            'pair_idx': pair_idx,\n",
        "                            'notes': field_result.get('notes', '')\n",
        "                        })\n",
        "\n",
        "                # 计算加权分数\n",
        "                weight = field_config['weight']\n",
        "                weighted_score += field_result['score'] * weight\n",
        "                total_weight += weight\n",
        "\n",
        "            # 计算该对KPI的元数据总分\n",
        "            if total_weight > 0:\n",
        "                pair_results['pair_metadata_score'] = weighted_score / total_weight\n",
        "\n",
        "            metadata_results['detailed_results'].append(pair_results)\n",
        "\n",
        "        # 计算整体分数\n",
        "        self._calculate_overall_metadata_scores(metadata_results, all_fields)\n",
        "\n",
        "        # 分析问题字段\n",
        "        self._analyze_problematic_fields(metadata_results)\n",
        "\n",
        "        self.metadata_results = metadata_results\n",
        "        logging.info(f\"元数据验证完成，共验证 {len(matched_pairs)} 对KPI\")\n",
        "\n",
        "        return metadata_results\n",
        "\n",
        "    def _calculate_overall_metadata_scores(self, metadata_results: Dict, all_fields: Dict):\n",
        "        \"\"\"计算整体元数据分数\"\"\"\n",
        "        overall_scores = metadata_results['overall_scores']\n",
        "\n",
        "        # 按类别计算分数\n",
        "        for category, fields in self.metadata_fields.items():\n",
        "            category_score = 0.0\n",
        "            category_weight = 0.0\n",
        "\n",
        "            for field_name, field_config in fields.items():\n",
        "                field_stats = metadata_results['field_results'][field_name]\n",
        "                if field_stats['total_comparisons'] > 0:\n",
        "                    field_accuracy = field_stats['correct_count'] / field_stats['total_comparisons']\n",
        "                    field_avg_score = field_stats['total_score'] / field_stats['total_comparisons']\n",
        "\n",
        "                    # 使用平均分数而不是简单的正确率\n",
        "                    category_score += field_avg_score * field_config['weight']\n",
        "                    category_weight += field_config['weight']\n",
        "\n",
        "            if category_weight > 0:\n",
        "                overall_scores[category] = category_score / category_weight\n",
        "            else:\n",
        "                overall_scores[category] = 0.0\n",
        "\n",
        "        # 计算总体元数据分数\n",
        "        total_score = 0.0\n",
        "        total_weight = 0.0\n",
        "\n",
        "        for field_name, field_config in all_fields.items():\n",
        "            field_stats = metadata_results['field_results'][field_name]\n",
        "            if field_stats['total_comparisons'] > 0:\n",
        "                field_avg_score = field_stats['total_score'] / field_stats['total_comparisons']\n",
        "                total_score += field_avg_score * field_config['weight']\n",
        "                total_weight += field_config['weight']\n",
        "\n",
        "        if total_weight > 0:\n",
        "            overall_scores['overall_metadata_score'] = total_score / total_weight\n",
        "        else:\n",
        "            overall_scores['overall_metadata_score'] = 0.0\n",
        "\n",
        "    def _analyze_problematic_fields(self, metadata_results: Dict):\n",
        "        \"\"\"分析问题字段的详细情况\"\"\"\n",
        "        problematic_analysis = metadata_results['problematic_field_analysis']\n",
        "\n",
        "        for field_name, issue_type in self.problematic_fields.items():\n",
        "            if field_name in metadata_results['field_results']:\n",
        "                field_stats = metadata_results['field_results'][field_name]\n",
        "\n",
        "                if field_stats['total_comparisons'] > 0:\n",
        "                    accuracy = field_stats['correct_count'] / field_stats['total_comparisons']\n",
        "                    avg_score = field_stats['total_score'] / field_stats['total_comparisons']\n",
        "\n",
        "                    problematic_analysis[field_name] = {\n",
        "                        'issue_type': issue_type,\n",
        "                        'accuracy': accuracy,\n",
        "                        'average_score': avg_score,\n",
        "                        'total_errors': field_stats['total_comparisons'] - field_stats['correct_count'],\n",
        "                        'error_breakdown': field_stats['error_types'],\n",
        "                        'severity': self._assess_field_severity(accuracy, field_name),\n",
        "                        'improvement_priority': self._get_improvement_priority(field_name, accuracy)\n",
        "                    }\n",
        "\n",
        "    def _assess_field_severity(self, accuracy: float, field_name: str) -> str:\n",
        "        \"\"\"评估字段问题的严重程度\"\"\"\n",
        "        if accuracy >= 0.9:\n",
        "            return \"low\"\n",
        "        elif accuracy >= 0.7:\n",
        "            return \"medium\"\n",
        "        elif accuracy >= 0.5:\n",
        "            return \"high\"\n",
        "        else:\n",
        "            return \"critical\"\n",
        "\n",
        "    def _get_improvement_priority(self, field_name: str, accuracy: float) -> str:\n",
        "        \"\"\"获取改进优先级\"\"\"\n",
        "        field_importance = {\n",
        "            'Absolute Page Number': 'medium',  # 您说会升级\n",
        "            'kpi_theme': 'high',  # 重要分类字段\n",
        "            'quantitative_value': 'critical'  # 最重要的数值字段\n",
        "        }\n",
        "\n",
        "        importance = field_importance.get(field_name, 'low')\n",
        "\n",
        "        if accuracy < 0.5 and importance in ['high', 'critical']:\n",
        "            return 'urgent'\n",
        "        elif accuracy < 0.7 and importance == 'critical':\n",
        "            return 'high'\n",
        "        elif accuracy < 0.8 and importance in ['high', 'critical']:\n",
        "            return 'medium'\n",
        "        else:\n",
        "            return 'low'\n",
        "\n",
        "    def explain_quantitative_value_validation(self) -> str:\n",
        "        \"\"\"详细解释 quantitative_value 字段的验证逻辑\"\"\"\n",
        "\n",
        "        explanation = \"\"\"\n",
        "# Quantitative Value Validation Explained\n",
        "\n",
        "## What is 'quantitative_value'?\n",
        "\n",
        "The 'quantitative_value' field contains the specific numerical data extracted from KPI text. This is arguably the most important field because it contains the actual performance data.\n",
        "\n",
        "### Examples:\n",
        "\n",
        "| KPI Text | quantitative_value | Notes |\n",
        "|----------|-------------------|--------|\n",
        "| \"Reduced emissions by 25.5%\" | \"25.5\" | Percentage extracted without % symbol |\n",
        "| \"Invested $1.5 million in clean energy\" | \"1.5\" | Million extracted, units in separate field |\n",
        "| \"89.4% renewable energy usage\" | \"89.4\" | Decimal percentage format |\n",
        "| \"Zero workplace fatalities\" | \"0\" | Zero values are still quantitative |\n",
        "\n",
        "## Validation Challenges:\n",
        "\n",
        "### 1. Number Format Variations\n",
        "Manual: \"1,500 employees\"     → quantitative_value: \"1500\"\n",
        "Auto:   \"1500 employees\"      → quantitative_value: \"1500\"\n",
        "Result: ✅ Match (after normalization)\n",
        "Manual: \"25.50%\"              → quantitative_value: \"25.5\"\n",
        "Auto:   \"25.5%\"               → quantitative_value: \"25.5\"\n",
        "Result: ✅ Match\n",
        "\n",
        "### 2. Unit Handling\n",
        "Manual: \"25 kg CO2\"           → quantitative_value: \"25\"\n",
        "Auto:   \"25kg CO2\"            → quantitative_value: \"25kg\"\n",
        "Result: ❌ Mismatch (units shouldn't be in quantitative_value)\n",
        "\n",
        "### 3. Precision Differences\n",
        "Manual: \"25.48%\"              → quantitative_value: \"25.48\"\n",
        "Auto:   \"25.5%\"               → quantitative_value: \"25.5\"\n",
        "Result: ⚠️  Close match (within tolerance)\n",
        "\n",
        "## Why This Validation Matters:\n",
        "\n",
        "1. **Data Accuracy**: Ensures the core numerical data is correctly extracted\n",
        "2. **Downstream Analysis**: Incorrect values affect all subsequent calculations\n",
        "3. **Compliance**: Financial and regulatory reporting requires precise numbers\n",
        "4. **Trust**: Stakeholders rely on accurate performance data\n",
        "\n",
        "## Validation Methodology:\n",
        "\n",
        "Our validation uses tolerance-based comparison:\n",
        "\n",
        "```python\n",
        "def _normalize_numerical_value(self, value_str: str) -> float:\n",
        "    # Remove common non-numeric characters\n",
        "    cleaned = re.sub(r'[^\\\\d\\\\.\\\\-\\\\+]', '', str(value_str))\n",
        "    return float(cleaned) if cleaned else None\n",
        "\n",
        "def validate_numerical_field(self, manual_value, auto_value):\n",
        "    manual_num = self._normalize_numerical_value(manual_value)\n",
        "    auto_num = self._normalize_numerical_value(auto_value)\n",
        "\n",
        "    # Allow small tolerance for rounding differences\n",
        "    tolerance = 0.01 if abs(manual_num) < 10 else abs(manual_num) * 0.001\n",
        "    is_match = abs(manual_num - auto_num) <= tolerance\n",
        "```\n",
        "\n",
        "This approach handles:\n",
        "\n",
        "* Format differences (commas, spaces)\n",
        "* Minor rounding differences\n",
        "* Different precision levels\n",
        "* Scientific notation\n",
        "\n",
        "The validation helps identify systematic extraction errors and improves the overall quality of KPI data extraction.\n",
        "\"\"\"\n",
        "        return explanation\n",
        "\n",
        "    def generate_field_explanation_report(self) -> str:\n",
        "        \"\"\"生成字段解释报告\"\"\"\n",
        "\n",
        "        # 详细的字段解释\n",
        "        self.field_explanations = {\n",
        "            'quantitative_value': {\n",
        "                'description': 'The specific numerical value extracted from KPI text',\n",
        "                'examples': ['25.5', '1500', '89.4%', '0.73'],\n",
        "                'importance': 'Critical - this is the core data point of any KPI',\n",
        "                'validation_challenges': [\n",
        "                    'Different number formats (1,500 vs 1500)',\n",
        "                    'Percentage vs decimal (25% vs 0.25)',\n",
        "                    'Units included in value (25kg vs 25)',\n",
        "                    'Precision differences (25.5 vs 25.48)'\n",
        "                ],\n",
        "                'why_validate': 'Ensures numerical accuracy of extracted data'\n",
        "            },\n",
        "            'kpi_theme': {\n",
        "                'description': 'High-level categorization of KPI (Environmental/Social/Governance)',\n",
        "                'examples': ['Environmental', 'Social', 'Governance'],\n",
        "                'importance': 'High - enables proper categorization and reporting',\n",
        "                'validation_challenges': [\n",
        "                    'Borderline cases (employee safety: Social or Governance?)',\n",
        "                    'Inconsistent classification between manual and auto'\n",
        "                ],\n",
        "                'why_validate': 'Ensures consistent thematic classification'\n",
        "            },\n",
        "            'Absolute Page Number': {\n",
        "                'description': 'The page number in the PDF where the KPI was found',\n",
        "                'examples': ['15', '23-24', 'Unknown'],\n",
        "                'importance': 'Medium - helps with source verification and auditing',\n",
        "                'validation_challenges': [\n",
        "                    'Different page numbering systems',\n",
        "                    'Multi-page KPIs',\n",
        "                    'Table/image spanning multiple pages'\n",
        "                ],\n",
        "                'why_validate': 'Enables source traceability and verification'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        report = \"\"\"\n",
        "# Metadata Validation Field Explanations\n",
        "\n",
        "This report explains what each metadata field represents and why its validation is important for KPI extraction quality.\n",
        "\"\"\"\n",
        "\n",
        "        for field_name, info in self.field_explanations.items():\n",
        "            report += f\"\"\"\n",
        "## {field_name}\n",
        "\n",
        "* **Description**: {info['description']}\n",
        "* **Examples**: {', '.join(info['examples'])}\n",
        "* **Importance Level**: {info['importance']}\n",
        "* **Why We Validate This Field**: {info['why_validate']}\n",
        "* **Validation Challenges**:\n",
        "\"\"\"\n",
        "            for challenge in info['validation_challenges']:\n",
        "                report += f\"  - {challenge}\\n\"\n",
        "\n",
        "        # 添加quantitative_value的详细解释\n",
        "        report += \"\\n\" + self.explain_quantitative_value_validation()\n",
        "\n",
        "        return report\n",
        "\n",
        "    def generate_metadata_report(self) -> str:\n",
        "        \"\"\"生成元数据验证报告\"\"\"\n",
        "        if not self.metadata_results:\n",
        "            return \"No metadata validation results available. Please run validate_metadata_for_matched_pairs() first.\"\n",
        "\n",
        "        results = self.metadata_results\n",
        "        overall_scores = results['overall_scores']\n",
        "\n",
        "        report = f\"\"\"\n",
        "# 元数据验证报告 (KPI文本验证独立报告)\n",
        "\n",
        "## 验证概览\n",
        "- **验证KPI对数**: {results['total_pairs']}\n",
        "- **总体元数据分数**: {overall_scores.get('overall_metadata_score', 0):.3f}\n",
        "- **验证时间**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "## 分类得分\n",
        "\n",
        "### 文档相关字段 ({overall_scores.get('document_fields', 0):.3f})\n",
        "\"\"\"\n",
        "\n",
        "        # 添加各类别详细分数\n",
        "        for category, category_score in overall_scores.items():\n",
        "            if category.endswith('_fields'):\n",
        "                category_name = category.replace('_', ' ').title()\n",
        "                report += f\"- **{category_name}**: {category_score:.3f}\\n\"\n",
        "\n",
        "        report += \"\\n## 字段详细分析\\n\\n\"\n",
        "        report += \"| 字段名 | 准确率 | 平均分数 | 错误数 | 主要错误类型 |\\n\"\n",
        "        report += \"|--------|--------|----------|--------|-------------|\\n\"\n",
        "\n",
        "        # 按准确率排序显示字段\n",
        "        field_items = list(results['field_results'].items())\n",
        "        field_items.sort(key=lambda x: x[1]['correct_count'] / max(x[1]['total_comparisons'], 1))\n",
        "\n",
        "        for field_name, field_stats in field_items:\n",
        "            if field_stats['total_comparisons'] > 0:\n",
        "                accuracy = field_stats['correct_count'] / field_stats['total_comparisons']\n",
        "                avg_score = field_stats['total_score'] / field_stats['total_comparisons']\n",
        "                error_count = field_stats['total_comparisons'] - field_stats['correct_count']\n",
        "\n",
        "                main_error = max(field_stats['error_types'].items(),\n",
        "                               key=lambda x: x[1], default=('none', 0))[0]\n",
        "\n",
        "                report += f\"| {field_name} | {accuracy:.3f} | {avg_score:.3f} | {error_count} | {main_error} |\\n\"\n",
        "\n",
        "        # 问题字段重点分析\n",
        "        if results['problematic_field_analysis']:\n",
        "            report += \"\\n## 重点关注字段分析\\n\\n\"\n",
        "\n",
        "            for field_name, analysis in results['problematic_field_analysis'].items():\n",
        "                report += f\"### {field_name} ({analysis['issue_type']})\\n\"\n",
        "                report += f\"- **准确率**: {analysis['accuracy']:.3f}\\n\"\n",
        "                report += f\"- **平均分数**: {analysis['average_score']:.3f}\\n\"\n",
        "                report += f\"- **错误数**: {analysis['total_errors']}\\n\"\n",
        "                report += f\"- **严重程度**: {analysis['severity']}\\n\"\n",
        "                report += f\"- **改进优先级**: {analysis['improvement_priority']}\\n\"\n",
        "\n",
        "                if analysis['error_breakdown']:\n",
        "                    report += \"- **错误类型分布**:\\n\"\n",
        "                    for error_type, count in analysis['error_breakdown'].items():\n",
        "                        report += f\"  - {error_type}: {count}\\n\"\n",
        "                report += \"\\n\"\n",
        "\n",
        "        # 改进建议\n",
        "        report += \"## 改进建议\\n\\n\"\n",
        "\n",
        "        critical_fields = [name for name, analysis in results['problematic_field_analysis'].items()\n",
        "                          if analysis['improvement_priority'] in ['urgent', 'high']]\n",
        "\n",
        "        if critical_fields:\n",
        "            report += \"### 优先改进字段:\\n\"\n",
        "            for field in critical_fields:\n",
        "                analysis = results['problematic_field_analysis'][field]\n",
        "                report += f\"- **{field}**: {analysis['issue_type']} (优先级: {analysis['improvement_priority']})\\n\"\n",
        "\n",
        "        report += \"\\n### 具体建议:\\n\"\n",
        "        if 'Absolute Page Number' in results['problematic_field_analysis']:\n",
        "            report += \"- **页码提取**: 考虑改进PDF页码识别算法\\n\"\n",
        "        if 'kpi_theme' in results['problematic_field_analysis']:\n",
        "            report += \"- **主题分类**: 优化KPI主题分类逻辑\\n\"\n",
        "        if 'quantitative_value' in results['problematic_field_analysis']:\n",
        "            report += \"- **数值提取**: 加强数值识别和标准化处理\\n\"\n",
        "\n",
        "        return report\n",
        "\n",
        "    def save_metadata_validation_results(self, output_dir: str = None):\n",
        "        \"\"\"保存元数据验证结果\"\"\"\n",
        "        if not self.metadata_results:\n",
        "            logging.warning(\"No metadata results to save\")\n",
        "            return {}\n",
        "\n",
        "        if output_dir is None:\n",
        "            output_dir = self.main_validator.output_dir / \"metadata_validation\"\n",
        "\n",
        "        output_path = Path(output_dir)\n",
        "        output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        saved_files = {}\n",
        "\n",
        "        # 1. 保存详细结果JSON\n",
        "        results_file = output_path / \"metadata_validation_results.json\"\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.metadata_results, f, indent=2, ensure_ascii=False, default=str)\n",
        "        saved_files['detailed_json'] = results_file\n",
        "\n",
        "        # 2. 保存字段分析Excel\n",
        "        field_analysis_data = []\n",
        "        for field_name, field_stats in self.metadata_results['field_results'].items():\n",
        "            if field_stats['total_comparisons'] > 0:\n",
        "                accuracy = field_stats['correct_count'] / field_stats['total_comparisons']\n",
        "                avg_score = field_stats['total_score'] / field_stats['total_comparisons']\n",
        "\n",
        "                field_analysis_data.append({\n",
        "                    'Field Name': field_name,\n",
        "                    'Total Comparisons': field_stats['total_comparisons'],\n",
        "                    'Correct Count': field_stats['correct_count'],\n",
        "                    'Accuracy': accuracy,\n",
        "                    'Average Score': avg_score,\n",
        "                    'Error Count': field_stats['total_comparisons'] - field_stats['correct_count'],\n",
        "                    'Main Error Type': max(field_stats['error_types'].items(),\n",
        "                                         key=lambda x: x[1], default=('none', 0))[0]\n",
        "                })\n",
        "\n",
        "        field_df = pd.DataFrame(field_analysis_data)\n",
        "        field_df = field_df.sort_values('Accuracy')\n",
        "\n",
        "        excel_file = output_path / \"metadata_field_analysis.xlsx\"\n",
        "        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
        "            field_df.to_excel(writer, sheet_name='Field Analysis', index=False)\n",
        "\n",
        "            # 问题字段详细分析\n",
        "            if self.metadata_results['problematic_field_analysis']:\n",
        "                prob_data = []\n",
        "                for field_name, analysis in self.metadata_results['problematic_field_analysis'].items():\n",
        "                    prob_data.append({\n",
        "                        'Field Name': field_name,\n",
        "                        'Issue Type': analysis['issue_type'],\n",
        "                        'Accuracy': analysis['accuracy'],\n",
        "                        'Average Score': analysis['average_score'],\n",
        "                        'Total Errors': analysis['total_errors'],\n",
        "                        'Severity': analysis['severity'],\n",
        "                        'Improvement Priority': analysis['improvement_priority']\n",
        "                    })\n",
        "\n",
        "                prob_df = pd.DataFrame(prob_data)\n",
        "                prob_df.to_excel(writer, sheet_name='Problematic Fields', index=False)\n",
        "\n",
        "        saved_files['field_analysis_excel'] = excel_file\n",
        "\n",
        "        # 3. 保存元数据报告\n",
        "        report = self.generate_metadata_report()\n",
        "        report_file = output_path / \"metadata_validation_report.md\"\n",
        "        with open(report_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(report)\n",
        "        saved_files['report_markdown'] = report_file\n",
        "\n",
        "        logging.info(f\"元数据验证结果已保存到: {output_path}\")\n",
        "        return saved_files\n",
        "\n",
        "\n",
        "# 集成函数：在主验证流程中添加元数据验证\n",
        "def run_complete_validation_with_metadata(df_auto: pd.DataFrame, manual_xlsx_path: str,\n",
        "                                         output_dir: str = \"complete_validation\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    运行完整验证（文本验证 + 元数据验证）\n",
        "\n",
        "    Args:\n",
        "        df_auto: 自动提取的KPI DataFrame\n",
        "        manual_xlsx_path: 手动标注文件路径\n",
        "        output_dir: 输出目录\n",
        "\n",
        "    Returns:\n",
        "        完整验证结果\n",
        "    \"\"\"\n",
        "    logging.info(\"开始运行完整验证（文本 + 元数据）...\")\n",
        "\n",
        "    # Step 1: 运行文本验证\n",
        "    print(\"🔍 Step 1: 运行文本验证...\")\n",
        "    # 注意：这里需要您根据实际的文本验证函数名称进行调整\n",
        "    # text_validation_results = enhanced_compare_with_manual_kpis(\n",
        "    #     df_auto, manual_xlsx_path, f\"{output_dir}/text_validation\"\n",
        "    # )\n",
        "\n",
        "    # 临时占位符，您需要替换为实际的文本验证函数\n",
        "    text_validation_results = {}\n",
        "    print(\"⚠️ 请确保已实现 enhanced_compare_with_manual_kpis 函数\")\n",
        "\n",
        "    if not text_validation_results:\n",
        "        logging.error(\"文本验证失败，无法继续元数据验证\")\n",
        "        return {}\n",
        "\n",
        "    # Step 2: 运行元数据验证\n",
        "    print(\"📊 Step 2: 运行元数据验证...\")\n",
        "\n",
        "    # 获取文本验证器实例\n",
        "    temp_auto_path = Path(f\"{output_dir}/text_validation\") / \"temp_auto_kpis.xlsx\"\n",
        "    if not temp_auto_path.exists():\n",
        "        temp_auto_path = Path(output_dir) / \"temp_auto_kpis.xlsx\"\n",
        "        temp_auto_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        df_auto.to_excel(temp_auto_path, index=False)\n",
        "\n",
        "    # 注意：这里需要您根据实际的KPIValidationPipeline类进行调整\n",
        "    # main_validator = KPIValidationPipeline(\n",
        "    #     manual_excel_path=manual_xlsx_path,\n",
        "    #     auto_excel_path=str(temp_auto_path),\n",
        "    #     output_dir=f\"{output_dir}/text_validation\"\n",
        "    # )\n",
        "\n",
        "    # 临时占位符，您需要替换为实际的验证管道\n",
        "    main_validator = None\n",
        "    print(\"⚠️ 请确保已实现 KPIValidationPipeline 类\")\n",
        "\n",
        "    if main_validator is None:\n",
        "        logging.error(\"无法创建主验证器\")\n",
        "        return {}\n",
        "\n",
        "    # 确保文本验证已运行\n",
        "    if not hasattr(main_validator, 'validation_results') or not main_validator.validation_results:\n",
        "        # main_validator.run_comprehensive_evaluation()\n",
        "        print(\"⚠️ 请确保已运行主验证器的评估方法\")\n",
        "\n",
        "    # 创建元数据验证扩展\n",
        "    metadata_validator = MetadataValidationExtension(main_validator)\n",
        "    metadata_results = metadata_validator.validate_metadata_for_matched_pairs()\n",
        "\n",
        "    # 保存元数据验证结果\n",
        "    metadata_saved_files = metadata_validator.save_metadata_validation_results(f\"{output_dir}/metadata_validation\")\n",
        "\n",
        "    # Step 3: 生成综合报告\n",
        "    print(\"📋 Step 3: 生成综合报告...\")\n",
        "    complete_results = {\n",
        "        'text_validation': text_validation_results,\n",
        "        'metadata_validation': metadata_results,\n",
        "        'saved_files': {\n",
        "            'text_validation_files': text_validation_results.get('saved_files', {}),\n",
        "            'metadata_validation_files': metadata_saved_files\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # 打印摘要\n",
        "    text_best = text_validation_results.get('best_metrics', {})\n",
        "    metadata_overall = metadata_results.get('overall_scores', {})\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"完整验证结果摘要\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"📝 文本验证 F1 分数: {text_best.get('f1_score', 0):.3f}\")\n",
        "    print(f\"📊 元数据总体分数: {metadata_overall.get('overall_metadata_score', 0):.3f}\")\n",
        "    print(f\"🎯 验证KPI对数: {metadata_results.get('total_pairs', 0)}\")\n",
        "\n",
        "    print(f\"\\n📂 元数据分类得分:\")\n",
        "    for category, score in metadata_overall.items():\n",
        "        if category.endswith('_fields'):\n",
        "            category_name = category.replace('_', ' ').title()\n",
        "            print(f\"   {category_name}: {score:.3f}\")\n",
        "\n",
        "    # 显示问题字段\n",
        "    if metadata_results.get('problematic_field_analysis'):\n",
        "        print(f\"\\n⚠️  需要关注的字段:\")\n",
        "        for field_name, analysis in metadata_results['problematic_field_analysis'].items():\n",
        "            print(f\"   {field_name}: {analysis['accuracy']:.3f} (优先级: {analysis['improvement_priority']})\")\n",
        "\n",
        "    print(f\"\\n📁 完整结果保存在: {output_dir}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # 清理临时文件\n",
        "    if temp_auto_path.exists():\n",
        "        temp_auto_path.unlink()\n",
        "\n",
        "    return complete_results\n",
        "\n",
        "\n",
        "# 便捷使用函数\n",
        "def add_metadata_validation_to_existing_pipeline():\n",
        "    \"\"\"为现有验证流程添加元数据验证的示例函数\"\"\"\n",
        "\n",
        "    def enhanced_main_with_metadata():\n",
        "        \"\"\"增强版main函数，包含元数据验证\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format=\"%(asctime)s - %(levelname)s: %(message)s\",\n",
        "            datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            # 这些变量需要您根据实际情况定义\n",
        "            PDF_PATH = \"your_pdf_path.pdf\"  # 请替换为实际PDF路径\n",
        "            EXPORT_AUTO_XLSX = \"auto_kpis.xlsx\"  # 请替换为实际输出路径\n",
        "            MANUAL_XLSX = \"manual_kpis.xlsx\"  # 请替换为实际手动标注文件路径\n",
        "\n",
        "            if not os.path.exists(PDF_PATH):\n",
        "                logging.error(f\"PDF file not found: {PDF_PATH}\")\n",
        "                return\n",
        "\n",
        "            # 原有的KPI提取流程\n",
        "            # df_auto = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "            # save_results(df_auto, EXPORT_AUTO_XLSX, PDF_PATH)\n",
        "\n",
        "            # 临时占位符，您需要替换为实际的处理函数\n",
        "            df_auto = pd.DataFrame()  # 请替换为实际的KPI提取结果\n",
        "            print(\"⚠️ 请确保已实现 process_sustainability_report_with_enhanced_images 函数\")\n",
        "\n",
        "            logging.info(f\"KPI extraction completed: {len(df_auto)} KPIs extracted\")\n",
        "\n",
        "            # 增强的验证流程（文本 + 元数据）\n",
        "            if MANUAL_XLSX and Path(MANUAL_XLSX).exists():\n",
        "                print(\"\\n🔍 Running complete validation (text + metadata)...\")\n",
        "                complete_validation_results = run_complete_validation_with_metadata(\n",
        "                    df_auto, MANUAL_XLSX, \"complete_validation\"\n",
        "                )\n",
        "\n",
        "                if complete_validation_results:\n",
        "                    print(\"✅ Complete validation finished with detailed analysis!\")\n",
        "                    print(f\"📁 Detailed results saved to: complete_validation/\")\n",
        "                else:\n",
        "                    print(\"⚠️ Validation encountered issues\")\n",
        "            else:\n",
        "                logging.info(\"Manual KPI file not found, skipping validation.\")\n",
        "\n",
        "            # 显示提取摘要（保持原有逻辑）\n",
        "            if not df_auto.empty:\n",
        "                print(f\"\\n=== Extraction Summary ===\")\n",
        "                print(f\"Total KPIs extracted: {len(df_auto)}\")\n",
        "\n",
        "                if 'source_type' in df_auto.columns:\n",
        "                    source_counts = df_auto['source_type'].value_counts()\n",
        "                    print(f\"From text/tables: {source_counts.get('text', 0)}\")\n",
        "                    print(f\"From images/charts: {source_counts.get('image', 0)}\")\n",
        "\n",
        "                if 'kpi_theme' in df_auto.columns:\n",
        "                    theme_counts = df_auto['kpi_theme'].value_counts()\n",
        "                    print(f\"\\nKPI Distribution by Theme:\")\n",
        "                    for theme, count in theme_counts.items():\n",
        "                        print(f\"  {theme}: {count}\")\n",
        "            else:\n",
        "                print(\"\\nNo KPIs were extracted from the document.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in enhanced main execution: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    return enhanced_main_with_metadata\n"
      ],
      "metadata": {
        "id": "wSVbF2fez9rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchKPIProcessor:\n",
        "    \"\"\"批量KPI处理器 - 支持多个PDF和Manual文件\"\"\"\n",
        "\n",
        "    def __init__(self, base_output_dir: str = \"batch_kpi_results\"):\n",
        "        \"\"\"\n",
        "        初始化批量处理器\n",
        "\n",
        "        Args:\n",
        "            base_output_dir: 批量处理结果的基础目录\n",
        "        \"\"\"\n",
        "        self.base_output_dir = Path(base_output_dir)\n",
        "        self.base_output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # 存储所有文件配对\n",
        "        self.file_pairs = []\n",
        "        self.batch_results = []\n",
        "\n",
        "        # 创建时间戳用于本次批量处理\n",
        "        self.batch_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.current_batch_dir = self.base_output_dir / f\"batch_{self.batch_timestamp}\"\n",
        "        self.current_batch_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        logging.info(f\"批量处理器初始化完成，结果保存到: {self.current_batch_dir}\")\n",
        "\n",
        "    def add_file_pair(self, pdf_path: str, manual_path: str, document_name: str = None):\n",
        "        \"\"\"\n",
        "        添加一对PDF和Manual文件\n",
        "\n",
        "        Args:\n",
        "            pdf_path: PDF文件路径\n",
        "            manual_path: Manual标注文件路径\n",
        "            document_name: 文档名称（可选，默认使用PDF文件名）\n",
        "        \"\"\"\n",
        "        pdf_path = Path(pdf_path)\n",
        "        manual_path = Path(manual_path)\n",
        "\n",
        "        # 验证文件存在\n",
        "        if not pdf_path.exists():\n",
        "            logging.error(f\"PDF文件不存在: {pdf_path}\")\n",
        "            return False\n",
        "\n",
        "        if not manual_path.exists():\n",
        "            logging.error(f\"Manual文件不存在: {manual_path}\")\n",
        "            return False\n",
        "\n",
        "        # 自动生成文档名称\n",
        "        if document_name is None:\n",
        "            document_name = pdf_path.stem\n",
        "\n",
        "        file_pair = {\n",
        "            'pdf_path': str(pdf_path),\n",
        "            'manual_path': str(manual_path),\n",
        "            'document_name': document_name,\n",
        "            'doc_id': len(self.file_pairs) + 1\n",
        "        }\n",
        "\n",
        "        self.file_pairs.append(file_pair)\n",
        "        logging.info(f\"添加文件对 {len(self.file_pairs)}: {document_name}\")\n",
        "        return True\n",
        "\n",
        "    def add_multiple_pairs_from_directory(self, pdf_dir: str, manual_dir: str,\n",
        "                                         pdf_pattern: str = \"*.pdf\",\n",
        "                                         manual_pattern: str = \"*.xlsx\"):\n",
        "        \"\"\"\n",
        "        从目录批量添加文件对（按文件名匹配）\n",
        "\n",
        "        Args:\n",
        "            pdf_dir: PDF文件目录\n",
        "            manual_dir: Manual文件目录\n",
        "            pdf_pattern: PDF文件匹配模式\n",
        "            manual_pattern: Manual文件匹配模式\n",
        "        \"\"\"\n",
        "        pdf_dir = Path(pdf_dir)\n",
        "        manual_dir = Path(manual_dir)\n",
        "\n",
        "        if not pdf_dir.exists() or not manual_dir.exists():\n",
        "            logging.error(f\"目录不存在: {pdf_dir} 或 {manual_dir}\")\n",
        "            return 0\n",
        "\n",
        "        # 获取所有PDF文件\n",
        "        pdf_files = list(pdf_dir.glob(pdf_pattern))\n",
        "        added_count = 0\n",
        "\n",
        "        for pdf_file in pdf_files:\n",
        "            # 尝试找到对应的Manual文件\n",
        "            base_name = pdf_file.stem\n",
        "\n",
        "            # 尝试多种匹配模式\n",
        "            possible_manual_names = [\n",
        "                f\"{base_name}.xlsx\",\n",
        "                f\"{base_name}_manual.xlsx\",\n",
        "                f\"manual_{base_name}.xlsx\",\n",
        "                f\"{base_name}.xls\"\n",
        "            ]\n",
        "\n",
        "            manual_file = None\n",
        "            for manual_name in possible_manual_names:\n",
        "                potential_manual = manual_dir / manual_name\n",
        "                if potential_manual.exists():\n",
        "                    manual_file = potential_manual\n",
        "                    break\n",
        "\n",
        "            if manual_file:\n",
        "                if self.add_file_pair(str(pdf_file), str(manual_file), base_name):\n",
        "                    added_count += 1\n",
        "            else:\n",
        "                logging.warning(f\"未找到 {base_name} 对应的Manual文件\")\n",
        "\n",
        "        logging.info(f\"从目录批量添加了 {added_count} 个文件对\")\n",
        "        return added_count\n",
        "\n",
        "    def list_file_pairs(self):\n",
        "        \"\"\"显示所有已添加的文件对\"\"\"\n",
        "        if not self.file_pairs:\n",
        "            print(\"❌ 没有添加任何文件对\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n📋 已添加的文件对 (共 {len(self.file_pairs)} 对):\")\n",
        "        print(\"-\" * 80)\n",
        "        for pair in self.file_pairs:\n",
        "            print(f\"{pair['doc_id']:2d}. 文档: {pair['document_name']}\")\n",
        "            print(f\"    PDF:    {pair['pdf_path']}\")\n",
        "            print(f\"    Manual: {pair['manual_path']}\")\n",
        "            print()\n",
        "\n",
        "    def process_single_document(self, file_pair: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        处理单个文档（PDF + Manual）\n",
        "\n",
        "        Args:\n",
        "            file_pair: 文件对信息\n",
        "\n",
        "        Returns:\n",
        "            处理结果字典\n",
        "        \"\"\"\n",
        "        doc_name = file_pair['document_name']\n",
        "        pdf_path = file_pair['pdf_path']\n",
        "        manual_path = file_pair['manual_path']\n",
        "        doc_id = file_pair['doc_id']\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"📄 处理文档 {doc_id}/{len(self.file_pairs)}: {doc_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # 为每个文档创建独立目录\n",
        "        doc_output_dir = self.current_batch_dir / f\"doc_{doc_id}_{doc_name}\"\n",
        "        doc_output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        start_time = time.time()\n",
        "        result = {\n",
        "            'doc_id': doc_id,\n",
        "            'document_name': doc_name,\n",
        "            'pdf_path': pdf_path,\n",
        "            'manual_path': manual_path,\n",
        "            'output_dir': str(doc_output_dir),\n",
        "            'start_time': datetime.now().isoformat(),\n",
        "            'status': 'processing'\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Step 1: 临时修改全局PDF路径\n",
        "            global PDF_PATH\n",
        "            original_pdf_path = PDF_PATH\n",
        "            PDF_PATH = pdf_path\n",
        "\n",
        "            print(f\"📊 Step 1: 提取KPI from {Path(pdf_path).name}...\")\n",
        "\n",
        "            # Step 2: 运行KPI提取\n",
        "            df_auto = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "\n",
        "            # Step 3: 保存自动提取结果\n",
        "            auto_excel_path = doc_output_dir / f\"{doc_name}_auto_kpis.xlsx\"\n",
        "            save_results(df_auto, str(auto_excel_path), PDF_PATH)\n",
        "\n",
        "            print(f\"✅ 提取完成: {len(df_auto)} KPIs\")\n",
        "\n",
        "            # Step 4: 运行验证\n",
        "            print(f\"🔍 Step 2: 运行验证 against {Path(manual_path).name}...\")\n",
        "            validation_output_dir = doc_output_dir / \"validation\"\n",
        "            validation_results = enhanced_compare_with_manual_kpis(\n",
        "                df_auto, manual_path, str(validation_output_dir)\n",
        "            )\n",
        "\n",
        "            # Step 5: 收集结果\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            result.update({\n",
        "                'status': 'completed',\n",
        "                'processing_time_seconds': processing_time,\n",
        "                'extracted_kpis_count': len(df_auto),\n",
        "                'auto_excel_path': str(auto_excel_path),\n",
        "                'validation_output_dir': str(validation_output_dir),\n",
        "                'end_time': datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "            # 添加验证指标\n",
        "            if validation_results and 'best_metrics' in validation_results:\n",
        "                metrics = validation_results['best_metrics']\n",
        "                result.update({\n",
        "                    'validation_f1_score': metrics.get('f1_score', 0),\n",
        "                    'validation_precision': metrics.get('precision', 0),\n",
        "                    'validation_recall': metrics.get('recall', 0),\n",
        "                    'true_positives': metrics.get('true_positives', 0),\n",
        "                    'false_positives': metrics.get('false_positives', 0),\n",
        "                    'false_negatives': metrics.get('false_negatives', 0)\n",
        "                })\n",
        "\n",
        "                print(f\"🎯 验证完成:\")\n",
        "                print(f\"   F1 Score: {metrics.get('f1_score', 0):.3f}\")\n",
        "                print(f\"   Precision: {metrics.get('precision', 0):.3f}\")\n",
        "                print(f\"   Recall: {metrics.get('recall', 0):.3f}\")\n",
        "\n",
        "            print(f\"⏱️  处理耗时: {processing_time:.1f}秒\")\n",
        "            print(f\"📁 结果保存到: {doc_output_dir}\")\n",
        "\n",
        "            # 恢复原始PDF路径\n",
        "            PDF_PATH = original_pdf_path\n",
        "\n",
        "        except Exception as e:\n",
        "            processing_time = time.time() - start_time\n",
        "            error_msg = str(e)\n",
        "\n",
        "            result.update({\n",
        "                'status': 'failed',\n",
        "                'processing_time_seconds': processing_time,\n",
        "                'error_message': error_msg,\n",
        "                'end_time': datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "            print(f\"❌ 处理失败: {error_msg}\")\n",
        "\n",
        "            # 恢复原始PDF路径\n",
        "            PDF_PATH = original_pdf_path\n",
        "\n",
        "            # 保存错误日志\n",
        "            error_log_path = doc_output_dir / \"error_log.txt\"\n",
        "            with open(error_log_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(f\"文档: {doc_name}\\n\")\n",
        "                f.write(f\"错误时间: {datetime.now()}\\n\")\n",
        "                f.write(f\"错误信息: {error_msg}\\n\")\n",
        "                f.write(f\"PDF路径: {pdf_path}\\n\")\n",
        "                f.write(f\"Manual路径: {manual_path}\\n\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def run_batch_processing(self, max_workers: int = 1):\n",
        "        \"\"\"\n",
        "        运行批量处理\n",
        "\n",
        "        Args:\n",
        "            max_workers: 最大并发处理数（建议保持为1，避免API限制）\n",
        "        \"\"\"\n",
        "        if not self.file_pairs:\n",
        "            print(\"❌ 没有要处理的文件对\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n🚀 开始批量处理 {len(self.file_pairs)} 个文档...\")\n",
        "        print(f\"📁 结果将保存到: {self.current_batch_dir}\")\n",
        "\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        # 处理每个文档\n",
        "        for file_pair in self.file_pairs:\n",
        "            result = self.process_single_document(file_pair)\n",
        "            self.batch_results.append(result)\n",
        "\n",
        "            # 实时保存进度（防止中断丢失结果）\n",
        "            self.save_batch_progress()\n",
        "\n",
        "        # 生成最终报告\n",
        "        batch_total_time = time.time() - batch_start_time\n",
        "        self.generate_batch_summary(batch_total_time)\n",
        "\n",
        "        print(f\"\\n🎉 批量处理完成!\")\n",
        "        print(f\"⏱️  总耗时: {batch_total_time:.1f}秒 ({batch_total_time/60:.1f}分钟)\")\n",
        "        print(f\"📊 处理统计: {self.get_batch_statistics()}\")\n",
        "        print(f\"📁 完整结果查看: {self.current_batch_dir}\")\n",
        "\n",
        "    def save_batch_progress(self):\n",
        "        \"\"\"保存批量处理进度\"\"\"\n",
        "        progress_file = self.current_batch_dir / \"batch_progress.json\"\n",
        "        with open(progress_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump({\n",
        "                'batch_timestamp': self.batch_timestamp,\n",
        "                'file_pairs': self.file_pairs,\n",
        "                'results': self.batch_results,\n",
        "                'last_updated': datetime.now().isoformat()\n",
        "            }, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    def get_batch_statistics(self) -> str:\n",
        "        \"\"\"获取批量处理统计信息\"\"\"\n",
        "        if not self.batch_results:\n",
        "            return \"无结果\"\n",
        "\n",
        "        total = len(self.batch_results)\n",
        "        completed = len([r for r in self.batch_results if r['status'] == 'completed'])\n",
        "        failed = len([r for r in self.batch_results if r['status'] == 'failed'])\n",
        "\n",
        "        # 计算平均验证指标\n",
        "        completed_results = [r for r in self.batch_results if r['status'] == 'completed']\n",
        "        if completed_results:\n",
        "            avg_f1 = sum(r.get('validation_f1_score', 0) for r in completed_results) / len(completed_results)\n",
        "            avg_precision = sum(r.get('validation_precision', 0) for r in completed_results) / len(completed_results)\n",
        "            avg_recall = sum(r.get('validation_recall', 0) for r in completed_results) / len(completed_results)\n",
        "            total_kpis = sum(r.get('extracted_kpis_count', 0) for r in completed_results)\n",
        "        else:\n",
        "            avg_f1 = avg_precision = avg_recall = total_kpis = 0\n",
        "\n",
        "        return f\"\"\"\n",
        "        成功: {completed}/{total} ({completed/total*100:.1f}%)\n",
        "        失败: {failed}/{total} ({failed/total*100:.1f}%)\n",
        "        总KPI数: {total_kpis}\n",
        "        平均F1: {avg_f1:.3f}\n",
        "        平均精确率: {avg_precision:.3f}\n",
        "        平均召回率: {avg_recall:.3f}\n",
        "        \"\"\"\n",
        "\n",
        "    def generate_batch_summary(self, total_time: float):\n",
        "        \"\"\"生成批量处理汇总报告\"\"\"\n",
        "        # 1. 保存详细结果到Excel\n",
        "        results_df = pd.DataFrame(self.batch_results)\n",
        "        excel_path = self.current_batch_dir / \"batch_summary.xlsx\"\n",
        "\n",
        "        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
        "            # 主要结果\n",
        "            results_df.to_excel(writer, sheet_name='处理结果', index=False)\n",
        "\n",
        "            # 验证指标汇总\n",
        "            if not results_df.empty:\n",
        "                completed_df = results_df[results_df['status'] == 'completed']\n",
        "                if not completed_df.empty:\n",
        "                    validation_columns = ['document_name', 'extracted_kpis_count',\n",
        "                                        'validation_f1_score', 'validation_precision',\n",
        "                                        'validation_recall', 'true_positives',\n",
        "                                        'false_positives', 'false_negatives']\n",
        "\n",
        "                    validation_df = completed_df[validation_columns].copy()\n",
        "                    validation_df.to_excel(writer, sheet_name='验证指标', index=False)\n",
        "\n",
        "        # 2. 生成Markdown报告\n",
        "        report_path = self.current_batch_dir / \"batch_report.md\"\n",
        "        with open(report_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"\"\"# 批量KPI提取与验证报告\n",
        "\n",
        "## 处理概览\n",
        "- **处理时间**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "- **批次ID**: {self.batch_timestamp}\n",
        "- **总文档数**: {len(self.file_pairs)}\n",
        "- **总耗时**: {total_time:.1f}秒 ({total_time/60:.1f}分钟)\n",
        "\n",
        "## 处理统计\n",
        "{self.get_batch_statistics()}\n",
        "\n",
        "## 详细结果\n",
        "\n",
        "| 文档ID | 文档名称 | 状态 | KPI数量 | F1分数 | 精确率 | 召回率 | 处理时间(秒) |\n",
        "|--------|----------|------|---------|--------|--------|--------|-------------|\n",
        "\"\"\")\n",
        "\n",
        "            for result in self.batch_results:\n",
        "                f.write(f\"| {result['doc_id']} | {result['document_name']} | {result['status']} | \"\n",
        "                       f\"{result.get('extracted_kpis_count', 'N/A')} | \"\n",
        "                       f\"{result.get('validation_f1_score', 0):.3f} | \"\n",
        "                       f\"{result.get('validation_precision', 0):.3f} | \"\n",
        "                       f\"{result.get('validation_recall', 0):.3f} | \"\n",
        "                       f\"{result.get('processing_time_seconds', 0):.1f} |\\n\")\n",
        "\n",
        "            if any(r['status'] == 'failed' for r in self.batch_results):\n",
        "                f.write(f\"\\n## 失败的文档\\n\")\n",
        "                for result in self.batch_results:\n",
        "                    if result['status'] == 'failed':\n",
        "                        f.write(f\"- **{result['document_name']}**: {result.get('error_message', '未知错误')}\\n\")\n",
        "\n",
        "        print(f\"📋 批量处理报告生成: {report_path}\")\n",
        "        print(f\"📊 详细结果Excel: {excel_path}\")"
      ],
      "metadata": {
        "id": "sJ5B5aGfIZsZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 修改批量处理器，显示详细的单文档验证信息\n",
        "class BatchKPIProcessorWithDetailedOutput(BatchKPIProcessor):\n",
        "    \"\"\"\n",
        "    扩展批量处理器，支持详细的验证输出\n",
        "    \"\"\"\n",
        "\n",
        "    def process_single_document(self, file_pair: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        处理单个文档，显示详细的验证信息\n",
        "        \"\"\"\n",
        "        doc_name = file_pair['document_name']\n",
        "        pdf_path = file_pair['pdf_path']\n",
        "        manual_path = file_pair['manual_path']\n",
        "        doc_id = file_pair['doc_id']\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"📄 Processing Document {doc_id}/{len(self.file_pairs)}: {doc_name}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # 为每个文档创建独立目录\n",
        "        doc_output_dir = self.current_batch_dir / f\"doc_{doc_id}_{doc_name}\"\n",
        "        doc_output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        start_time = time.time()\n",
        "        result = {\n",
        "            'doc_id': doc_id,\n",
        "            'document_name': doc_name,\n",
        "            'pdf_path': pdf_path,\n",
        "            'manual_path': manual_path,\n",
        "            'output_dir': str(doc_output_dir),\n",
        "            'start_time': datetime.now().isoformat(),\n",
        "            'status': 'processing'\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Step 1: 临时修改全局PDF路径\n",
        "            global PDF_PATH\n",
        "            original_pdf_path = PDF_PATH\n",
        "            PDF_PATH = pdf_path\n",
        "\n",
        "            print(f\"📊 Step 1: Extracting KPIs from {Path(pdf_path).name}...\")\n",
        "\n",
        "            # Step 2: 运行KPI提取\n",
        "            df_auto = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "\n",
        "            # Step 3: 保存自动提取结果\n",
        "            auto_excel_path = doc_output_dir / f\"{doc_name}_auto_kpis.xlsx\"\n",
        "            save_results(df_auto, str(auto_excel_path), PDF_PATH)\n",
        "\n",
        "            print(f\"✅ Extraction completed: {len(df_auto)} KPIs\")\n",
        "\n",
        "            # Step 4: 运行详细验证\n",
        "            print(f\"\\n🔍 Step 2: Running comprehensive validation against {Path(manual_path).name}...\")\n",
        "            validation_output_dir = doc_output_dir / \"validation\"\n",
        "            validation_start_time = time.time()\n",
        "\n",
        "            complete_validation_results = enhanced_compare_with_manual_kpis(\n",
        "                df_auto, manual_path, str(validation_output_dir)\n",
        "            )\n",
        "\n",
        "            validation_time = time.time() - validation_start_time\n",
        "\n",
        "            # Step 5: 收集结果\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            result.update({\n",
        "                'status': 'completed',\n",
        "                'processing_time_seconds': processing_time,\n",
        "                'validation_time_seconds': validation_time,\n",
        "                'extracted_kpis_count': len(df_auto),\n",
        "                'auto_excel_path': str(auto_excel_path),\n",
        "                'validation_output_dir': str(validation_output_dir),\n",
        "                'end_time': datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "            # 添加详细的验证指标\n",
        "            if complete_validation_results:\n",
        "                # 文本验证指标\n",
        "                if 'text_validation' in complete_validation_results:\n",
        "                    text_metrics = complete_validation_results['text_validation'].get('best_metrics', {})\n",
        "                    result.update({\n",
        "                        'text_validation_f1_score': text_metrics.get('f1_score', 0),\n",
        "                        'text_validation_precision': text_metrics.get('precision', 0),\n",
        "                        'text_validation_recall': text_metrics.get('recall', 0),\n",
        "                        'true_positives': text_metrics.get('true_positives', 0),\n",
        "                        'false_positives': text_metrics.get('false_positives', 0),\n",
        "                        'false_negatives': text_metrics.get('false_negatives', 0),\n",
        "                        'manual_kpis_count': text_metrics.get('total_manual', 0),\n",
        "                        'auto_kpis_count': text_metrics.get('total_auto', 0)\n",
        "                    })\n",
        "\n",
        "                # 元数据验证指标\n",
        "                if 'metadata_validation' in complete_validation_results:\n",
        "                    metadata_scores = complete_validation_results['metadata_validation'].get('overall_scores', {})\n",
        "                    result.update({\n",
        "                        'metadata_overall_score': metadata_scores.get('overall_metadata_score', 0),\n",
        "                        'document_fields_score': metadata_scores.get('document_fields', 0),\n",
        "                        'classification_fields_score': metadata_scores.get('classification_fields', 0),\n",
        "                        'quantitative_fields_score': metadata_scores.get('quantitative_fields', 0),\n",
        "                        'analysis_fields_score': metadata_scores.get('analysis_fields', 0)\n",
        "                    })\n",
        "\n",
        "                    # 添加问题字段分析\n",
        "                    problematic_fields = complete_validation_results['metadata_validation'].get('problematic_field_analysis', {})\n",
        "                    for field_name in ['Absolute Page Number', 'kpi_theme', 'quantitative_value']:\n",
        "                        if field_name in problematic_fields:\n",
        "                            field_key = field_name.lower().replace(' ', '_')\n",
        "                            result[f'{field_key}_accuracy'] = problematic_fields[field_name]['accuracy']\n",
        "                            result[f'{field_key}_priority'] = problematic_fields[field_name]['improvement_priority']\n",
        "\n",
        "                # 显示最终摘要\n",
        "                print(f\"\\n🎯 Document {doc_id} Verification Completed:\")\n",
        "                print(f\"   📊 Dataset: {result.get('manual_kpis_count', 0)} manual vs {result.get('auto_kpis_count', 0)} auto KPIs\")\n",
        "                print(f\"   🎯 Text F1 Score: {result.get('text_validation_f1_score', 0):.3f}\")\n",
        "                print(f\"   📈 Text Precision: {result.get('text_validation_precision', 0):.3f}\")\n",
        "                print(f\"   📉 Text Recall: {result.get('text_validation_recall', 0):.3f}\")\n",
        "                print(f\"   ✅ True Positives: {result.get('true_positives', 0)}\")\n",
        "                print(f\"   ❌ False Positives: {result.get('false_positives', 0)}\")\n",
        "                print(f\"   ⚠️  False Negatives: {result.get('false_negatives', 0)}\")\n",
        "                print(f\"   📊 Metadata Overall Score: {result.get('metadata_overall_score', 0):.3f}\")\n",
        "\n",
        "            print(f\"⏱️  Processing time: {processing_time:.1f}秒 (validation: {validation_time:.1f}秒)\")\n",
        "            print(f\"📁 Results saved to: {doc_output_dir}\")\n",
        "\n",
        "            # 恢复原始PDF路径\n",
        "            PDF_PATH = original_pdf_path\n",
        "\n",
        "        except Exception as e:\n",
        "            processing_time = time.time() - start_time\n",
        "            error_msg = str(e)\n",
        "\n",
        "            result.update({\n",
        "                'status': 'failed',\n",
        "                'processing_time_seconds': processing_time,\n",
        "                'error_message': error_msg,\n",
        "                'end_time': datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "            print(f\"❌ Processing failed: {error_msg}\")\n",
        "\n",
        "            # 恢复原始PDF路径\n",
        "            PDF_PATH = original_pdf_path\n",
        "\n",
        "            # 保存错误日志\n",
        "            error_log_path = doc_output_dir / \"error_log.txt\"\n",
        "            with open(error_log_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(f\"Document: {doc_name}\\n\")\n",
        "                f.write(f\"Error time: {datetime.now()}\\n\")\n",
        "                f.write(f\"Error message: {error_msg}\\n\")\n",
        "                f.write(f\"PDF Path: {pdf_path}\\n\")\n",
        "                f.write(f\"Manual Path: {manual_path}\\n\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def generate_batch_summary(self, total_time: float):\n",
        "        \"\"\"生成详细的批量处理汇总报告\"\"\"\n",
        "        # 调用父类方法生成基础报告\n",
        "        super().generate_batch_summary(total_time)\n",
        "\n",
        "        # 生成详细的批量摘要\n",
        "        completed_results = [r for r in self.batch_results if r['status'] == 'completed']\n",
        "\n",
        "        if completed_results:\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(\"BATCH PROCESSING DETAILED SUMMARY\")\n",
        "            print(f\"{'='*80}\")\n",
        "\n",
        "            # 计算批量统计\n",
        "            total_manual_kpis = sum(r.get('manual_kpis_count', 0) for r in completed_results)\n",
        "            total_auto_kpis = sum(r.get('auto_kpis_count', 0) for r in completed_results)\n",
        "            total_true_positives = sum(r.get('true_positives', 0) for r in completed_results)\n",
        "            total_false_positives = sum(r.get('false_positives', 0) for r in completed_results)\n",
        "            total_false_negatives = sum(r.get('false_negatives', 0) for r in completed_results)\n",
        "\n",
        "            # 计算平均指标\n",
        "            avg_f1 = sum(r.get('text_validation_f1_score', 0) for r in completed_results) / len(completed_results)\n",
        "            avg_precision = sum(r.get('text_validation_precision', 0) for r in completed_results) / len(completed_results)\n",
        "            avg_recall = sum(r.get('text_validation_recall', 0) for r in completed_results) / len(completed_results)\n",
        "            avg_metadata_score = sum(r.get('metadata_overall_score', 0) for r in completed_results) / len(completed_results)\n",
        "\n",
        "            print(f\"📊 Batch Dataset Summary:\")\n",
        "            print(f\"   Total Documents Processed: {len(completed_results)}\")\n",
        "            print(f\"   Total Manual KPIs: {total_manual_kpis}\")\n",
        "            print(f\"   Total Auto KPIs: {total_auto_kpis}\")\n",
        "            print(f\"   Total True Positives: {total_true_positives}\")\n",
        "            print(f\"   Total False Positives: {total_false_positives}\")\n",
        "            print(f\"   Total False Negatives: {total_false_negatives}\")\n",
        "\n",
        "            print(f\"\\n🎯 Batch Average Performance:\")\n",
        "            print(f\"   Average Text F1 Score: {avg_f1:.3f}\")\n",
        "            print(f\"   Average Text Precision: {avg_precision:.3f}\")\n",
        "            print(f\"   Average Text Recall: {avg_recall:.3f}\")\n",
        "            print(f\"   Average Metadata Overall Score: {avg_metadata_score:.3f}\")\n",
        "\n",
        "            # 显示各文档表现\n",
        "            print(f\"\\n📋 Individual Document Performance:\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            for result in completed_results:\n",
        "                doc_name = result['document_name'][:30]  # 限制长度\n",
        "                f1 = result.get('text_validation_f1_score', 0)\n",
        "                precision = result.get('text_validation_precision', 0)\n",
        "                recall = result.get('text_validation_recall', 0)\n",
        "                metadata = result.get('metadata_overall_score', 0)\n",
        "                tp = result.get('true_positives', 0)\n",
        "                fp = result.get('false_positives', 0)\n",
        "                fn = result.get('false_negatives', 0)\n",
        "\n",
        "                print(f\"{doc_name:<30} | F1: {f1:.3f} | P: {precision:.3f} | R: {recall:.3f} | Meta: {metadata:.3f} | TP:{tp:2d} FP:{fp:2d} FN:{fn:2d}\")\n",
        "\n",
        "            print(\"=\"*80)\n",
        "            print(f\"📁 Detailed results saved to: {self.current_batch_dir}\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "# 创建详细输出的批量处理器\n",
        "def create_batch_processor_with_detailed_output():\n",
        "    \"\"\"创建支持详细输出的批量处理器\"\"\"\n",
        "    return BatchKPIProcessorWithDetailedOutput()\n",
        "\n",
        "# 修改集成执行函数\n",
        "def integrated_main_execution_detailed():\n",
        "    \"\"\"集成的主执行函数 - 详细输出版本\"\"\"\n",
        "    print(\"🚀 Enhanced KPI Extraction System - Detailed Output\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"1. Single PDF processing (detailed text + metadata validation)\")\n",
        "    print(\"2. Batch PDF processing (detailed text + metadata validation)\")\n",
        "    print(\"3. Quick batch from directories (detailed output)\")\n",
        "    print(\"4. Quick metadata validation test\")\n",
        "    print(\"5. View usage examples\")\n",
        "\n",
        "    try:\n",
        "        choice = input(\"Please select processing mode (1-5): \")\n",
        "\n",
        "        if choice == '1':\n",
        "            # 单个PDF处理，详细输出\n",
        "            enhanced_main_with_detailed_output()\n",
        "\n",
        "        elif choice == '2':\n",
        "            # 批量处理，详细输出\n",
        "            processor = create_batch_processor_with_detailed_output()\n",
        "\n",
        "            # 让用户手动添加文件对\n",
        "            while True:\n",
        "                pdf_path = input(\"Enter PDF file path (press Enter to finish): \").strip()\n",
        "                if not pdf_path:\n",
        "                    break\n",
        "                manual_path = input(\"Enter corresponding Manual file path: \").strip()\n",
        "                doc_name = input(\"Document name (press Enter for default): \").strip() or None\n",
        "\n",
        "                processor.add_file_pair(pdf_path, manual_path, doc_name)\n",
        "\n",
        "            if processor.file_pairs:\n",
        "                processor.list_file_pairs()\n",
        "                confirm = input(f\"\\nStart detailed processing of these {len(processor.file_pairs)} documents? (y/n): \")\n",
        "                if confirm.lower() == 'y':\n",
        "                    processor.run_batch_processing()\n",
        "                else:\n",
        "                    print(\"Batch processing cancelled.\")\n",
        "            else:\n",
        "                print(\"❌ No file pairs added.\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            # 快速目录批量处理，详细输出\n",
        "            pdf_dir = input(\"PDF files directory path: \").strip()\n",
        "            manual_dir = input(\"Manual files directory path: \").strip()\n",
        "\n",
        "            processor = create_batch_processor_with_detailed_output()\n",
        "            added_count = processor.add_multiple_pairs_from_directory(pdf_dir, manual_dir)\n",
        "\n",
        "            if added_count == 0:\n",
        "                print(\"❌ No matching PDF and Manual file pairs found.\")\n",
        "                return None\n",
        "\n",
        "            processor.list_file_pairs()\n",
        "            response = input(f\"\\nStart detailed processing of these {added_count} documents? (y/n): \")\n",
        "            if response.lower() == 'y':\n",
        "                processor.run_batch_processing()\n",
        "            else:\n",
        "                print(\"Batch processing cancelled.\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            # 快速元数据验证测试\n",
        "            quick_test_metadata_validation()\n",
        "\n",
        "        elif choice == '5':\n",
        "            # 显示使用示例\n",
        "            metadata_validation_usage_examples()\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid selection, running default single PDF processing\")\n",
        "            enhanced_main_with_detailed_output()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nUser cancelled operation\")\n",
        "    except Exception as e:\n",
        "        print(f\"Execution error: {e}\")\n",
        "        print(\"Running default single PDF processing\")\n",
        "        enhanced_main_with_detailed_output()"
      ],
      "metadata": {
        "id": "fP6Nh5cT_rRu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FileUploadManager:\n",
        "    \"\"\"文件上传和管理器\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.uploaded_files = []\n",
        "        self.pdf_files = []\n",
        "        self.manual_files = []\n",
        "        self.file_pairs = []\n",
        "\n",
        "        # 创建工作目录\n",
        "        self.work_dir = Path(\"/content/kpi_files\")\n",
        "        self.work_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        print(f\"📁 工作目录: {self.work_dir}\")\n",
        "\n",
        "    def upload_files_directly(self):\n",
        "        \"\"\"直接上传文件到Colab\"\"\"\n",
        "        print(\"📤 请选择要上传的文件...\")\n",
        "        print(\"可以同时选择多个PDF和Excel文件\")\n",
        "\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for filename, content in uploaded.items():\n",
        "            file_path = self.work_dir / filename\n",
        "            with open(file_path, 'wb') as f:\n",
        "                f.write(content)\n",
        "\n",
        "            self.uploaded_files.append(str(file_path))\n",
        "            print(f\"✅ 已上传: {filename}\")\n",
        "\n",
        "        self._categorize_files()\n",
        "        return len(uploaded)\n",
        "\n",
        "    def mount_google_drive(self):\n",
        "        \"\"\"挂载Google Drive\"\"\"\n",
        "        try:\n",
        "            drive.mount('/content/drive')\n",
        "            print(\"✅ Google Drive已挂载\")\n",
        "            print(\"📁 你的文件在: /content/drive/MyDrive/\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Drive挂载失败: {e}\")\n",
        "            return False\n",
        "\n",
        "    def scan_drive_directory(self, drive_path: str):\n",
        "        \"\"\"扫描Drive目录中的文件\"\"\"\n",
        "        drive_path = Path(drive_path)\n",
        "\n",
        "        if not drive_path.exists():\n",
        "            print(f\"❌ 目录不存在: {drive_path}\")\n",
        "            return 0\n",
        "\n",
        "        # 扫描PDF文件\n",
        "        pdf_files = list(drive_path.glob(\"*.pdf\"))\n",
        "        excel_files = list(drive_path.glob(\"*.xlsx\")) + list(drive_path.glob(\"*.xls\"))\n",
        "\n",
        "        print(f\"📊 发现文件:\")\n",
        "        print(f\"   PDF文件: {len(pdf_files)}个\")\n",
        "        print(f\"   Excel文件: {len(excel_files)}个\")\n",
        "\n",
        "        # 复制到工作目录\n",
        "        for pdf_file in pdf_files:\n",
        "            dest = self.work_dir / pdf_file.name\n",
        "            shutil.copy2(pdf_file, dest)\n",
        "            self.uploaded_files.append(str(dest))\n",
        "            print(f\"📄 复制PDF: {pdf_file.name}\")\n",
        "\n",
        "        for excel_file in excel_files:\n",
        "            dest = self.work_dir / excel_file.name\n",
        "            shutil.copy2(excel_file, dest)\n",
        "            self.uploaded_files.append(str(dest))\n",
        "            print(f\"📊 复制Excel: {excel_file.name}\")\n",
        "\n",
        "        self._categorize_files()\n",
        "        return len(pdf_files) + len(excel_files)\n",
        "\n",
        "    def _categorize_files(self):\n",
        "        \"\"\"分类文件\"\"\"\n",
        "        self.pdf_files = []\n",
        "        self.manual_files = []\n",
        "\n",
        "        for file_path in self.uploaded_files:\n",
        "            path = Path(file_path)\n",
        "            if path.suffix.lower() == '.pdf':\n",
        "                self.pdf_files.append(file_path)\n",
        "            elif path.suffix.lower() in ['.xlsx', '.xls']:\n",
        "                self.manual_files.append(file_path)\n",
        "\n",
        "        print(f\"\\n📋 文件分类完成:\")\n",
        "        print(f\"   PDF文件: {len(self.pdf_files)}个\")\n",
        "        print(f\"   Manual文件: {len(self.manual_files)}个\")\n",
        "\n",
        "    def auto_match_files(self) -> List[Tuple[str, str, str]]:\n",
        "        \"\"\"自动匹配PDF和Manual文件\"\"\"\n",
        "        matches = []\n",
        "\n",
        "        for pdf_path in self.pdf_files:\n",
        "            pdf_name = Path(pdf_path).stem\n",
        "\n",
        "            # 尝试多种匹配模式\n",
        "            potential_matches = []\n",
        "\n",
        "            for manual_path in self.manual_files:\n",
        "                manual_name = Path(manual_path).stem\n",
        "\n",
        "                # 匹配模式1: 完全相同\n",
        "                if pdf_name.lower() == manual_name.lower():\n",
        "                    potential_matches.append((manual_path, 1.0, \"完全匹配\"))\n",
        "\n",
        "                # 匹配模式2: PDF名称_manual\n",
        "                elif manual_name.lower() == f\"{pdf_name.lower()}_manual\":\n",
        "                    potential_matches.append((manual_path, 0.9, \"后缀匹配\"))\n",
        "\n",
        "                # 匹配模式3: manual_PDF名称\n",
        "                elif manual_name.lower() == f\"manual_{pdf_name.lower()}\":\n",
        "                    potential_matches.append((manual_path, 0.9, \"前缀匹配\"))\n",
        "\n",
        "                # 匹配模式4: 包含关系\n",
        "                elif pdf_name.lower() in manual_name.lower() or manual_name.lower() in pdf_name.lower():\n",
        "                    potential_matches.append((manual_path, 0.7, \"部分匹配\"))\n",
        "\n",
        "            # 选择最佳匹配\n",
        "            if potential_matches:\n",
        "                best_match = max(potential_matches, key=lambda x: x[1])\n",
        "                matches.append((pdf_path, best_match[0], pdf_name))\n",
        "                print(f\"✅ 匹配: {pdf_name} → {Path(best_match[0]).name} ({best_match[2]})\")\n",
        "            else:\n",
        "                print(f\"❌ 未找到匹配: {pdf_name}\")\n",
        "\n",
        "        self.file_pairs = matches\n",
        "        return matches\n",
        "\n",
        "    def manual_pair_files(self):\n",
        "        \"\"\"手动配对文件\"\"\"\n",
        "        print(\"\\n🔧 手动文件配对\")\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "        self.file_pairs = []\n",
        "\n",
        "        print(\"可用的PDF文件:\")\n",
        "        for i, pdf_path in enumerate(self.pdf_files, 1):\n",
        "            print(f\"  {i}. {Path(pdf_path).name}\")\n",
        "\n",
        "        print(\"\\n可用的Manual文件:\")\n",
        "        for i, manual_path in enumerate(self.manual_files, 1):\n",
        "            print(f\"  {i}. {Path(manual_path).name}\")\n",
        "\n",
        "        for pdf_path in self.pdf_files:\n",
        "            pdf_name = Path(pdf_path).name\n",
        "            print(f\"\\n为PDF文件 '{pdf_name}' 选择Manual文件:\")\n",
        "\n",
        "            for i, manual_path in enumerate(self.manual_files, 1):\n",
        "                print(f\"  {i}. {Path(manual_path).name}\")\n",
        "\n",
        "            try:\n",
        "                choice = int(input(\"请输入Manual文件编号 (0跳过): \"))\n",
        "                if choice > 0 and choice <= len(self.manual_files):\n",
        "                    manual_path = self.manual_files[choice - 1]\n",
        "                    doc_name = Path(pdf_path).stem\n",
        "                    self.file_pairs.append((pdf_path, manual_path, doc_name))\n",
        "                    print(f\"✅ 配对成功: {pdf_name} → {Path(manual_path).name}\")\n",
        "                else:\n",
        "                    print(f\"⏭️ 跳过: {pdf_name}\")\n",
        "            except ValueError:\n",
        "                print(f\"⏭️ 输入无效，跳过: {pdf_name}\")\n",
        "\n",
        "    def validate_manual_files(self) -> Dict[str, bool]:\n",
        "        \"\"\"验证Manual文件格式\"\"\"\n",
        "        validation_results = {}\n",
        "\n",
        "        print(\"\\n🔍 验证Manual文件格式...\")\n",
        "\n",
        "        for manual_path in self.manual_files:\n",
        "            file_name = Path(manual_path).name\n",
        "            try:\n",
        "                df = pd.read_excel(manual_path)\n",
        "\n",
        "                # 检查必需列\n",
        "                required_columns = ['kpi_text']\n",
        "                missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "\n",
        "                if missing_columns:\n",
        "                    print(f\"❌ {file_name}: 缺少列 {missing_columns}\")\n",
        "                    validation_results[manual_path] = False\n",
        "                else:\n",
        "                    # 检查数据\n",
        "                    non_empty_rows = df['kpi_text'].notna().sum()\n",
        "                    print(f\"✅ {file_name}: {len(df)}行数据, {non_empty_rows}个有效KPI\")\n",
        "                    validation_results[manual_path] = True\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ {file_name}: 读取失败 - {e}\")\n",
        "                validation_results[manual_path] = False\n",
        "\n",
        "        return validation_results\n",
        "\n",
        "    def show_file_summary(self):\n",
        "        \"\"\"显示文件汇总\"\"\"\n",
        "        print(f\"\\n📊 文件上传汇总\")\n",
        "        print(\"=\" * 40)\n",
        "        print(f\"总文件数: {len(self.uploaded_files)}\")\n",
        "        print(f\"PDF文件: {len(self.pdf_files)}\")\n",
        "        print(f\"Manual文件: {len(self.manual_files)}\")\n",
        "        print(f\"配对文件: {len(self.file_pairs)}\")\n",
        "\n",
        "        if self.file_pairs:\n",
        "            print(f\"\\n📋 配对结果:\")\n",
        "            for i, (pdf_path, manual_path, doc_name) in enumerate(self.file_pairs, 1):\n",
        "                print(f\"  {i}. {doc_name}\")\n",
        "                print(f\"     PDF: {Path(pdf_path).name}\")\n",
        "                print(f\"     Manual: {Path(manual_path).name}\")\n",
        "\n",
        "    def get_file_pairs_for_batch_processing(self) -> List[Tuple[str, str, str]]:\n",
        "        \"\"\"获取用于批量处理的文件对\"\"\"\n",
        "        return self.file_pairs\n",
        "\n",
        "    def create_batch_processor_from_uploads(self):\n",
        "        \"\"\"从上传的文件创建批量处理器\"\"\"\n",
        "        if not self.file_pairs:\n",
        "            print(\"❌ 没有可用的文件对\")\n",
        "            return None\n",
        "\n",
        "        # 导入批量处理器\n",
        "        from your_main_script import create_batch_processor  # 需要替换为实际的导入\n",
        "\n",
        "        processor = create_batch_processor()\n",
        "\n",
        "        for pdf_path, manual_path, doc_name in self.file_pairs:\n",
        "            processor.add_file_pair(pdf_path, manual_path, doc_name)\n",
        "\n",
        "        return processor"
      ],
      "metadata": {
        "id": "InVqb0qIB7a0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ 便捷使用函数 ============\n",
        "\n",
        "def create_batch_processor():\n",
        "    \"\"\"A convenience function to create a batch KPI processor\"\"\"\n",
        "    return BatchKPIProcessor()\n",
        "\n",
        "def quick_batch_from_directories(pdf_dir: str, manual_dir: str):\n",
        "    \"\"\"Quickly create a batch process from two directories\"\"\"\n",
        "    processor = BatchKPIProcessor()\n",
        "\n",
        "    # 添加文件对\n",
        "    added_count = processor.add_multiple_pairs_from_directory(pdf_dir, manual_dir)\n",
        "\n",
        "    if added_count == 0:\n",
        "        print(\"❌ No matching PDF and Manual file pairs found.\")\n",
        "        return None\n",
        "\n",
        "    # 显示文件列表\n",
        "    processor.list_file_pairs()\n",
        "\n",
        "    # 询问是否继续\n",
        "    response = input(f\"\\nStart processing these {added_count} documents? (y/n): \")\n",
        "    if response.lower() == 'y':\n",
        "        processor.run_batch_processing()\n",
        "        return processor\n",
        "    else:\n",
        "        print(\"Batch processing cancelled.\")\n",
        "        return processor\n",
        "\n",
        "def manual_batch_setup():\n",
        "    \"\"\"Interactive function for manually configuring a batch process\"\"\"\n",
        "    processor = BatchKPIProcessor()\n",
        "\n",
        "    print(\"📋 Manual Batch Processing Setup\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    while True:\n",
        "        print(f\"\\nCurrently added {len(processor.file_pairs)} file pair(s)\")\n",
        "        print(\"1. Add a single file pair\")\n",
        "        print(\"2. Add multiple file pairs from directories\")\n",
        "        print(\"3. View added file pairs\")\n",
        "        print(\"4. Start batch processing\")\n",
        "        print(\"5. Exit\")\n",
        "\n",
        "        choice = input(\"Select an option (1-5): \")\n",
        "\n",
        "        if choice == '1':\n",
        "            pdf_path = input(\"PDF file path: \")\n",
        "            manual_path = input(\"Manual file path: \")\n",
        "            doc_name = input(\"Document name (press Enter for default): \").strip()\n",
        "\n",
        "            if not doc_name:\n",
        "                doc_name = None\n",
        "\n",
        "            processor.add_file_pair(pdf_path, manual_path, doc_name)\n",
        "\n",
        "        elif choice == '2':\n",
        "            pdf_dir = input(\"PDF directory: \")\n",
        "            manual_dir = input(\"Manual directory: \")\n",
        "            added = processor.add_multiple_pairs_from_directory(pdf_dir, manual_dir)\n",
        "            print(f\"{added} file pair(s) added.\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            processor.list_file_pairs()\n",
        "\n",
        "        elif choice == '4':\n",
        "            if processor.file_pairs:\n",
        "                processor.run_batch_processing()\n",
        "                break\n",
        "            else:\n",
        "                print(\"❌ No file pairs added.\")\n",
        "\n",
        "        elif choice == '5':\n",
        "            print(\"Exiting batch setup.\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid selection. Please try again.\")\n",
        "\n",
        "    return processor"
      ],
      "metadata": {
        "id": "Mc6cffCKCHDk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced comparison function for the main code\n",
        "def enhanced_compare_with_manual_kpis_with_llm(df_auto: pd.DataFrame, manual_xlsx_path: str,\n",
        "                                              output_dir: str = \"validation_results\",\n",
        "                                              use_llm_validation: bool = False,\n",
        "                                              llm_sample_size: int = None) -> Dict[str, any]:\n",
        "    \"\"\"\n",
        "    增强版比较函数 - 包含可选的LLM验证\n",
        "    \"\"\"\n",
        "    if not Path(manual_xlsx_path).exists():\n",
        "        logging.warning(f\"Manual KPI file not found: {manual_xlsx_path}\")\n",
        "        return {}\n",
        "\n",
        "    # Save auto KPIs to temporary file\n",
        "    temp_auto_path = Path(output_dir) / \"temp_auto_kpis.xlsx\"\n",
        "    temp_auto_path.parent.mkdir(exist_ok=True)\n",
        "    df_auto.to_excel(temp_auto_path, index=False)\n",
        "\n",
        "    try:\n",
        "        # Step 1: 传统验证\n",
        "        print(f\"\\n🔍 Running traditional validation against {Path(manual_xlsx_path).name}...\")\n",
        "\n",
        "        validator = KPIValidationPipeline(\n",
        "            manual_excel_path=manual_xlsx_path,\n",
        "            auto_excel_path=str(temp_auto_path),\n",
        "            output_dir=output_dir\n",
        "        )\n",
        "\n",
        "        text_validation_results = validator.run_full_validation()\n",
        "\n",
        "        # Step 2: LLM验证（如果启用）\n",
        "        llm_results = {}\n",
        "        if use_llm_validation:\n",
        "            print(f\"\\n🤖 Running LLM validation...\")\n",
        "\n",
        "            # 确保有OpenAI客户端\n",
        "            global client\n",
        "            if client:\n",
        "                llm_validator = LLMAssistedValidation(client, validator)\n",
        "                llm_results = llm_validator.run_llm_validation_on_matches(llm_sample_size)\n",
        "\n",
        "                # 保存LLM比较报告\n",
        "                llm_report = llm_validator.generate_llm_comparison_report()\n",
        "                llm_report_path = Path(output_dir) / \"llm_validation_report.md\"\n",
        "                with open(llm_report_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write(llm_report)\n",
        "\n",
        "                print(f\"🤖 LLM validation completed: {llm_results.get('agreement_rate', 0):.1%} agreement rate\")\n",
        "            else:\n",
        "                print(\"❌ OpenAI client not available for LLM validation\")\n",
        "\n",
        "        # Step 3: 元数据验证\n",
        "        print(f\"\\n📊 Running metadata validation...\")\n",
        "        metadata_validator = MetadataValidationExtension(validator)\n",
        "        metadata_results = metadata_validator.validate_metadata_for_matched_pairs()\n",
        "        metadata_saved_files = metadata_validator.save_metadata_validation_results(f\"{output_dir}/metadata_validation\")\n",
        "\n",
        "        # Step 4: 保存增强表格\n",
        "        validator.save_results_with_enhanced_tables()\n",
        "\n",
        "        # 组合所有结果\n",
        "        complete_results = {\n",
        "            'text_validation': text_validation_results,\n",
        "            'llm_validation': llm_results,\n",
        "            'metadata_validation': metadata_results,\n",
        "            'saved_files': {\n",
        "                'text_validation_files': text_validation_results.get('saved_files', {}),\n",
        "                'llm_validation_files': {'report': f\"{output_dir}/llm_validation_report.md\"} if llm_results else {},\n",
        "                'metadata_validation_files': metadata_saved_files,\n",
        "                'enhanced_tables': f\"{output_dir}/validation_summary_tables.xlsx\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Clean up\n",
        "        if temp_auto_path.exists():\n",
        "            temp_auto_path.unlink()\n",
        "\n",
        "        return complete_results\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Enhanced validation failed: {e}\")\n",
        "        if temp_auto_path.exists():\n",
        "            temp_auto_path.unlink()\n",
        "        return {}\n",
        "\n",
        "# 保持向后兼容性\n",
        "def enhanced_compare_with_manual_kpis(df_auto: pd.DataFrame, manual_xlsx_path: str,\n",
        "                                     output_dir: str = \"validation_results\") -> Dict[str, any]:\n",
        "    \"\"\"向后兼容的验证函数\"\"\"\n",
        "    return enhanced_compare_with_manual_kpis_with_llm(df_auto, manual_xlsx_path, output_dir, False, None)\n",
        "\n",
        "# Integration function for the main pipeline\n",
        "def run_kpi_extraction_with_validation():\n",
        "    \"\"\"Run KPI extraction with comprehensive validation\"\"\"\n",
        "    print(\"🚀 Starting KPI extraction with automated validation...\")\n",
        "\n",
        "    # Validate environment\n",
        "    if not validate_environment():\n",
        "        print(\"Please fix the environment issues before running.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Step 1: Run KPI extraction\n",
        "        print(\"\\n📊 Step 1: Extracting KPIs...\")\n",
        "        df_auto = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "\n",
        "        # Save auto results\n",
        "        save_results(df_auto, EXPORT_AUTO_XLSX, PDF_PATH)\n",
        "        print(f\"✅ Extracted {len(df_auto)} KPIs and saved to {EXPORT_AUTO_XLSX}\")\n",
        "\n",
        "        # Step 2: Run validation if manual file exists\n",
        "        if MANUAL_XLSX and Path(MANUAL_XLSX).exists():\n",
        "            print(f\"\\n🔍 Step 2: Running validation against {MANUAL_XLSX}...\")\n",
        "            validation_results = enhanced_compare_with_manual_kpis(\n",
        "                df_auto, MANUAL_XLSX, \"validation_results\"\n",
        "            )\n",
        "\n",
        "            if validation_results:\n",
        "                best_metrics = validation_results['best_metrics']\n",
        "                print(f\"\\n🎯 Validation completed!\")\n",
        "                print(f\"   F1 Score: {best_metrics['f1_score']:.3f}\")\n",
        "                print(f\"   Precision: {best_metrics['precision']:.3f}\")\n",
        "                print(f\"   Recall: {best_metrics['recall']:.3f}\")\n",
        "\n",
        "                return {\n",
        "                    'extracted_kpis': df_auto,\n",
        "                    'validation_results': validation_results\n",
        "                }\n",
        "            else:\n",
        "                print(\"⚠️ Validation failed, but extraction completed successfully\")\n",
        "                return {'extracted_kpis': df_auto}\n",
        "        else:\n",
        "            print(f\"\\n⚠️ Manual KPI file not found ({MANUAL_XLSX}), skipping validation\")\n",
        "            return {'extracted_kpis': df_auto}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Pipeline failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "# Batch validation function for multiple documents\n",
        "def run_batch_validation(pdf_list: List[str], manual_list: List[str],\n",
        "                        output_base_dir: str = \"batch_validation\"):\n",
        "    \"\"\"\n",
        "    Run validation across multiple PDF documents\n",
        "\n",
        "    Args:\n",
        "        pdf_list: List of PDF file paths\n",
        "        manual_list: List of corresponding manual annotation files\n",
        "        output_base_dir: Base directory for validation results\n",
        "    \"\"\"\n",
        "    batch_results = []\n",
        "\n",
        "    for i, (pdf_path, manual_path) in enumerate(zip(pdf_list, manual_list)):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Processing document {i+1}/{len(pdf_list)}: {Path(pdf_path).name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        try:\n",
        "            # Set up paths for this document\n",
        "            doc_name = Path(pdf_path).stem\n",
        "            doc_output_dir = Path(output_base_dir) / doc_name\n",
        "            doc_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            # Extract KPIs\n",
        "            global PDF_PATH\n",
        "            original_pdf_path = PDF_PATH\n",
        "            PDF_PATH = pdf_path\n",
        "\n",
        "            df_auto = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "            auto_excel_path = doc_output_dir / f\"{doc_name}_auto_kpis.xlsx\"\n",
        "            save_results(df_auto, str(auto_excel_path), PDF_PATH)\n",
        "\n",
        "            # Run validation\n",
        "            validation_results = enhanced_compare_with_manual_kpis(\n",
        "                df_auto, manual_path, str(doc_output_dir / \"validation\")\n",
        "            )\n",
        "\n",
        "            # Store results\n",
        "            doc_result = {\n",
        "                'document': doc_name,\n",
        "                'pdf_path': pdf_path,\n",
        "                'manual_path': manual_path,\n",
        "                'extracted_kpis': len(df_auto),\n",
        "                'validation_results': validation_results.get('best_metrics', {}),\n",
        "                'output_dir': str(doc_output_dir)\n",
        "            }\n",
        "            batch_results.append(doc_result)\n",
        "\n",
        "            # Restore original PDF path\n",
        "            PDF_PATH = original_pdf_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to process {doc_name}: {e}\")\n",
        "            batch_results.append({\n",
        "                'document': doc_name,\n",
        "                'pdf_path': pdf_path,\n",
        "                'manual_path': manual_path,\n",
        "                'error': str(e)\n",
        "            })\n",
        "\n",
        "    # Generate batch summary\n",
        "    batch_summary_path = Path(output_base_dir) / \"batch_summary.xlsx\"\n",
        "    batch_df = pd.DataFrame(batch_results)\n",
        "    batch_df.to_excel(batch_summary_path, index=False)\n",
        "\n",
        "    print(f\"\\n🎉 Batch validation completed!\")\n",
        "    print(f\"📊 Processed {len(pdf_list)} documents\")\n",
        "    print(f\"📁 Results saved to {output_base_dir}\")\n",
        "    print(f\"📋 Summary available at {batch_summary_path}\")\n",
        "\n",
        "    return batch_results\n",
        "\n",
        "\n",
        "# Quick validation function for testing\n",
        "def quick_validation_test(manual_xlsx: str = None, auto_xlsx: str = None):\n",
        "    \"\"\"Quick validation test with existing files\"\"\"\n",
        "    manual_file = manual_xlsx or MANUAL_XLSX\n",
        "    auto_file = auto_xlsx or EXPORT_AUTO_XLSX\n",
        "\n",
        "    if not Path(manual_file).exists():\n",
        "        print(f\"❌ Manual file not found: {manual_file}\")\n",
        "        return None\n",
        "\n",
        "    if not Path(auto_file).exists():\n",
        "        print(f\"❌ Auto file not found: {auto_file}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"🔍 Quick validation test:\")\n",
        "    print(f\"  Manual: {manual_file}\")\n",
        "    print(f\"  Auto: {auto_file}\")\n",
        "\n",
        "    try:\n",
        "        validator = KPIValidationPipeline(\n",
        "            manual_excel_path=manual_file,\n",
        "            auto_excel_path=auto_file,\n",
        "            output_dir=\"quick_validation\"\n",
        "        )\n",
        "\n",
        "        results = validator.run_full_validation()\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Quick validation failed: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Performance benchmarking function\n",
        "def benchmark_extraction_methods():\n",
        "    \"\"\"Benchmark different extraction methods with validation\"\"\"\n",
        "    methods = {\n",
        "        'text_only': process_text_only,\n",
        "        'with_images': process_sustainability_report_with_enhanced_images,\n",
        "        'optimized': process_sustainability_report_OPTIMIZED\n",
        "    }\n",
        "\n",
        "    benchmark_results = {}\n",
        "\n",
        "    for method_name, method_func in methods.items():\n",
        "        print(f\"\\n🧪 Benchmarking {method_name}...\")\n",
        "\n",
        "        try:\n",
        "            import time\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Run extraction\n",
        "            df_result = method_func(PDF_PATH)\n",
        "            extraction_time = time.time() - start_time\n",
        "\n",
        "            # Save results\n",
        "            method_output = f\"{method_name}_{EXPORT_AUTO_XLSX}\"\n",
        "            save_results(df_result, method_output, PDF_PATH)\n",
        "\n",
        "            # Run validation if manual file exists\n",
        "            validation_metrics = {}\n",
        "            if MANUAL_XLSX and Path(MANUAL_XLSX).exists():\n",
        "                validation_results = enhanced_compare_with_manual_kpis(\n",
        "                    df_result, MANUAL_XLSX, f\"benchmark_{method_name}\"\n",
        "                )\n",
        "                if validation_results:\n",
        "                    validation_metrics = validation_results['best_metrics']\n",
        "\n",
        "            benchmark_results[method_name] = {\n",
        "                'extraction_time': extraction_time,\n",
        "                'kpi_count': len(df_result),\n",
        "                'kpis_per_second': len(df_result) / extraction_time,\n",
        "                'validation_metrics': validation_metrics\n",
        "            }\n",
        "\n",
        "            print(f\"✅ {method_name}: {len(df_result)} KPIs in {extraction_time:.1f}s\")\n",
        "            if validation_metrics:\n",
        "                print(f\"   F1: {validation_metrics.get('f1_score', 0):.3f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ {method_name} failed: {e}\")\n",
        "            benchmark_results[method_name] = {'error': str(e)}\n",
        "\n",
        "    # Save benchmark results\n",
        "    benchmark_df = pd.DataFrame(benchmark_results).T\n",
        "    benchmark_df.to_excel(\"extraction_benchmark.xlsx\")\n",
        "\n",
        "    print(f\"\\n🏆 Benchmark completed!\")\n",
        "    print(f\"📊 Results saved to extraction_benchmark.xlsx\")\n",
        "\n",
        "    return benchmark_results\n",
        "\n",
        "\n",
        "# Usage examples and documentation\n",
        "def validation_usage_examples():\n",
        "    \"\"\"Show usage examples for the validation pipeline\"\"\"\n",
        "    print(\"\"\"\n",
        "# KPI Validation Pipeline Usage Examples\n",
        "\n",
        "## 1. Basic validation with existing files\n",
        "```python\n",
        "validator = KPIValidationPipeline(\n",
        "    manual_excel_path=\"manual_kpis.xlsx\",\n",
        "    auto_excel_path=\"auto_kpis.xlsx\"\n",
        ")\n",
        "results = validator.run_full_validation()\n",
        "```\n",
        "\n",
        "## 2. Integrated extraction + validation\n",
        "```python\n",
        "results = run_kpi_extraction_with_validation()\n",
        "```\n",
        "\n",
        "## 3. Quick validation test\n",
        "```python\n",
        "results = quick_validation_test(\"manual.xlsx\", \"auto.xlsx\")\n",
        "```\n",
        "\n",
        "## 4. Batch validation for multiple documents\n",
        "```python\n",
        "pdf_files = [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]\n",
        "manual_files = [\"manual1.xlsx\", \"manual2.xlsx\", \"manual3.xlsx\"]\n",
        "batch_results = run_batch_validation(pdf_files, manual_files)\n",
        "```\n",
        "\n",
        "## 5. Benchmark different extraction methods\n",
        "```python\n",
        "benchmark_results = benchmark_extraction_methods()\n",
        "```\n",
        "\n",
        "## 6. Custom threshold analysis\n",
        "```python\n",
        "validator = KPIValidationPipeline(\"manual.xlsx\", \"auto.xlsx\")\n",
        "validator.run_comprehensive_evaluation()\n",
        "\n",
        "# Check performance at different thresholds\n",
        "for threshold in [0.5, 0.7, 0.9]:\n",
        "    metrics = validator.calculate_metrics_at_threshold(threshold)\n",
        "    print(f\"Threshold {threshold}: F1={metrics['f1_score']:.3f}\")\n",
        "```\n",
        "\n",
        "## Output Files Generated:\n",
        "- validation_results.json - Complete results in JSON format\n",
        "- detailed_matches.xlsx - All matched KPIs with similarity scores\n",
        "- error_analysis.xlsx - False positives and false negatives\n",
        "- validation_report.md - Human-readable report\n",
        "- threshold_analysis.xlsx - Performance across different thresholds\n",
        "- validation_visualizations.png - Comprehensive charts and graphs\n",
        "\n",
        "## Key Metrics Explained:\n",
        "- **Precision**: % of auto KPIs that match manual annotations\n",
        "- **Recall**: % of manual KPIs found by automatic extraction\n",
        "- **F1 Score**: Harmonic mean of precision and recall\n",
        "- **True Positives**: Correctly identified KPIs\n",
        "- **False Positives**: Auto KPIs not in manual annotations\n",
        "- **False Negatives**: Manual KPIs missed by extraction\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "vv0x-kG2_odA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ 批量处理相关类 ============\n",
        "\n",
        "class DynamicBatchValidationTable:\n",
        "    \"\"\"动态批量验证表格生成器 - 支持任意数量的PDF文件\"\"\"\n",
        "\n",
        "    def __init__(self, batch_results: List[Dict]):\n",
        "        self.batch_results = batch_results\n",
        "        self.document_count = len(batch_results)\n",
        "\n",
        "        print(f\"📊 Initializing dynamic table generator for {self.document_count} documents\")\n",
        "\n",
        "    def generate_dynamic_accuracy_summary(self) -> pd.DataFrame:\n",
        "        \"\"\"动态生成准确度汇总表格 - 自动适应文档数量\"\"\"\n",
        "\n",
        "        print(f\"📋 Generating accuracy summary for {self.document_count} documents...\")\n",
        "\n",
        "        summary_data = []\n",
        "\n",
        "        for i, result in enumerate(self.batch_results, 1):\n",
        "            if result.get('status') == 'completed':\n",
        "                text_metrics = result.get('text_validation', {}).get('best_metrics', {})\n",
        "                metadata_scores = result.get('metadata_validation', {}).get('overall_scores', {})\n",
        "                llm_validation = result.get('llm_validation', {})\n",
        "\n",
        "                row_data = {\n",
        "                    'Doc_ID': i,\n",
        "                    'Document_Name': result.get('document_name', f'Document_{i}'),\n",
        "                    'PDF_File': Path(result.get('pdf_path', '')).name,\n",
        "                    'Manual_File': Path(result.get('manual_path', '')).name,\n",
        "\n",
        "                    # 基础统计\n",
        "                    'Manual_KPIs': text_metrics.get('total_manual', 0),\n",
        "                    'Auto_KPIs': text_metrics.get('total_auto', 0),\n",
        "                    'Matches_Found': text_metrics.get('true_positives', 0),\n",
        "\n",
        "                    # 准确度指标\n",
        "                    'F1_Score': round(text_metrics.get('f1_score', 0), 3),\n",
        "                    'Precision': round(text_metrics.get('precision', 0), 3),\n",
        "                    'Recall': round(text_metrics.get('recall', 0), 3),\n",
        "                    'False_Positives': text_metrics.get('false_positives', 0),\n",
        "                    'False_Negatives': text_metrics.get('false_negatives', 0),\n",
        "\n",
        "                    # 元数据分数\n",
        "                    'Metadata_Score': round(metadata_scores.get('overall_metadata_score', 0), 3),\n",
        "                    'Page_Number_Accuracy': round(self._get_field_accuracy(result, 'Absolute Page Number'), 3),\n",
        "                    'Theme_Accuracy': round(self._get_field_accuracy(result, 'kpi_theme'), 3),\n",
        "                    'Quantitative_Value_Accuracy': round(self._get_field_accuracy(result, 'quantitative_value'), 3),\n",
        "\n",
        "                    # LLM验证（如果有）\n",
        "                    'LLM_Agreement': round(llm_validation.get('agreement_rate', 0), 3) if llm_validation else None,\n",
        "\n",
        "                    # 质量评级和排名\n",
        "                    'Quality_Grade': self._calculate_quality_grade(text_metrics, metadata_scores),\n",
        "                    'Processing_Time_Sec': round(result.get('processing_time_seconds', 0), 1),\n",
        "                    'Status': '✅ Success'\n",
        "                }\n",
        "\n",
        "            else:\n",
        "                # 失败情况\n",
        "                row_data = {\n",
        "                    'Doc_ID': i,\n",
        "                    'Document_Name': result.get('document_name', f'Document_{i}'),\n",
        "                    'PDF_File': Path(result.get('pdf_path', '')).name,\n",
        "                    'Manual_File': Path(result.get('manual_path', '')).name,\n",
        "                    'Status': '❌ Failed',\n",
        "                    'Error': result.get('error_message', 'Unknown error')[:50]\n",
        "                }\n",
        "\n",
        "                # 设置其他字段为默认值\n",
        "                numeric_fields = ['Manual_KPIs', 'Auto_KPIs', 'Matches_Found', 'F1_Score', 'Precision',\n",
        "                                'Recall', 'False_Positives', 'False_Negatives', 'Metadata_Score',\n",
        "                                'Processing_Time_Sec']\n",
        "                for field in numeric_fields:\n",
        "                    row_data[field] = 0\n",
        "\n",
        "            summary_data.append(row_data)\n",
        "\n",
        "        df = pd.DataFrame(summary_data)\n",
        "\n",
        "        # 添加排名列（只对成功的文档排名）\n",
        "        successful_mask = df['Status'] == '✅ Success'\n",
        "        if successful_mask.sum() > 0:\n",
        "            df.loc[successful_mask, 'F1_Rank'] = df.loc[successful_mask, 'F1_Score'].rank(\n",
        "                ascending=False, method='dense').astype(int)\n",
        "            df.loc[successful_mask, 'Overall_Rank'] = df.loc[successful_mask].apply(\n",
        "                lambda row: self._calculate_overall_score(row), axis=1).rank(\n",
        "                ascending=False, method='dense').astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _get_field_accuracy(self, result: Dict, field_name: str) -> float:\n",
        "        \"\"\"提取特定字段的准确度\"\"\"\n",
        "        metadata_validation = result.get('metadata_validation', {})\n",
        "        field_results = metadata_validation.get('field_results', {})\n",
        "\n",
        "        if field_name in field_results:\n",
        "            field_stats = field_results[field_name]\n",
        "            if field_stats['total_comparisons'] > 0:\n",
        "                return field_stats['correct_count'] / field_stats['total_comparisons']\n",
        "        return 0.0\n",
        "\n",
        "    def _calculate_quality_grade(self, text_metrics: Dict, metadata_scores: Dict) -> str:\n",
        "        \"\"\"计算质量等级\"\"\"\n",
        "        f1 = text_metrics.get('f1_score', 0)\n",
        "        metadata = metadata_scores.get('overall_metadata_score', 0)\n",
        "\n",
        "        # 综合评分\n",
        "        combined_score = f1 * 0.6 + metadata * 0.4\n",
        "\n",
        "        if combined_score >= 0.9: return 'A+'\n",
        "        elif combined_score >= 0.85: return 'A'\n",
        "        elif combined_score >= 0.8: return 'B+'\n",
        "        elif combined_score >= 0.75: return 'B'\n",
        "        elif combined_score >= 0.7: return 'C+'\n",
        "        elif combined_score >= 0.65: return 'C'\n",
        "        elif combined_score >= 0.6: return 'D'\n",
        "        else: return 'F'\n",
        "\n",
        "    def _calculate_overall_score(self, row) -> float:\n",
        "        \"\"\"计算综合分数用于排名\"\"\"\n",
        "        return row['F1_Score'] * 0.6 + row['Metadata_Score'] * 0.4\n",
        "\n",
        "    def generate_batch_statistics(self) -> pd.DataFrame:\n",
        "        \"\"\"生成批量统计 - 自动适应文档数量\"\"\"\n",
        "\n",
        "        successful_results = [r for r in self.batch_results if r.get('status') == 'completed']\n",
        "        failed_count = len(self.batch_results) - len(successful_results)\n",
        "\n",
        "        if not successful_results:\n",
        "            return pd.DataFrame({\n",
        "                'Statistic': ['Total Documents', 'Failed Documents'],\n",
        "                'Value': [self.document_count, failed_count],\n",
        "                'Note': ['No successful extractions', 'Check error logs']\n",
        "            })\n",
        "\n",
        "        # 提取所有成功结果的指标\n",
        "        f1_scores = [r.get('text_validation', {}).get('best_metrics', {}).get('f1_score', 0)\n",
        "                    for r in successful_results]\n",
        "        precisions = [r.get('text_validation', {}).get('best_metrics', {}).get('precision', 0)\n",
        "                     for r in successful_results]\n",
        "        recalls = [r.get('text_validation', {}).get('best_metrics', {}).get('recall', 0)\n",
        "                  for r in successful_results]\n",
        "        metadata_scores = [r.get('metadata_validation', {}).get('overall_scores', {}).get('overall_metadata_score', 0)\n",
        "                          for r in successful_results]\n",
        "        processing_times = [r.get('processing_time_seconds', 0) for r in successful_results]\n",
        "\n",
        "        # 计算统计信息\n",
        "        stats_data = [\n",
        "            # 基本统计\n",
        "            {'Category': 'Basic Stats', 'Statistic': 'Total Documents Processed', 'Value': self.document_count},\n",
        "            {'Category': 'Basic Stats', 'Statistic': 'Successful Extractions', 'Value': f\"{len(successful_results)} ({len(successful_results)/self.document_count*100:.1f}%)\"},\n",
        "            {'Category': 'Basic Stats', 'Statistic': 'Failed Extractions', 'Value': f\"{failed_count} ({failed_count/self.document_count*100:.1f}%)\"},\n",
        "\n",
        "            # F1分数统计\n",
        "            {'Category': 'F1 Score', 'Statistic': 'Average', 'Value': f\"{np.mean(f1_scores):.3f}\"},\n",
        "            {'Category': 'F1 Score', 'Statistic': 'Best', 'Value': f\"{np.max(f1_scores):.3f}\"},\n",
        "            {'Category': 'F1 Score', 'Statistic': 'Worst', 'Value': f\"{np.min(f1_scores):.3f}\"},\n",
        "            {'Category': 'F1 Score', 'Statistic': 'Standard Deviation', 'Value': f\"{np.std(f1_scores):.3f}\"},\n",
        "            {'Category': 'F1 Score', 'Statistic': 'Documents > 0.8', 'Value': f\"{sum(1 for score in f1_scores if score > 0.8)} ({sum(1 for score in f1_scores if score > 0.8)/len(f1_scores)*100:.1f}%)\"},\n",
        "\n",
        "            # 精确率统计\n",
        "            {'Category': 'Precision', 'Statistic': 'Average', 'Value': f\"{np.mean(precisions):.3f}\"},\n",
        "            {'Category': 'Precision', 'Statistic': 'Best', 'Value': f\"{np.max(precisions):.3f}\"},\n",
        "            {'Category': 'Precision', 'Statistic': 'Worst', 'Value': f\"{np.min(precisions):.3f}\"},\n",
        "\n",
        "            # 召回率统计\n",
        "            {'Category': 'Recall', 'Statistic': 'Average', 'Value': f\"{np.mean(recalls):.3f}\"},\n",
        "            {'Category': 'Recall', 'Statistic': 'Best', 'Value': f\"{np.max(recalls):.3f}\"},\n",
        "            {'Category': 'Recall', 'Statistic': 'Worst', 'Value': f\"{np.min(recalls):.3f}\"},\n",
        "\n",
        "            # 元数据统计\n",
        "            {'Category': 'Metadata', 'Statistic': 'Average Score', 'Value': f\"{np.mean(metadata_scores):.3f}\"},\n",
        "            {'Category': 'Metadata', 'Statistic': 'Best Score', 'Value': f\"{np.max(metadata_scores):.3f}\"},\n",
        "            {'Category': 'Metadata', 'Statistic': 'Worst Score', 'Value': f\"{np.min(metadata_scores):.3f}\"},\n",
        "\n",
        "            # 处理时间统计\n",
        "            {'Category': 'Performance', 'Statistic': 'Total Processing Time', 'Value': f\"{sum(processing_times)/60:.1f} minutes\"},\n",
        "            {'Category': 'Performance', 'Statistic': 'Average Time per Document', 'Value': f\"{np.mean(processing_times):.1f} seconds\"},\n",
        "            {'Category': 'Performance', 'Statistic': 'Fastest Document', 'Value': f\"{np.min(processing_times):.1f} seconds\"},\n",
        "            {'Category': 'Performance', 'Statistic': 'Slowest Document', 'Value': f\"{np.max(processing_times):.1f} seconds\"},\n",
        "        ]\n",
        "\n",
        "        return pd.DataFrame(stats_data)\n",
        "\n",
        "    def save_dynamic_batch_tables(self, output_path: str = None):\n",
        "        \"\"\"保存动态批量表格\"\"\"\n",
        "\n",
        "        if output_path is None:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            output_path = f\"batch_validation_{self.document_count}docs_{timestamp}.xlsx\"\n",
        "\n",
        "        print(f\"💾 Saving batch validation tables for {self.document_count} documents to: {output_path}\")\n",
        "\n",
        "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
        "\n",
        "            # 1. 主要准确度汇总\n",
        "            accuracy_summary = self.generate_dynamic_accuracy_summary()\n",
        "            accuracy_summary.to_excel(writer, sheet_name='📊_Accuracy_Summary', index=False)\n",
        "\n",
        "            # 2. 批量统计\n",
        "            batch_stats = self.generate_batch_statistics()\n",
        "            batch_stats.to_excel(writer, sheet_name='📈_Batch_Statistics', index=False)\n",
        "\n",
        "            # 3. 排名表（仅成功的文档）\n",
        "            successful_docs = accuracy_summary[accuracy_summary['Status'] == '✅ Success'].copy()\n",
        "            if not successful_docs.empty:\n",
        "                ranking_table = successful_docs[['Doc_ID', 'Document_Name', 'F1_Score', 'Metadata_Score',\n",
        "                                               'Quality_Grade', 'F1_Rank', 'Overall_Rank']].sort_values('Overall_Rank')\n",
        "                ranking_table.to_excel(writer, sheet_name='🏆_Document_Rankings', index=False)\n",
        "\n",
        "            # 4. 错误分析（如果有失败的文档）\n",
        "            failed_docs = accuracy_summary[accuracy_summary['Status'] == '❌ Failed']\n",
        "            if not failed_docs.empty:\n",
        "                error_analysis = failed_docs[['Doc_ID', 'Document_Name', 'PDF_File', 'Manual_File', 'Error']].copy()\n",
        "                error_analysis.to_excel(writer, sheet_name='❌_Error_Analysis', index=False)\n",
        "\n",
        "            # 5. 详细字段准确度（如果有元数据验证）\n",
        "            if any('metadata_validation' in result for result in self.batch_results):\n",
        "                field_accuracy_data = []\n",
        "                for result in self.batch_results:\n",
        "                    if result.get('status') == 'completed':\n",
        "                        doc_name = result.get('document_name', '')\n",
        "                        metadata_validation = result.get('metadata_validation', {})\n",
        "                        field_results = metadata_validation.get('field_results', {})\n",
        "\n",
        "                        for field_name, field_stats in field_results.items():\n",
        "                            if field_stats['total_comparisons'] > 0:\n",
        "                                accuracy = field_stats['correct_count'] / field_stats['total_comparisons']\n",
        "                                field_accuracy_data.append({\n",
        "                                    'Document': doc_name,\n",
        "                                    'Field': field_name,\n",
        "                                    'Accuracy': round(accuracy, 3),\n",
        "                                    'Correct': field_stats['correct_count'],\n",
        "                                    'Total': field_stats['total_comparisons'],\n",
        "                                    'Errors': field_stats['total_comparisons'] - field_stats['correct_count']\n",
        "                                })\n",
        "\n",
        "                if field_accuracy_data:\n",
        "                    field_df = pd.DataFrame(field_accuracy_data)\n",
        "                    field_pivot = field_df.pivot(index='Document', columns='Field', values='Accuracy').fillna(0)\n",
        "                    field_pivot.to_excel(writer, sheet_name='🔍_Field_Accuracy_Details')\n",
        "\n",
        "        return output_path\n",
        "\n",
        "class FlexibleBatchProcessor:\n",
        "    \"\"\"灵活的批量处理器 - 支持任意数量的PDF文件\"\"\"\n",
        "\n",
        "    def __init__(self, output_base_dir: str = \"flexible_batch_results\"):\n",
        "        self.output_base_dir = Path(output_base_dir)\n",
        "        self.output_base_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        self.file_pairs = []\n",
        "        self.batch_results = []\n",
        "\n",
        "        # 生成时间戳用于本次批量处理\n",
        "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    def add_file_pair(self, pdf_path: str, manual_path: str, doc_name: str = None):\n",
        "        \"\"\"添加单个文件对\"\"\"\n",
        "        pdf_path = Path(pdf_path)\n",
        "        manual_path = Path(manual_path)\n",
        "\n",
        "        if not pdf_path.exists() or not manual_path.exists():\n",
        "            print(f\"❌ Files not found: {pdf_path.name} or {manual_path.name}\")\n",
        "            return False\n",
        "\n",
        "        doc_name = doc_name or pdf_path.stem\n",
        "\n",
        "        self.file_pairs.append({\n",
        "            'pdf_path': str(pdf_path),\n",
        "            'manual_path': str(manual_path),\n",
        "            'doc_name': doc_name,\n",
        "            'doc_id': len(self.file_pairs) + 1\n",
        "        })\n",
        "\n",
        "        print(f\"✅ Added file pair {len(self.file_pairs)}: {doc_name}\")\n",
        "        return True\n",
        "\n",
        "    def add_files_from_lists(self, pdf_list: List[str], manual_list: List[str], doc_names: List[str] = None):\n",
        "        \"\"\"从列表批量添加文件对\"\"\"\n",
        "        if len(pdf_list) != len(manual_list):\n",
        "            print(f\"❌ Mismatch: {len(pdf_list)} PDFs vs {len(manual_list)} manual files\")\n",
        "            return 0\n",
        "\n",
        "        added_count = 0\n",
        "        for i, (pdf_path, manual_path) in enumerate(zip(pdf_list, manual_list)):\n",
        "            doc_name = doc_names[i] if doc_names and i < len(doc_names) else None\n",
        "            if self.add_file_pair(pdf_path, manual_path, doc_name):\n",
        "                added_count += 1\n",
        "\n",
        "        print(f\"📋 Added {added_count}/{len(pdf_list)} file pairs\")\n",
        "        return added_count\n",
        "\n",
        "    def add_files_from_directory(self, pdf_dir: str, manual_dir: str):\n",
        "        \"\"\"从目录自动匹配添加文件对\"\"\"\n",
        "        pdf_dir = Path(pdf_dir)\n",
        "        manual_dir = Path(manual_dir)\n",
        "\n",
        "        pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
        "        added_count = 0\n",
        "\n",
        "        for pdf_file in pdf_files:\n",
        "            # 尝试找到匹配的manual文件\n",
        "            possible_names = [\n",
        "                f\"{pdf_file.stem}.xlsx\",\n",
        "                f\"{pdf_file.stem}_manual.xlsx\",\n",
        "                f\"manual_{pdf_file.stem}.xlsx\"\n",
        "            ]\n",
        "\n",
        "            manual_file = None\n",
        "            for name in possible_names:\n",
        "                potential_path = manual_dir / name\n",
        "                if potential_path.exists():\n",
        "                    manual_file = potential_path\n",
        "                    break\n",
        "\n",
        "            if manual_file:\n",
        "                if self.add_file_pair(str(pdf_file), str(manual_file)):\n",
        "                    added_count += 1\n",
        "            else:\n",
        "                print(f\"⚠️  No manual file found for: {pdf_file.name}\")\n",
        "\n",
        "        return added_count\n",
        "\n",
        "    def show_file_summary(self):\n",
        "        \"\"\"显示文件汇总\"\"\"\n",
        "        count = len(self.file_pairs)\n",
        "        print(f\"\\n📊 BATCH PROCESSING SUMMARY\")\n",
        "        print(f\"{'='*50}\")\n",
        "        print(f\"Total file pairs: {count}\")\n",
        "        print(f\"Estimated processing time: {count * 2:.1f} - {count * 5:.1f} minutes\")\n",
        "        print(f\"Output directory: {self.output_base_dir}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        if count > 0:\n",
        "            print(f\"\\n📋 File pairs to process:\")\n",
        "            for i, pair in enumerate(self.file_pairs, 1):\n",
        "                print(f\"  {i:2d}. {pair['doc_name']}\")\n",
        "                print(f\"      PDF: {Path(pair['pdf_path']).name}\")\n",
        "                print(f\"      Manual: {Path(pair['manual_path']).name}\")\n",
        "\n",
        "    def run_flexible_batch_processing(self, use_llm: bool = False, llm_sample_size: int = None):\n",
        "        \"\"\"运行灵活的批量处理\"\"\"\n",
        "\n",
        "        if not self.file_pairs:\n",
        "            print(\"❌ No file pairs to process\")\n",
        "            return None\n",
        "\n",
        "        count = len(self.file_pairs)\n",
        "        current_batch_dir = self.output_base_dir / f\"batch_{count}docs_{self.timestamp}\"\n",
        "        current_batch_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        print(f\"\\n🚀 Starting flexible batch processing for {count} documents...\")\n",
        "        print(f\"📁 Results will be saved to: {current_batch_dir}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # 处理每个文档\n",
        "        for i, file_pair in enumerate(self.file_pairs, 1):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"📄 Processing document {i}/{count}: {file_pair['doc_name']}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            result = self._process_single_document(file_pair, current_batch_dir, use_llm, llm_sample_size)\n",
        "            self.batch_results.append(result)\n",
        "\n",
        "            # 显示进度\n",
        "            progress = i / count * 100\n",
        "            print(f\"📈 Overall progress: {i}/{count} ({progress:.1f}%)\")\n",
        "\n",
        "        # 生成汇总表格\n",
        "        total_time = time.time() - start_time\n",
        "        self._generate_final_summary_tables(current_batch_dir, total_time)\n",
        "\n",
        "        return {\n",
        "            'batch_results': self.batch_results,\n",
        "            'output_directory': current_batch_dir,\n",
        "            'total_time': total_time,\n",
        "            'document_count': count\n",
        "        }\n",
        "\n",
        "    def _process_single_document(self, file_pair: Dict, output_dir: Path, use_llm: bool, llm_sample_size: int) -> Dict:\n",
        "        \"\"\"处理单个文档\"\"\"\n",
        "\n",
        "        doc_name = file_pair['doc_name']\n",
        "        pdf_path = file_pair['pdf_path']\n",
        "        manual_path = file_pair['manual_path']\n",
        "\n",
        "        doc_output_dir = output_dir / f\"doc_{file_pair['doc_id']}_{doc_name}\"\n",
        "        doc_output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        start_time = time.time()\n",
        "        result = {\n",
        "            'doc_id': file_pair['doc_id'],\n",
        "            'document_name': doc_name,\n",
        "            'pdf_path': pdf_path,\n",
        "            'manual_path': manual_path,\n",
        "            'output_dir': str(doc_output_dir),\n",
        "            'start_time': datetime.now().isoformat(),\n",
        "            'status': 'processing'\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # 临时设置全局PDF路径\n",
        "            global PDF_PATH\n",
        "            original_pdf_path = PDF_PATH\n",
        "            PDF_PATH = pdf_path\n",
        "\n",
        "            # KPI提取\n",
        "            print(f\"📊 Extracting KPIs from {Path(pdf_path).name}...\")\n",
        "            df_auto = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "\n",
        "            # 保存自动提取结果\n",
        "            auto_excel_path = doc_output_dir / f\"{doc_name}_auto_kpis.xlsx\"\n",
        "            save_results(df_auto, str(auto_excel_path), PDF_PATH)\n",
        "\n",
        "            print(f\"✅ Extracted {len(df_auto)} KPIs\")\n",
        "\n",
        "            # 运行验证\n",
        "            print(f\"🔍 Running validation against {Path(manual_path).name}...\")\n",
        "            validation_results = enhanced_compare_with_manual_kpis_with_llm(\n",
        "                df_auto, manual_path, str(doc_output_dir / \"validation\"),\n",
        "                use_llm_validation=use_llm,\n",
        "                llm_sample_size=llm_sample_size\n",
        "            )\n",
        "\n",
        "            # 收集结果\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            result.update({\n",
        "                'status': 'completed',\n",
        "                'processing_time_seconds': processing_time,\n",
        "                'extracted_kpis_count': len(df_auto),\n",
        "                'auto_excel_path': str(auto_excel_path),\n",
        "                'text_validation': validation_results.get('text_validation', {}),\n",
        "                'metadata_validation': validation_results.get('metadata_validation', {}),\n",
        "                'llm_validation': validation_results.get('llm_validation', {}) if use_llm else {},\n",
        "                'end_time': datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "            # 显示结果\n",
        "            if validation_results and 'text_validation' in validation_results:\n",
        "                metrics = validation_results['text_validation'].get('best_metrics', {})\n",
        "                print(f\"🎯 Validation completed:\")\n",
        "                print(f\"   F1 Score: {metrics.get('f1_score', 0):.3f}\")\n",
        "                print(f\"   Precision: {metrics.get('precision', 0):.3f}\")\n",
        "                print(f\"   Recall: {metrics.get('recall', 0):.3f}\")\n",
        "\n",
        "            print(f\"⏱️  Processing time: {processing_time:.1f} seconds\")\n",
        "\n",
        "            # 恢复原始PDF路径\n",
        "            PDF_PATH = original_pdf_path\n",
        "\n",
        "        except Exception as e:\n",
        "            processing_time = time.time() - start_time\n",
        "            result.update({\n",
        "                'status': 'failed',\n",
        "                'processing_time_seconds': processing_time,\n",
        "                'error_message': str(e),\n",
        "                'end_time': datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "            print(f\"❌ Processing failed: {e}\")\n",
        "            PDF_PATH = original_pdf_path\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _generate_final_summary_tables(self, output_dir: Path, total_time: float):\n",
        "        \"\"\"生成最终汇总表格\"\"\"\n",
        "\n",
        "        print(f\"\\n📊 Generating summary tables for {len(self.batch_results)} documents...\")\n",
        "\n",
        "        # 创建动态表格生成器\n",
        "        table_generator = DynamicBatchValidationTable(self.batch_results)\n",
        "\n",
        "        # 保存表格\n",
        "        summary_path = output_dir / f\"BATCH_SUMMARY_{len(self.batch_results)}documents.xlsx\"\n",
        "        table_generator.save_dynamic_batch_tables(str(summary_path))\n",
        "\n",
        "        # 显示最终统计\n",
        "        successful_count = len([r for r in self.batch_results if r.get('status') == 'completed'])\n",
        "        failed_count = len(self.batch_results) - successful_count\n",
        "\n",
        "        print(f\"\\n🎉 Batch processing completed!\")\n",
        "        print(f\"📊 Results:\")\n",
        "        print(f\"   ✅ Successful: {successful_count}/{len(self.batch_results)}\")\n",
        "        print(f\"   ❌ Failed: {failed_count}/{len(self.batch_results)}\")\n",
        "        print(f\"   ⏱️  Total time: {total_time:.1f} seconds ({total_time/60:.1f} minutes)\")\n",
        "        print(f\"   📋 Summary tables: {summary_path}\")\n",
        "\n",
        "        return summary_path\n",
        "\n",
        "# ============ 通用使用接口 ============\n",
        "\n",
        "def flexible_batch_validation(**kwargs):\n",
        "    \"\"\"通用的批量验证接口 - 支持多种输入方式\"\"\"\n",
        "\n",
        "    processor = FlexibleBatchProcessor()\n",
        "\n",
        "    # 方式1：从文件列表\n",
        "    if 'pdf_list' in kwargs and 'manual_list' in kwargs:\n",
        "        pdf_list = kwargs['pdf_list']\n",
        "        manual_list = kwargs['manual_list']\n",
        "        doc_names = kwargs.get('doc_names', None)\n",
        "\n",
        "        added = processor.add_files_from_lists(pdf_list, manual_list, doc_names)\n",
        "        if added == 0:\n",
        "            return None\n",
        "\n",
        "    # 方式2：从目录\n",
        "    elif 'pdf_dir' in kwargs and 'manual_dir' in kwargs:\n",
        "        pdf_dir = kwargs['pdf_dir']\n",
        "        manual_dir = kwargs['manual_dir']\n",
        "\n",
        "        added = processor.add_files_from_directory(pdf_dir, manual_dir)\n",
        "        if added == 0:\n",
        "            return None\n",
        "\n",
        "    # 方式3：交互式添加\n",
        "    elif kwargs.get('interactive', False):\n",
        "        print(\"🔧 Interactive file pair setup\")\n",
        "        while True:\n",
        "            pdf_path = input(\"PDF file path (Enter to finish): \").strip()\n",
        "            if not pdf_path:\n",
        "                break\n",
        "            manual_path = input(\"Manual file path: \").strip()\n",
        "            doc_name = input(\"Document name (optional): \").strip() or None\n",
        "\n",
        "            processor.add_file_pair(pdf_path, manual_path, doc_name)\n",
        "\n",
        "    else:\n",
        "        print(\"❌ No valid input method provided\")\n",
        "        print(\"Usage examples:\")\n",
        "        print(\"  flexible_batch_validation(pdf_list=[...], manual_list=[...])\")\n",
        "        print(\"  flexible_batch_validation(pdf_dir='path/to/pdfs', manual_dir='path/to/manuals')\")\n",
        "        print(\"  flexible_batch_validation(interactive=True)\")\n",
        "        return None\n",
        "\n",
        "    # 显示汇总并确认\n",
        "    processor.show_file_summary()\n",
        "\n",
        "    if not processor.file_pairs:\n",
        "        print(\"❌ No valid file pairs to process\")\n",
        "        return None\n",
        "\n",
        "    # 询问处理选项\n",
        "    use_llm = kwargs.get('use_llm', False)\n",
        "    if not use_llm:\n",
        "        response = input(\"\\n🤖 Use LLM validation? (y/n): \").lower()\n",
        "        use_llm = response == 'y'\n",
        "\n",
        "    llm_sample_size = kwargs.get('llm_sample_size', None)\n",
        "    if use_llm and llm_sample_size is None:\n",
        "        sample_input = input(\"LLM sample size per document (Enter for default 20): \").strip()\n",
        "        llm_sample_size = int(sample_input) if sample_input.isdigit() else 20\n",
        "\n",
        "    # 最终确认\n",
        "    confirm = input(f\"\\n🎯 Start processing {len(processor.file_pairs)} documents? (y/n): \").lower()\n",
        "    if confirm != 'y':\n",
        "        print(\"Processing cancelled\")\n",
        "        return None\n",
        "\n",
        "    # 运行批量处理\n",
        "    return processor.run_flexible_batch_processing(use_llm, llm_sample_size)\n",
        "\n",
        "def quick_batch_validation():\n",
        "    \"\"\"快捷批量验证启动函数\"\"\"\n",
        "\n",
        "    print(\"🚀 Quick Batch Validation Setup\")\n",
        "    print(\"=\" * 40)\n",
        "    print(\"1. Process files from lists\")\n",
        "    print(\"2. Process files from directories\")\n",
        "    print(\"3. Interactive file selection\")\n",
        "\n",
        "    choice = input(\"Select option (1-3): \").strip()\n",
        "\n",
        "    if choice == '1':\n",
        "        # 从列表处理\n",
        "        print(\"\\n📋 Enter file paths (comma-separated):\")\n",
        "        pdf_input = input(\"PDF files: \").strip()\n",
        "        manual_input = input(\"Manual files: \").strip()\n",
        "\n",
        "        if pdf_input and manual_input:\n",
        "            pdf_list = [p.strip() for p in pdf_input.split(',')]\n",
        "            manual_list = [m.strip() for m in manual_input.split(',')]\n",
        "\n",
        "            return flexible_batch_validation(\n",
        "                pdf_list=pdf_list,\n",
        "                manual_list=manual_list\n",
        "            )\n",
        "\n",
        "    elif choice == '2':\n",
        "        # 从目录处理\n",
        "        pdf_dir = input(\"PDF directory path: \").strip()\n",
        "        manual_dir = input(\"Manual directory path: \").strip()\n",
        "\n",
        "        if pdf_dir and manual_dir:\n",
        "            return flexible_batch_validation(\n",
        "                pdf_dir=pdf_dir,\n",
        "                manual_dir=manual_dir\n",
        "            )\n",
        "\n",
        "    elif choice == '3':\n",
        "        # 交互式\n",
        "        return flexible_batch_validation(interactive=True)\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid selection\")\n",
        "        return None\n",
        "\n",
        "# ============ 增强的主函数 ============\n",
        "\n",
        "def enhanced_main_with_teacher_feedback():\n",
        "    \"\"\"根据老师反馈改进的主函数\"\"\"\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s - %(levelname)s: %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        if not os.path.exists(PDF_PATH):\n",
        "            logging.error(f\"PDF file not found: {PDF_PATH}\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n🚀 Starting enhanced KPI extraction with validation...\")\n",
        "\n",
        "        # Step 1: KPI提取\n",
        "        df_auto = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "        save_results(df_auto, EXPORT_AUTO_XLSX, PDF_PATH)\n",
        "        print(f\"✅ Extracted {len(df_auto)} KPIs\")\n",
        "\n",
        "        # Step 2: 询问是否使用LLM验证\n",
        "        use_llm = False\n",
        "        if MANUAL_XLSX and Path(MANUAL_XLSX).exists():\n",
        "            response = input(\"\\n🤖 Use LLM validation for comparison? (y/n): \").lower()\n",
        "            use_llm = response == 'y'\n",
        "\n",
        "            if use_llm:\n",
        "                sample_size_input = input(\"Sample size for LLM validation (press Enter for all): \").strip()\n",
        "                sample_size = int(sample_size_input) if sample_size_input.isdigit() else None\n",
        "            else:\n",
        "                sample_size = None\n",
        "\n",
        "            # Step 3: 运行增强验证\n",
        "            validation_results = enhanced_compare_with_manual_kpis_with_llm(\n",
        "                df_auto, MANUAL_XLSX, \"enhanced_validation\",\n",
        "                use_llm_validation=use_llm,\n",
        "                llm_sample_size=sample_size\n",
        "            )\n",
        "\n",
        "            if validation_results:\n",
        "                print(f\"\\n📊 Validation completed!\")\n",
        "                print(f\"📁 Enhanced results (with tables) saved to: enhanced_validation/\")\n",
        "                print(f\"📋 Check validation_summary_tables.xlsx for easy visualization\")\n",
        "\n",
        "                if use_llm and validation_results.get('llm_validation'):\n",
        "                    llm_agreement = validation_results['llm_validation'].get('agreement_rate', 0)\n",
        "                    print(f\"🤖 LLM agreement with traditional method: {llm_agreement:.1%}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"⚠️ Manual KPI file not found, skipping validation\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Enhanced main execution failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "def main_with_flexible_batch_support():\n",
        "    \"\"\"支持灵活批量处理的主函数\"\"\"\n",
        "\n",
        "    print(\"🚀 Enhanced KPI Extraction System with Flexible Batch Processing\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"1. Single PDF processing\")\n",
        "    print(\"2. Flexible batch processing (any number of PDFs)\")\n",
        "    print(\"3. Quick batch setup\")\n",
        "    print(\"4. View usage examples\")\n",
        "\n",
        "    try:\n",
        "        choice = input(\"Select processing mode (1-4): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            # 单个PDF处理\n",
        "            enhanced_main_with_teacher_feedback()\n",
        "\n",
        "        elif choice == '2':\n",
        "            # 灵活批量处理\n",
        "            print(\"\\n📊 Flexible Batch Processing Options:\")\n",
        "            print(\"a. From file lists\")\n",
        "            print(\"b. From directories\")\n",
        "            print(\"c. Interactive setup\")\n",
        "\n",
        "            sub_choice = input(\"Select input method (a-c): \").strip().lower()\n",
        "\n",
        "            if sub_choice == 'a':\n",
        "                # 文件列表输入\n",
        "                pdf_count = int(input(\"How many PDF files? \"))\n",
        "                pdf_list = []\n",
        "                manual_list = []\n",
        "                doc_names = []\n",
        "\n",
        "                for i in range(pdf_count):\n",
        "                    pdf_path = input(f\"PDF file {i+1} path: \").strip()\n",
        "                    manual_path = input(f\"Manual file {i+1} path: \").strip()\n",
        "                    doc_name = input(f\"Document {i+1} name (optional): \").strip()\n",
        "\n",
        "                    pdf_list.append(pdf_path)\n",
        "                    manual_list.append(manual_path)\n",
        "                    if doc_name:\n",
        "                        doc_names.append(doc_name)\n",
        "\n",
        "                flexible_batch_validation(\n",
        "                    pdf_list=pdf_list,\n",
        "                    manual_list=manual_list,\n",
        "                    doc_names=doc_names if doc_names else None\n",
        "                )\n",
        "\n",
        "            elif sub_choice == 'b':\n",
        "                # 目录输入\n",
        "                pdf_dir = input(\"PDF files directory: \").strip()\n",
        "                manual_dir = input(\"Manual files directory: \").strip()\n",
        "\n",
        "                flexible_batch_validation(\n",
        "                    pdf_dir=pdf_dir,\n",
        "                    manual_dir=manual_dir\n",
        "                )\n",
        "\n",
        "            elif sub_choice == 'c':\n",
        "                # 交互式\n",
        "                flexible_batch_validation(interactive=True)\n",
        "\n",
        "        elif choice == '3':\n",
        "            # 快速批量设置\n",
        "            quick_batch_validation()\n",
        "\n",
        "        elif choice == '4':\n",
        "            # 使用示例\n",
        "            print(\"\"\"\n",
        "=== Flexible Batch Validation Usage Examples ===\n",
        "\n",
        "📝 Example 1: Processing 3 PDFs\n",
        "flexible_batch_validation(\n",
        "    pdf_list=[\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"],\n",
        "    manual_list=[\"manual1.xlsx\", \"manual2.xlsx\", \"manual3.xlsx\"],\n",
        "    doc_names=[\"Company A\", \"Company B\", \"Company C\"]\n",
        ")\n",
        "\n",
        "📝 Example 2: Processing 20 PDFs from directories\n",
        "flexible_batch_validation(\n",
        "    pdf_dir=\"/path/to/20_pdfs/\",\n",
        "    manual_dir=\"/path/to/20_manuals/\"\n",
        ")\n",
        "\n",
        "📝 Example 3: Interactive mode (any number)\n",
        "flexible_batch_validation(interactive=True)\n",
        "\n",
        "The system automatically generates tables for ANY number of documents!\n",
        "            \"\"\")\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid selection, running single PDF processing\")\n",
        "            enhanced_main_with_teacher_feedback()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nUser cancelled operation\")\n",
        "    except Exception as e:\n",
        "        print(f\"Execution error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# ============ 便捷使用函数 ============\n",
        "\n",
        "def run_kpi_extraction_with_enhanced_validation():\n",
        "    \"\"\"运行KPI提取并进行增强验证\"\"\"\n",
        "    print(\"🚀 Starting KPI extraction with enhanced validation...\")\n",
        "\n",
        "    # 验证环境\n",
        "    if not validate_environment():\n",
        "        print(\"Please fix the environment issues before running.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Step 1: 运行KPI提取\n",
        "        print(\"\\n📊 Step 1: Extracting KPIs...\")\n",
        "        df_auto = process_sustainability_report_with_enhanced_images(PDF_PATH)\n",
        "\n",
        "        # 保存自动结果\n",
        "        save_results(df_auto, EXPORT_AUTO_XLSX, PDF_PATH)\n",
        "        print(f\"✅ Extracted {len(df_auto)} KPIs and saved to {EXPORT_AUTO_XLSX}\")\n",
        "\n",
        "        # Step 2: 运行验证（如果有manual文件）\n",
        "        if MANUAL_XLSX and Path(MANUAL_XLSX).exists():\n",
        "            print(f\"\\n🔍 Step 2: Running enhanced validation against {MANUAL_XLSX}...\")\n",
        "\n",
        "            # 询问是否使用LLM\n",
        "            use_llm = input(\"🤖 Use LLM validation? (y/n): \").lower() == 'y'\n",
        "            sample_size = None\n",
        "            if use_llm:\n",
        "                sample_input = input(\"LLM sample size (Enter for default): \").strip()\n",
        "                sample_size = int(sample_input) if sample_input.isdigit() else None\n",
        "\n",
        "            validation_results = enhanced_compare_with_manual_kpis_with_llm(\n",
        "                df_auto, MANUAL_XLSX, \"enhanced_validation_results\",\n",
        "                use_llm_validation=use_llm,\n",
        "                llm_sample_size=sample_size\n",
        "            )\n",
        "\n",
        "            if validation_results:\n",
        "                best_metrics = validation_results['text_validation'].get('best_metrics', {})\n",
        "                print(f\"\\n🎯 Enhanced validation completed!\")\n",
        "                print(f\"   F1 Score: {best_metrics.get('f1_score', 0):.3f}\")\n",
        "                print(f\"   Precision: {best_metrics.get('precision', 0):.3f}\")\n",
        "                print(f\"   Recall: {best_metrics.get('recall', 0):.3f}\")\n",
        "                print(f\"📁 Enhanced tables saved to: enhanced_validation_results/validation_summary_tables.xlsx\")\n",
        "\n",
        "                return {\n",
        "                    'extracted_kpis': df_auto,\n",
        "                    'validation_results': validation_results\n",
        "                }\n",
        "            else:\n",
        "                print(\"⚠️ Validation failed, but extraction completed successfully\")\n",
        "                return {'extracted_kpis': df_auto}\n",
        "        else:\n",
        "            print(f\"\\n⚠️ Manual KPI file not found ({MANUAL_XLSX}), skipping validation\")\n",
        "            return {'extracted_kpis': df_auto}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Enhanced pipeline failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# ============ 最终修改：替换原有的主函数调用 ============\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 检测运行环境并提供选择\n",
        "    print(\"🔍 KPI Extraction System Starting...\")\n",
        "\n",
        "    # 提供简单的启动选项\n",
        "    startup_choice = input(\"\"\"\n",
        "Choose startup mode:\n",
        "1. Enhanced single PDF processing (with optional LLM validation)\n",
        "2. Flexible batch processing (any number of PDFs)\n",
        "3. Quick batch validation\n",
        "4. Original single PDF processing (legacy)\n",
        "\n",
        "Enter choice (1-4): \"\"\").strip()\n",
        "\n",
        "    if startup_choice == '1':\n",
        "        enhanced_main_with_teacher_feedback()\n",
        "    elif startup_choice == '2':\n",
        "        main_with_flexible_batch_support()\n",
        "    elif startup_choice == '3':\n",
        "        quick_batch_validation()\n",
        "    elif startup_choice == '4':\n",
        "        # 调用原有的集成函数\n",
        "        integrated_main_execution_detailed()\n",
        "    else:\n",
        "        print(\"Invalid choice, running enhanced single PDF processing...\")\n",
        "        enhanced_main_with_teacher_feedback()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ejwu6Xqi1sr",
        "outputId": "66587398-51b3-4c08-fedd-2eb359155d99"
      },
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 KPI Extraction System Starting...\n",
            "\n",
            "Choose startup mode:\n",
            "1. Enhanced single PDF processing (with optional LLM validation)\n",
            "2. Flexible batch processing (any number of PDFs)  \n",
            "3. Quick batch validation\n",
            "4. Original single PDF processing (legacy)\n",
            "\n",
            "Enter choice (1-4): 2\n",
            "🚀 Enhanced KPI Extraction System with Flexible Batch Processing\n",
            "======================================================================\n",
            "1. Single PDF processing\n",
            "2. Flexible batch processing (any number of PDFs)\n",
            "3. Quick batch setup\n",
            "4. View usage examples\n",
            "Select processing mode (1-4): 2\n",
            "\n",
            "📊 Flexible Batch Processing Options:\n",
            "a. From file lists\n",
            "b. From directories\n",
            "c. Interactive setup\n",
            "Select input method (a-c): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建详细输出的批量处理器\n",
        "def create_batch_processor_with_detailed_output():\n",
        "    \"\"\"创建支持详细输出的批量处理器\"\"\"\n",
        "    return BatchKPIProcessorWithDetailedOutput()\n",
        "\n",
        "# 修改集成执行函数\n",
        "def integrated_main_execution_detailed():\n",
        "    \"\"\"集成的主执行函数 - 详细输出版本\"\"\"\n",
        "    print(\"🚀 Enhanced KPI Extraction System - Detailed Output\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"1. Single PDF processing (detailed text + metadata validation)\")\n",
        "    print(\"2. Batch PDF processing (detailed text + metadata validation)\")\n",
        "    print(\"3. Quick batch from directories (detailed output)\")\n",
        "    print(\"4. Quick metadata validation test\")\n",
        "    print(\"5. View usage examples\")\n",
        "\n",
        "    try:\n",
        "        choice = input(\"Please select processing mode (1-5): \")\n",
        "\n",
        "        if choice == '1':\n",
        "            # 单个PDF处理，详细输出\n",
        "            enhanced_main_with_detailed_output()\n",
        "\n",
        "        elif choice == '2':\n",
        "            # 批量处理，详细输出\n",
        "            processor = create_batch_processor_with_detailed_output()\n",
        "\n",
        "            # 让用户手动添加文件对\n",
        "            while True:\n",
        "                pdf_path = input(\"Enter PDF file path (press Enter to finish): \").strip()\n",
        "                if not pdf_path:\n",
        "                    break\n",
        "                manual_path = input(\"Enter corresponding Manual file path: \").strip()\n",
        "                doc_name = input(\"Document name (press Enter for default): \").strip() or None\n",
        "\n",
        "                processor.add_file_pair(pdf_path, manual_path, doc_name)\n",
        "\n",
        "            if processor.file_pairs:\n",
        "                processor.list_file_pairs()\n",
        "                confirm = input(f\"\\nStart detailed processing of these {len(processor.file_pairs)} documents? (y/n): \")\n",
        "                if confirm.lower() == 'y':\n",
        "                    processor.run_batch_processing()\n",
        "                else:\n",
        "                    print(\"Batch processing cancelled.\")\n",
        "            else:\n",
        "                print(\"❌ No file pairs added.\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            # 快速目录批量处理，详细输出\n",
        "            pdf_dir = input(\"PDF files directory path: \").strip()\n",
        "            manual_dir = input(\"Manual files directory path: \").strip()\n",
        "\n",
        "            processor = create_batch_processor_with_detailed_output()\n",
        "            added_count = processor.add_multiple_pairs_from_directory(pdf_dir, manual_dir)\n",
        "\n",
        "            if added_count == 0:\n",
        "                print(\"❌ No matching PDF and Manual file pairs found.\")\n",
        "                return None\n",
        "\n",
        "            processor.list_file_pairs()\n",
        "            response = input(f\"\\nStart detailed processing of these {added_count} documents? (y/n): \")\n",
        "            if response.lower() == 'y':\n",
        "                processor.run_batch_processing()\n",
        "            else:\n",
        "                print(\"Batch processing cancelled.\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            # 快速元数据验证测试\n",
        "            quick_test_metadata_validation()\n",
        "\n",
        "        elif choice == '5':\n",
        "            # 显示使用示例\n",
        "            metadata_validation_usage_examples()\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid selection, running default single PDF processing\")\n",
        "            enhanced_main_with_detailed_output()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nUser cancelled operation\")\n",
        "    except Exception as e:\n",
        "        print(f\"Execution error: {e}\")\n",
        "        print(\"Running default single PDF processing\")\n",
        "        enhanced_main_with_detailed_output()\n",
        "\n",
        "# 更新主执行部分\n",
        "if __name__ == \"__main__\":\n",
        "    # 使用详细输出的集成执行函数\n",
        "    integrated_main_execution_detailed()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mbBRhgS1ARfC",
        "outputId": "1ac6b97d-17fe-4668-a245-12b26f90ac18"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Enhanced KPI Extraction System - Detailed Output\n",
            "============================================================\n",
            "1. Single PDF processing (detailed text + metadata validation)\n",
            "2. Batch PDF processing (detailed text + metadata validation)\n",
            "3. Quick batch from directories (detailed output)\n",
            "4. Quick metadata validation test\n",
            "5. View usage examples\n",
            "Please select processing mode (1-5): 2\n",
            "Enter PDF file path (press Enter to finish): /content/Avid.pdf\n",
            "Enter corresponding Manual file path: /content/Avid.xlsx\n",
            "Document name (press Enter for default): Avid\n",
            "Enter PDF file path (press Enter to finish): /content/Cineplex.pdf\n",
            "Enter corresponding Manual file path: /content/Cineplex.xlsx\n",
            "Document name (press Enter for default): Cineplex\n",
            "Enter PDF file path (press Enter to finish): /content/NewNewtest.pdf\n",
            "Enter corresponding Manual file path: /content/NewNewtest.xlsx\n",
            "Document name (press Enter for default): NewNewtest\n",
            "Enter PDF file path (press Enter to finish): \n",
            "\n",
            "📋 已添加的文件对 (共 3 对):\n",
            "--------------------------------------------------------------------------------\n",
            " 1. 文档: Avid\n",
            "    PDF:    /content/Avid.pdf\n",
            "    Manual: /content/Avid.xlsx\n",
            "\n",
            " 2. 文档: Cineplex\n",
            "    PDF:    /content/Cineplex.pdf\n",
            "    Manual: /content/Cineplex.xlsx\n",
            "\n",
            " 3. 文档: NewNewtest\n",
            "    PDF:    /content/NewNewtest.pdf\n",
            "    Manual: /content/NewNewtest.xlsx\n",
            "\n",
            "\n",
            "Start detailed processing of these 3 documents? (y/n): y\n",
            "\n",
            "🚀 开始批量处理 3 个文档...\n",
            "📁 结果将保存到: batch_kpi_results/batch_20250802_162625\n",
            "\n",
            "================================================================================\n",
            "📄 Processing Document 1/3: Avid\n",
            "================================================================================\n",
            "📊 Step 1: Extracting KPIs from Avid.pdf...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Image analysis response not JSON list: The image provided does not contain any visible numerical data or identifiable chart elements that c...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a simple bar chart with three vertical bars of different colors. However, ther...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided does not contain any charts or graphs with quantifiable performance data. It appe...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided does not contain any charts or graphs with quantifiable performance data. It appe...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a text document and does not contain any charts or graphs with quantifiable pe...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a text document and does not contain any charts or graphs with quantifiable pe...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided contains text but no charts or graphs with quantifiable performance data. Therefo...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a text document and does not contain any charts or graphs with quantifiable pe...\n",
            "WARNING:root:Image analysis response not JSON list: The image appears to be a series of simple vertical bars with different colors and lengths. However,...\n",
            "WARNING:root:Image analysis response not JSON list: The image appears to be a series of vertical colored lines on a black background. Without any numeri...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided does not contain any visible charts or graphs with quantifiable performance data....\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a bar chart with multiple colored bars, indicating it is a grouped chart. Each...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a bar chart with multiple colored bars, indicating it could be a grouped or st...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a bar chart with multiple colored bars, indicating it is a grouped chart. Each...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a text document and does not contain any charts or graphs with quantifiable pe...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a text document and does not contain any charts or graphs with quantifiable pe...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction completed: 3 KPIs\n",
            "\n",
            "🔍 Step 2: Running comprehensive validation against Avid.xlsx...\n",
            "\n",
            "🔍 Running traditional validation against Avid.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Enhanced validation failed: name 'MetadataValidationExtension' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "KPI EXTRACTION VALIDATION SUMMARY\n",
            "============================================================\n",
            "📊 Dataset: 3 manual vs 3 auto KPIs\n",
            "🎯 Best F1 Score: 1.000\n",
            "📈 Precision: 1.000\n",
            "📉 Recall: 1.000\n",
            "✅ True Positives: 3\n",
            "❌ False Positives: 0\n",
            "⚠️  False Negatives: 0\n",
            "============================================================\n",
            "📁 Results saved to: batch_kpi_results/batch_20250802_162625/doc_1_Avid/validation\n",
            "============================================================\n",
            "\n",
            "📊 Running metadata validation...\n",
            "⏱️  Processing time: 183.5秒 (validation: 5.6秒)\n",
            "📁 Results saved to: batch_kpi_results/batch_20250802_162625/doc_1_Avid\n",
            "\n",
            "================================================================================\n",
            "📄 Processing Document 2/3: Cineplex\n",
            "================================================================================\n",
            "📊 Step 1: Extracting KPIs from Cineplex.pdf...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:API response not JSON list: The provided text does not contain any specific numbers, percentages, or measurable quantities that ...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a logo and does not contain any charts or graphs with quantifiable performance...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a logo and does not contain any charts or graphs with quantifiable performance...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a text document discussing Cineplex's Corporate Social Responsibility approach...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a text document discussing Cineplex's approach to Corporate Social Responsibil...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a text document rather than a chart or graph. It contains qualitative descript...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a text document and does not contain any charts or graphs with quantifiable pe...\n",
            "WARNING:root:Image analysis response not JSON list: The image contains text with quantifiable performance data related to inclusivity, diversity, and cu...\n",
            "WARNING:root:Image analysis response not JSON list: The image contains text with quantifiable data points related to inclusivity, diversity, and custome...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided does not contain any charts or graphs with quantifiable performance data. It is a...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided is a text document and does not contain any charts or graphs. Therefore, there ar...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction completed: 4 KPIs\n",
            "\n",
            "🔍 Step 2: Running comprehensive validation against Cineplex.xlsx...\n",
            "\n",
            "🔍 Running traditional validation against Cineplex.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Enhanced validation failed: name 'MetadataValidationExtension' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "KPI EXTRACTION VALIDATION SUMMARY\n",
            "============================================================\n",
            "📊 Dataset: 6 manual vs 4 auto KPIs\n",
            "🎯 Best F1 Score: 0.800\n",
            "📈 Precision: 1.000\n",
            "📉 Recall: 0.667\n",
            "✅ True Positives: 4\n",
            "❌ False Positives: 0\n",
            "⚠️  False Negatives: 2\n",
            "============================================================\n",
            "📁 Results saved to: batch_kpi_results/batch_20250802_162625/doc_2_Cineplex/validation\n",
            "============================================================\n",
            "\n",
            "📊 Running metadata validation...\n",
            "⏱️  Processing time: 118.2秒 (validation: 5.0秒)\n",
            "📁 Results saved to: batch_kpi_results/batch_20250802_162625/doc_2_Cineplex\n",
            "\n",
            "================================================================================\n",
            "📄 Processing Document 3/3: NewNewtest\n",
            "================================================================================\n",
            "📊 Step 1: Extracting KPIs from NewNewtest.pdf...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Image analysis response not JSON list: The image provided does not contain any charts or graphs with quantifiable performance data. It appe...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided does not contain any charts or graphs with quantifiable performance data. It appe...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided does not contain any charts or graphs with quantifiable performance data. It appe...\n",
            "WARNING:root:Image analysis response not JSON list: The image provided does not contain any charts or graphs with quantifiable performance data. It appe...\n",
            "ERROR:root:Error extracting KPIs from image: Request timed out.\n",
            "ERROR:root:Error extracting KPIs from image: Request timed out.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction completed: 39 KPIs\n",
            "\n",
            "🔍 Step 2: Running comprehensive validation against NewNewtest.xlsx...\n",
            "\n",
            "🔍 Running traditional validation against NewNewtest.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Enhanced validation failed: name 'MetadataValidationExtension' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "KPI EXTRACTION VALIDATION SUMMARY\n",
            "============================================================\n",
            "📊 Dataset: 46 manual vs 39 auto KPIs\n",
            "🎯 Best F1 Score: 0.918\n",
            "📈 Precision: 1.000\n",
            "📉 Recall: 0.848\n",
            "✅ True Positives: 39\n",
            "❌ False Positives: 0\n",
            "⚠️  False Negatives: 7\n",
            "============================================================\n",
            "📁 Results saved to: batch_kpi_results/batch_20250802_162625/doc_3_NewNewtest/validation\n",
            "============================================================\n",
            "\n",
            "📊 Running metadata validation...\n",
            "⏱️  Processing time: 563.8秒 (validation: 72.6秒)\n",
            "📁 Results saved to: batch_kpi_results/batch_20250802_162625/doc_3_NewNewtest\n",
            "Execution error: \"['validation_f1_score', 'validation_precision', 'validation_recall', 'true_positives', 'false_positives', 'false_negatives'] not in index\"\n",
            "Running default single PDF processing\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'enhanced_main_with_detailed_output' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3656353995.py\u001b[0m in \u001b[0;36mintegrated_main_execution_detailed\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mconfirm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                     \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_batch_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-734487109.py\u001b[0m in \u001b[0;36mrun_batch_processing\u001b[0;34m(self, max_workers)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mbatch_total_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_batch_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_total_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3872114425.py\u001b[0m in \u001b[0;36mgenerate_batch_summary\u001b[0;34m(self, total_time)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# 调用父类方法生成基础报告\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_batch_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-734487109.py\u001b[0m in \u001b[0;36mgenerate_batch_summary\u001b[0;34m(self, total_time)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                     \u001b[0mvalidation_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompleted_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m                     \u001b[0mvalidation_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'验证指标'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['validation_f1_score', 'validation_precision', 'validation_recall', 'true_positives', 'false_positives', 'false_negatives'] not in index\"",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3656353995.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# 使用详细输出的集成执行函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mintegrated_main_execution_detailed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3656353995.py\u001b[0m in \u001b[0;36mintegrated_main_execution_detailed\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution error: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running default single PDF processing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0menhanced_main_with_detailed_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# 更新主执行部分\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'enhanced_main_with_detailed_output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WGFaPAXxmjTw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaOKcHV8SxcOHGu7jRbp9c",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0002286f577d4bd0b35496b02c9b3519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5ce56c0a551449b96971a00d033a463",
              "IPY_MODEL_b48738c746ed492f82b3da267f58b057",
              "IPY_MODEL_355143171293469486b2f3573683808d"
            ],
            "layout": "IPY_MODEL_e68e0c22756b4ff79e29c8840a6d7042"
          }
        },
        "e5ce56c0a551449b96971a00d033a463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f716ac47d34b7fb47a15d6c5c9978e",
            "placeholder": "​",
            "style": "IPY_MODEL_5ce75021849c47ff8397414bfffb4f71",
            "value": "config.json: "
          }
        },
        "b48738c746ed492f82b3da267f58b057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_387e067b34084caebcf299a3b7d642e3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9ea394c6e434dfebbeed25c80c04f65",
            "value": 1
          }
        },
        "355143171293469486b2f3573683808d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f42a9810df04e7fb1a3e5bb4c313ee5",
            "placeholder": "​",
            "style": "IPY_MODEL_39a6f8857aed4a18a3c02996a0ec4e19",
            "value": " 4.19k/? [00:00&lt;00:00, 182kB/s]"
          }
        },
        "e68e0c22756b4ff79e29c8840a6d7042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95f716ac47d34b7fb47a15d6c5c9978e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce75021849c47ff8397414bfffb4f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "387e067b34084caebcf299a3b7d642e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a9ea394c6e434dfebbeed25c80c04f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f42a9810df04e7fb1a3e5bb4c313ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a6f8857aed4a18a3c02996a0ec4e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7e7811c04314fc7ae1c664adc6635a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54d483cc303448f49157dd450ef578d6",
              "IPY_MODEL_de0a9c121a6644ae822c32739445aede",
              "IPY_MODEL_81644a7b4873436b9dd5cda5aa5e4832"
            ],
            "layout": "IPY_MODEL_8a9f31cd90694d708f460da8510e41e3"
          }
        },
        "54d483cc303448f49157dd450ef578d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb55b387423f468ea48450d00a2c33b7",
            "placeholder": "​",
            "style": "IPY_MODEL_b9bc1a5bf49c407f89c611c17ba6f23b",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "de0a9c121a6644ae822c32739445aede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_090eae0e4cc54e8783f149c0a3a668e2",
            "max": 605247071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b42f2070c9cf47ca92b3a75d56b3d763",
            "value": 605247071
          }
        },
        "81644a7b4873436b9dd5cda5aa5e4832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e42798b138be456fa4f7f550641d9ec5",
            "placeholder": "​",
            "style": "IPY_MODEL_2dfa72a8849d4be984c33d5dcbed5891",
            "value": " 605M/605M [00:08&lt;00:00, 141MB/s]"
          }
        },
        "8a9f31cd90694d708f460da8510e41e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb55b387423f468ea48450d00a2c33b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9bc1a5bf49c407f89c611c17ba6f23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "090eae0e4cc54e8783f149c0a3a668e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42f2070c9cf47ca92b3a75d56b3d763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e42798b138be456fa4f7f550641d9ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dfa72a8849d4be984c33d5dcbed5891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2771b3bbc87540fca43a137b7c1ac783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7af0ce88614649d18248a2eebf07327a",
              "IPY_MODEL_bcb9d8d65c374a11bcf0830871c60f47",
              "IPY_MODEL_572640eddf76421ca426a2348ab71353"
            ],
            "layout": "IPY_MODEL_deb9ba6e70194f2683fb03593c3450ef"
          }
        },
        "7af0ce88614649d18248a2eebf07327a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b6874147fe34db9995cafa47dc474cc",
            "placeholder": "​",
            "style": "IPY_MODEL_1116ffc0d0e64cde83929cc5243a604b",
            "value": "model.safetensors: 100%"
          }
        },
        "bcb9d8d65c374a11bcf0830871c60f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb5419e5a1ad46048bed98c5102494ad",
            "max": 605157884,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eee252faec204616913e8c51c8260755",
            "value": 605157884
          }
        },
        "572640eddf76421ca426a2348ab71353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d224af04a1d4a1993e75a5812748d5f",
            "placeholder": "​",
            "style": "IPY_MODEL_e0a5e549dede4523a4eae5d5e9b68a26",
            "value": " 605M/605M [00:07&lt;00:00, 119MB/s]"
          }
        },
        "deb9ba6e70194f2683fb03593c3450ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b6874147fe34db9995cafa47dc474cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1116ffc0d0e64cde83929cc5243a604b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb5419e5a1ad46048bed98c5102494ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee252faec204616913e8c51c8260755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d224af04a1d4a1993e75a5812748d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a5e549dede4523a4eae5d5e9b68a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fca65d8785a44aabc8a8f6a974ad242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb36a2f0db0a491e83fdb981b687cf54",
              "IPY_MODEL_7cb7bb19ecdd4aed9e68c873cbc345c1",
              "IPY_MODEL_7c43d77187ec49d6ad05a386bb39a601"
            ],
            "layout": "IPY_MODEL_0bb02190fa7548898065afb695f6e00c"
          }
        },
        "fb36a2f0db0a491e83fdb981b687cf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_987ac61b1b3c41ddaa1b86a43826cc50",
            "placeholder": "​",
            "style": "IPY_MODEL_27065dbbeec042b69c7801cdfc2ac902",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "7cb7bb19ecdd4aed9e68c873cbc345c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cc3059dc28a4a568a425d37f2c4e2d2",
            "max": 316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1203b85ee004f62833434b6070dc495",
            "value": 316
          }
        },
        "7c43d77187ec49d6ad05a386bb39a601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41d337248952404dbdcf1ed32f3e3c0c",
            "placeholder": "​",
            "style": "IPY_MODEL_ce4bffb0b443499db52091a1aecab6ae",
            "value": " 316/316 [00:00&lt;00:00, 5.19kB/s]"
          }
        },
        "0bb02190fa7548898065afb695f6e00c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "987ac61b1b3c41ddaa1b86a43826cc50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27065dbbeec042b69c7801cdfc2ac902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cc3059dc28a4a568a425d37f2c4e2d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1203b85ee004f62833434b6070dc495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41d337248952404dbdcf1ed32f3e3c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce4bffb0b443499db52091a1aecab6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3e7b49859dc4f2c9f1f2e9b5571bf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bc5b5a260ef4f018edbf3e0851e02b2",
              "IPY_MODEL_3abcacc2a37b4cda9bfd633d9e671429",
              "IPY_MODEL_e5cdfe8762374b33818dc7fec867bb0e"
            ],
            "layout": "IPY_MODEL_cf18674534f2445894d59c0d6b9a02db"
          }
        },
        "0bc5b5a260ef4f018edbf3e0851e02b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afd4e05d78f545dfb642636f9f5888a3",
            "placeholder": "​",
            "style": "IPY_MODEL_ce5670c75ee4463caba04c64c66de9fc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3abcacc2a37b4cda9bfd633d9e671429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a156259f674bbcb6ced8c4f9bd5d28",
            "max": 592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77cb59c859db4992a028fd63299a4bef",
            "value": 592
          }
        },
        "e5cdfe8762374b33818dc7fec867bb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a41ba7e0d26648e58601f953b151958c",
            "placeholder": "​",
            "style": "IPY_MODEL_229554cef136486c8a5aa0e9e6d20c8e",
            "value": " 592/592 [00:00&lt;00:00, 14.3kB/s]"
          }
        },
        "cf18674534f2445894d59c0d6b9a02db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd4e05d78f545dfb642636f9f5888a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5670c75ee4463caba04c64c66de9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46a156259f674bbcb6ced8c4f9bd5d28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77cb59c859db4992a028fd63299a4bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a41ba7e0d26648e58601f953b151958c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229554cef136486c8a5aa0e9e6d20c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74baab93f4f94f57acfdf742ef54ed54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27fe1dfa34214aef88464e80fe1010bb",
              "IPY_MODEL_376393e1d7264fff9e1c85af9f3054d8",
              "IPY_MODEL_66ac5ed6caec4c5d98fbb53d8f65faab"
            ],
            "layout": "IPY_MODEL_fb3c8486c260492e9ed975861bcbc763"
          }
        },
        "27fe1dfa34214aef88464e80fe1010bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43790ce901b742d9bae31d2d128ad5eb",
            "placeholder": "​",
            "style": "IPY_MODEL_edf80fa27da2420b9f2aceb9593f81dc",
            "value": "vocab.json: "
          }
        },
        "376393e1d7264fff9e1c85af9f3054d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8293433bbd3b41b7a87018156c5abcdf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_688f485dd12f4858ad6110c8952ad57e",
            "value": 1
          }
        },
        "66ac5ed6caec4c5d98fbb53d8f65faab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b88acf2e8334cc0b2c6d886d972e9f6",
            "placeholder": "​",
            "style": "IPY_MODEL_ca4e2047755449128384196c8f2e5a62",
            "value": " 862k/? [00:00&lt;00:00, 12.0MB/s]"
          }
        },
        "fb3c8486c260492e9ed975861bcbc763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43790ce901b742d9bae31d2d128ad5eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf80fa27da2420b9f2aceb9593f81dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8293433bbd3b41b7a87018156c5abcdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "688f485dd12f4858ad6110c8952ad57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b88acf2e8334cc0b2c6d886d972e9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca4e2047755449128384196c8f2e5a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fa5668fd8eb4fc49ae889c6fc7e65f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dae2fc0f22004fda97bfeb5a3b04aa85",
              "IPY_MODEL_e3e5b11809bb4d16a0c5467cad6a2102",
              "IPY_MODEL_cd7e1ffc0a36427bbab78efd74caaeab"
            ],
            "layout": "IPY_MODEL_6e300209165540dbb9fa07573cde758b"
          }
        },
        "dae2fc0f22004fda97bfeb5a3b04aa85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a9908e479e4158941718735f028171",
            "placeholder": "​",
            "style": "IPY_MODEL_c0dfbc01035944fabc7eb65fda855bbb",
            "value": "merges.txt: "
          }
        },
        "e3e5b11809bb4d16a0c5467cad6a2102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cd422a23cb74016b5ef5780a02ac300",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4deb4215098447b4955a446eb07724d9",
            "value": 1
          }
        },
        "cd7e1ffc0a36427bbab78efd74caaeab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ba8725a29c4a6cb5ae2978be823639",
            "placeholder": "​",
            "style": "IPY_MODEL_687184aa7f29424ea1827269dfc4200f",
            "value": " 525k/? [00:00&lt;00:00, 7.43MB/s]"
          }
        },
        "6e300209165540dbb9fa07573cde758b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a9908e479e4158941718735f028171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0dfbc01035944fabc7eb65fda855bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cd422a23cb74016b5ef5780a02ac300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4deb4215098447b4955a446eb07724d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2ba8725a29c4a6cb5ae2978be823639": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "687184aa7f29424ea1827269dfc4200f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "983f3416c7274f5ea89fcdccbd825716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89d40ada26c949f397eb0dd3f95c5ba1",
              "IPY_MODEL_7951f52ca7a44e18a6680e894986ebd0",
              "IPY_MODEL_8507a09ada164c078953a257017130ba"
            ],
            "layout": "IPY_MODEL_1442095b5f764d9aad2ba4eb85b5ec55"
          }
        },
        "89d40ada26c949f397eb0dd3f95c5ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86f73c9eb4a3458d8329b7445bd5b435",
            "placeholder": "​",
            "style": "IPY_MODEL_01f54f8e653c4ba19775eee1c672fe89",
            "value": "tokenizer.json: "
          }
        },
        "7951f52ca7a44e18a6680e894986ebd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36fa5650a069406fa308133891f05607",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d842cc33814a4cf3bb2a31eeb16c0bb5",
            "value": 1
          }
        },
        "8507a09ada164c078953a257017130ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ed5d7b0b19643e7bde3a3962ef7cd06",
            "placeholder": "​",
            "style": "IPY_MODEL_1290f7e1dde2436cb12b5804f8954e9c",
            "value": " 2.22M/? [00:00&lt;00:00, 17.3MB/s]"
          }
        },
        "1442095b5f764d9aad2ba4eb85b5ec55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f73c9eb4a3458d8329b7445bd5b435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f54f8e653c4ba19775eee1c672fe89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36fa5650a069406fa308133891f05607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d842cc33814a4cf3bb2a31eeb16c0bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ed5d7b0b19643e7bde3a3962ef7cd06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1290f7e1dde2436cb12b5804f8954e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1128ba2c510436e9f85e3f2e09e8367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a1c4f5c79d8408db37e19cc989f16b4",
              "IPY_MODEL_9af452734876489e8b4152c029edf54f",
              "IPY_MODEL_23e8f9fd2e1742fd812fecf5bb8d4095"
            ],
            "layout": "IPY_MODEL_a2c302d015b0434bb61297b6c14a8d0b"
          }
        },
        "7a1c4f5c79d8408db37e19cc989f16b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fb2205d93d544bfaeb221f672dde4a7",
            "placeholder": "​",
            "style": "IPY_MODEL_1f1b7697582640be8c2519d68885f6e1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9af452734876489e8b4152c029edf54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0014b16d79144e98ad74be78121a3b42",
            "max": 389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc46109850b04f68911b971854cbd4b2",
            "value": 389
          }
        },
        "23e8f9fd2e1742fd812fecf5bb8d4095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15ea70c578ed49cca24bbe7018305772",
            "placeholder": "​",
            "style": "IPY_MODEL_bcfb67e1505a49ba91fbe44458bdc4ec",
            "value": " 389/389 [00:00&lt;00:00, 4.93kB/s]"
          }
        },
        "a2c302d015b0434bb61297b6c14a8d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb2205d93d544bfaeb221f672dde4a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1b7697582640be8c2519d68885f6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0014b16d79144e98ad74be78121a3b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc46109850b04f68911b971854cbd4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15ea70c578ed49cca24bbe7018305772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcfb67e1505a49ba91fbe44458bdc4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}